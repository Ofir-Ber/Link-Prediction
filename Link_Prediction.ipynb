{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90bf025c",
      "metadata": {
        "id": "90bf025c"
      },
      "source": [
        "## Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe079666",
      "metadata": {
        "id": "fe079666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a20e21-52f0-4b28-eb91-b8a741856508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting igraph\n",
            "  Downloading igraph-0.9.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.9.9 texttable-1.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install igraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b9ddbf5",
      "metadata": {
        "id": "9b9ddbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34075b81-d328-450d-eb69-6658d831f903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d87a80d",
      "metadata": {
        "id": "1d87a80d"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import igraph\n",
        "import networkx as nx\n",
        "from tqdm import tqdm_notebook,tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from gensim.models import Word2Vec, Doc2Vec\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "from sklearn.model_selection import (train_test_split, GridSearchCV)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
        "\n",
        "\n",
        "# import numpy for Scientific computations\n",
        "import numpy as np\n",
        "# import machine learning libraries\n",
        "from sklearn.metrics import accuracy_score\n",
        "# import packages for hyperparameters tuning\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2079fc78",
      "metadata": {
        "id": "2079fc78"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1cf45d",
      "metadata": {
        "id": "ec1cf45d"
      },
      "outputs": [],
      "source": [
        "path_to_data = \"C:/Users/ofir6/Desktop/MLNS kaggle/data/\"\n",
        "\n",
        "training_set = pd.read_table(path_to_data+\"training_set.txt\",sep=\" \",names=[\"source\",\"target\",\"label\"])\n",
        "testing_set = pd.read_table(path_to_data+\"testing_set.txt\",sep=\" \",names=[\"source\",\"target\"])\n",
        "node_info = pd.read_csv(path_to_data+\"node_information.csv\",names=[\"id\",\"year\",\"title\",\"author\",\"classification\",\"description\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401070b3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1aaf50191c4649d6ba62232d6ed4f238",
            "df131eafaaf14d2ab2b14f7a0e1758b6",
            "337e2ada51ea4d4582fe744f866eec3b",
            "dbe8b1b1216847e19b727a01f5330035",
            "1b3140e58dd543fd991301eec58b2643",
            "4c33878e0bd0459fa65027320c6a12ff",
            "7856211ed05f4e6a90b5e3ec96637ece",
            "1a427bc407b14f8a9bcd18148d264086",
            "8a1a882635f248d7a23e60ecde6997c8",
            "d0e05e9a81ea4d048449ee70ae751e56",
            "98b56302a75a4f3e8b30d4636f2a5fb9"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "401070b3",
        "outputId": "c13f2b49-4d05-4159-9d73-ac0d19966240"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aaf50191c4649d6ba62232d6ed4f238"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm import tqdm, notebook\n",
        "notebook.tqdm_notebook().pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec666dd0",
      "metadata": {
        "id": "ec666dd0",
        "outputId": "099455f2-5060-48ef-eb50-6b7dc38e9eaa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>classification</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>2000</td>\n",
              "      <td>compactification geometry and duality</td>\n",
              "      <td>Paul S. Aspinwall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>these are notes based on lectures given at tas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>2000</td>\n",
              "      <td>domain walls and massive gauged supergravity p...</td>\n",
              "      <td>M. Cvetic, H. Lu, C.N. Pope</td>\n",
              "      <td>Class.Quant.Grav.</td>\n",
              "      <td>we point out that massive gauged supergravity ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  year                                              title  \\\n",
              "0  1001  2000              compactification geometry and duality   \n",
              "1  1002  2000  domain walls and massive gauged supergravity p...   \n",
              "\n",
              "                        author     classification  \\\n",
              "0            Paul S. Aspinwall                NaN   \n",
              "1  M. Cvetic, H. Lu, C.N. Pope  Class.Quant.Grav.   \n",
              "\n",
              "                                         description  \n",
              "0  these are notes based on lectures given at tas...  \n",
              "1  we point out that massive gauged supergravity ...  "
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "node_info.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5acabf5",
      "metadata": {
        "id": "d5acabf5",
        "outputId": "c75f1e54-ca76-454b-8a32-c90d19d76afc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9510123</td>\n",
              "      <td>9502114</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9707075</td>\n",
              "      <td>9604178</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    source   target  label\n",
              "0  9510123  9502114      1\n",
              "1  9707075  9604178      1"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00e5872",
      "metadata": {
        "id": "c00e5872"
      },
      "source": [
        "## Semantic Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c13abce",
      "metadata": {
        "id": "6c13abce"
      },
      "outputs": [],
      "source": [
        "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "N_VECTORIZATION = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d85b22b",
      "metadata": {
        "id": "9d85b22b"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2447e16c",
      "metadata": {
        "id": "2447e16c"
      },
      "outputs": [],
      "source": [
        "#Convert a collection of raw documents to a matrix of TF-IDF features\n",
        "#stop_words - that list is assumed to contain stop words, all of which will be removed from the resulting tokens\n",
        "#ngram - The lower and upper boundary of the range of n-values for different n-grams to be extracted. \n",
        "#max_features - build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
        "#norm - ach output row will have unit norm\n",
        "tfidf = TfidfVectorizer(stop_words=stpwds,ngram_range=(1,3),max_features=2000,norm=\"l2\")\n",
        "vectorized_desc = tfidf.fit_transform(list(node_info.description))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00da749b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ce7e97326d684c40b43932bef4d42daf"
          ]
        },
        "id": "00da749b",
        "outputId": "ae7c46cf-0598-48c4-a081-ad6011e0201d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce7e97326d684c40b43932bef4d42daf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/27770 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#creating a corpus of all the descriptions\n",
        "corpus = [element.split(\" \") for element in node_info[\"description\"]]\n",
        "for i in notebook.tqdm(range(len(corpus))):\n",
        "    corpus[i] = [stemmer.stem(el) for el in corpus[i] if (el.isdigit()==False and len(el)>2 and len(el)<15)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83942db2",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b613aaa8243f4583b93858ce4f8d4aef"
          ]
        },
        "id": "83942db2",
        "outputId": "428664fe-cd14-4fb8-86fa-ce14f6171d18"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b613aaa8243f4583b93858ce4f8d4aef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#creating a named tuple with words and tags\n",
        "from collections import namedtuple\n",
        "docs = []\n",
        "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
        "for i, words in notebook.tqdm(enumerate(corpus)):\n",
        "    tags = [i]\n",
        "    docs.append(analyzedDocument(words, tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac8f99b3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8f96c2ed7dfc412eb5912262cad1044f"
          ]
        },
        "id": "ac8f99b3",
        "outputId": "c2f18550-ef87-40d7-8448-02ba82990aae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f96c2ed7dfc412eb5912262cad1044f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/27770 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#represents each Document as a Vector using Doc2Vec\n",
        "model = Doc2Vec(docs, vector_size=N_VECTORIZATION, window=8, min_count=5, workers=4)\n",
        "liste = [list(model.dv[i]) for i in notebook.tqdm(range(len(model.dv)))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1afeabe",
      "metadata": {
        "id": "c1afeabe"
      },
      "outputs": [],
      "source": [
        "#merge the vectors to node_info data frame\n",
        "node_info = node_info.merge(pd.DataFrame(liste, columns=[\"description_d2v_\"+str(i) for i in range(N_VECTORIZATION)]),\n",
        "                            how='outer', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8257d1",
      "metadata": {
        "id": "0f8257d1"
      },
      "outputs": [],
      "source": [
        "#merge the vectors to node_info data frame\n",
        "#new_desc = pd.DataFrame(liste, columns=[\"description_d2v_\"+str(i) for i in range(N_VECTORIZATION)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45838e8a",
      "metadata": {
        "id": "45838e8a"
      },
      "source": [
        "## Title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866b4dfc",
      "metadata": {
        "id": "866b4dfc"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(stop_words=stpwds,ngram_range=(1,3),max_features=2000,norm=\"l2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c1e8a3",
      "metadata": {
        "id": "04c1e8a3"
      },
      "outputs": [],
      "source": [
        "vectorized_title = tfidf.fit_transform(list(node_info.title))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a795fa0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cfb0296a9d7149bf959100fd738f87ec"
          ]
        },
        "id": "9a795fa0",
        "outputId": "534ec4a6-887e-49c6-ba96-66a65f226aa2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfb0296a9d7149bf959100fd738f87ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/27770 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "corpus = [element.split(\" \") for element in node_info[\"title\"]]\n",
        "for i in notebook.tqdm(range(len(corpus))):\n",
        "    corpus[i] = [stemmer.stem(el) for el in corpus[i] if (el.isdigit()==False and len(el)>2 and len(el)<15)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7248445",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c745a5fe2d1b486aaa0bffdb0aed8b09"
          ]
        },
        "id": "a7248445",
        "outputId": "ae60e3b3-a576-4516-aa20-018fda08eec9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c745a5fe2d1b486aaa0bffdb0aed8b09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "docs = []\n",
        "\n",
        "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
        "for i, words in notebook.tqdm(enumerate(corpus)):\n",
        "    tags = [i]\n",
        "    docs.append(analyzedDocument(words, tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557ee786",
      "metadata": {
        "id": "557ee786"
      },
      "outputs": [],
      "source": [
        "model = Doc2Vec(docs, vector_size=N_VECTORIZATION, window=8, min_count=5, workers=4)\n",
        "liste = [list(model.dv[i]) for i in range(len(model.dv))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc61622",
      "metadata": {
        "id": "bfc61622"
      },
      "outputs": [],
      "source": [
        "node_info = node_info.merge(pd.DataFrame(liste, columns=[\"title_d2v_\"+str(i) for i in range(N_VECTORIZATION)]),how='outer', left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7639b231",
      "metadata": {
        "id": "7639b231"
      },
      "outputs": [],
      "source": [
        "#new_title = pd.DataFrame(liste, columns=[\"description_d2v_\"+str(i) for i in range(N_VECTORIZATION)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e329de30",
      "metadata": {
        "id": "e329de30"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ac64ea",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "de150fc9545c455f9c9a949bbc6d6485"
          ]
        },
        "id": "85ac64ea",
        "outputId": "e3444586-0a51-4b11-cbce-99e0e1a52344"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de150fc9545c455f9c9a949bbc6d6485",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/27770 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def clear_name(val):\n",
        "    if val!=val:\n",
        "        return \"\"\n",
        "    ar = val.split(\",\")\n",
        "    for i in range(len(ar)):\n",
        "        if ar[i][0]== \" \" and len(ar[i])>1: #get rid of the first space\n",
        "            ar[i] = ar[i][1:]\n",
        "        ar[i] = \";\".join(ar[i].split(\" \"))\n",
        "        #or ar[i] = ar[i].split(\" \")[-1]\n",
        "        ar[i] = ar[i].replace(\"(\", \"\")\n",
        "        ar[i] = ar[i].replace(\")\", \"\")\n",
        "    return \" \".join(ar)\n",
        "\n",
        "node_info[\"author\"] = node_info[\"author\"].progress_apply(lambda val: clear_name(val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "def clean_data(data):\n",
        "    #punctuations\n",
        "    punctuations = string.punctuation\n",
        "    #digits\n",
        "    digits = string.digits\n",
        "    for punctuation in punctuations:\n",
        "        data = data.replace(punctuation, ' ')\n",
        "    for digit in digits:\n",
        "        data = data.replace(digit, ' ')\n",
        "    data = ' '.join(data.split())\n",
        "    return data\n",
        "\n",
        "def lemmatization(data):\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    words = data.split()\n",
        "    new_data = []\n",
        "    for word in words:\n",
        "        word = wordnet_lemmatizer.lemmatize(word, 'v')\n",
        "        new_data.append(word)\n",
        "    new_data = ' '.join(new_data)\n",
        "    return new_data \n",
        "\n",
        "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "\n",
        "def clean_stop(data):\n",
        "    words = data.split()\n",
        "    new_data = []\n",
        "    for word in words:\n",
        "        if word not in stpwds:\n",
        "            if len(word)> 1:\n",
        "                new_data.append(word)\n",
        "    new_data = ' '.join(new_data)\n",
        "    return new_data "
      ],
      "metadata": {
        "id": "RVIg2uALDNbG"
      },
      "id": "RVIg2uALDNbG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "556d7df4",
      "metadata": {
        "id": "556d7df4"
      },
      "outputs": [],
      "source": [
        "node_info[\"pos\"] = pd.Series([i for i in range(len(node_info))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c6cce4",
      "metadata": {
        "id": "d6c6cce4"
      },
      "outputs": [],
      "source": [
        "training_set = training_set.merge(node_info, how=\"left\", left_on = \"source\", right_on = \"id\")\n",
        "training_set = training_set.merge(node_info, how=\"left\", left_on = \"target\", right_on = \"id\", suffixes= [\"_source\",\"_target\"])\n",
        "\n",
        "testing_set = testing_set.merge(node_info, how=\"left\", left_on = \"source\", right_on = \"id\")\n",
        "testing_set = testing_set.merge(node_info, how=\"left\", left_on = \"target\", right_on = \"id\", suffixes= [\"_source\",\"_target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf9ac54",
      "metadata": {
        "id": "bdf9ac54"
      },
      "outputs": [],
      "source": [
        "del(tfidf, corpus, model, analyzedDocument, docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7efbc8b6",
      "metadata": {
        "id": "7efbc8b6"
      },
      "outputs": [],
      "source": [
        "#training_set.columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7a3d77",
      "metadata": {
        "id": "ec7a3d77"
      },
      "source": [
        "## Features based on graph topology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845bcf49",
      "metadata": {
        "id": "845bcf49"
      },
      "outputs": [],
      "source": [
        "edges = training_set[training_set[\"label\"]==1]\n",
        "\n",
        "ig = igraph.Graph()\n",
        "ig.add_vertices(node_info.id)\n",
        "ig.add_edges([(source,target) for source,target in zip(edges.pos_source,edges.pos_target)])\n",
        "\n",
        "g = nx.Graph()\n",
        "g.add_nodes_from(node_info.id)\n",
        "g.add_edges_from([(source,target) for source,target in zip(edges.source,edges.target)])\n",
        "\n",
        "dg = nx.DiGraph()\n",
        "dg.add_nodes_from(node_info.id)\n",
        "dg.add_edges_from([(source,target) for source,target in zip(edges.source,edges.target)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c051973",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "abd183d1c11d41828e34f38b90a8f2df",
            "ff56d6b7e76b4480b8a9c8d488e1868d"
          ]
        },
        "id": "3c051973",
        "outputId": "270bd4a9-d2dd-4e75-b480-111e88d23908"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abd183d1c11d41828e34f38b90a8f2df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff56d6b7e76b4480b8a9c8d488e1868d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def common_neighbor(line):\n",
        "    n_source = set(ig.neighbors(line[\"pos_source\"], mode=\"ALL\"))\n",
        "    n_target = set(ig.neighbors(line[\"pos_target\"], mode=\"ALL\"))\n",
        "    return(len(n_source & n_target)>0)\n",
        "\n",
        "training_set[\"common_neighbor\"] = training_set.progress_apply(common_neighbor,axis=1)\n",
        "testing_set[\"common_neighbor\"] = testing_set.progress_apply(common_neighbor,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29fc972",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "484a4137e5b445c89cdbe1ec66be5489",
            "7ca7d432fad64b08bf15d423da7b2e1c"
          ]
        },
        "id": "d29fc972",
        "outputId": "ba109567-2a60-4c5c-96e5-ced441a6b7fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "484a4137e5b445c89cdbe1ec66be5489",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ca7d432fad64b08bf15d423da7b2e1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def jaccard(line):\n",
        "    n_source = set(ig.neighbors(line[\"pos_source\"], mode=\"ALL\"))\n",
        "    n_target = set(ig.neighbors(line[\"pos_target\"], mode=\"ALL\"))\n",
        "    if(len(n_source) == 0 and len(n_target)==0):\n",
        "        return 1\n",
        "    return(len(n_source & n_target)/len(n_source | n_target))\n",
        "\n",
        "training_set[\"jaccard\"] = training_set.progress_apply(jaccard,axis=1)\n",
        "testing_set[\"jaccard\"] = testing_set.progress_apply(jaccard,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd39e8bf",
      "metadata": {
        "id": "dd39e8bf"
      },
      "outputs": [],
      "source": [
        "betweenness = ig.betweenness()\n",
        "\n",
        "training_set[\"betweenness_source\"] = training_set[\"pos_source\"].progress_apply(lambda x : betweenness[x])\n",
        "testing_set[\"betweenness_source\"] = testing_set[\"pos_source\"].progress_apply(lambda x : betweenness[x])\n",
        "\n",
        "training_set[\"betweenness_target\"] = training_set[\"pos_target\"].progress_apply(lambda x : betweenness[x])\n",
        "testing_set[\"betweenness_target\"] = testing_set[\"pos_target\"].progress_apply(lambda x : betweenness[x])\n",
        "\n",
        "training_set[\"diff_in_bc\"] = training_set[\"betweenness_target\"] - training_set[\"betweenness_source\"]\n",
        "testing_set[\"diff_in_bc\"] = testing_set[\"betweenness_target\"] - testing_set[\"betweenness_source\"]\n",
        "\n",
        "del(betweenness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc78423",
      "metadata": {
        "id": "bfc78423"
      },
      "outputs": [],
      "source": [
        "inlinks = ig.indegree()\n",
        "\n",
        "def diff_in_inlinks(line):\n",
        "    return(inlinks[line[\"pos_target\"]]-inlinks[line[\"pos_source\"]])\n",
        "\n",
        "training_set[\"diff_in_inlinks\"] = training_set.progress_apply(diff_in_inlinks,axis=1)\n",
        "testing_set[\"diff_in_inlinks\"] = testing_set.progress_apply(diff_in_inlinks,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "925faa8b",
      "metadata": {
        "id": "925faa8b"
      },
      "outputs": [],
      "source": [
        "# Cluster = connected component\n",
        "\n",
        "cluster = ig.clusters().membership\n",
        "\n",
        "def same_cluster(line):\n",
        "    return(cluster[line[\"pos_target\"]]-cluster[line[\"pos_source\"]])\n",
        "\n",
        "training_set[\"same_cluster\"] = training_set.progress_apply(same_cluster,axis=1)\n",
        "testing_set[\"same_cluster\"] = testing_set.progress_apply(same_cluster,axis=1)\n",
        "\n",
        "del(cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f3e69e",
      "metadata": {
        "id": "39f3e69e"
      },
      "outputs": [],
      "source": [
        "# Eccentricity : cumulative sum of the distance to other edges\n",
        "\n",
        "eccentricity = ig.eccentricity(mode=\"IN\")\n",
        "\n",
        "def target_eccentricty(line):\n",
        "    return(eccentricity[line[\"pos_target\"]])\n",
        "\n",
        "training_set[\"target_eccentricty\"] = training_set.progress_apply(target_eccentricty,axis=1)\n",
        "testing_set[\"target_eccentricty\"] = testing_set.progress_apply(target_eccentricty,axis=1)\n",
        "\n",
        "del(eccentricity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87400bf2",
      "metadata": {
        "id": "87400bf2"
      },
      "outputs": [],
      "source": [
        "# Distance\n",
        "dijsktra = nx.all_pairs_dijkstra_path_length(dg, cutoff=5)\n",
        "\n",
        "def shortest_path(line):\n",
        "    try:\n",
        "        return(dijsktra[line[\"source\"]][line[\"target\"]])\n",
        "    except:\n",
        "        return(6)\n",
        "\n",
        "training_set[\"shortest_path\"] = training_set.progress_apply(shortest_path,axis=1)\n",
        "testing_set[\"shortest_path\"] = testing_set.progress_apply(shortest_path,axis=1)\n",
        "\n",
        "del(dijsktra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17df4a0f",
      "metadata": {
        "id": "17df4a0f"
      },
      "outputs": [],
      "source": [
        "training_set.columns.to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb3d2cb9",
      "metadata": {
        "id": "fb3d2cb9"
      },
      "source": [
        "## Features based on graph topology for the author graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3cb79a",
      "metadata": {
        "id": "2b3cb79a"
      },
      "outputs": [],
      "source": [
        "#creation graph for author -> two authors are linked if one cites another\n",
        "auth_list = []\n",
        "\n",
        "for author_names in node_info[\"author\"]:\n",
        "    for name in author_names.split(\"_\"):\n",
        "        auth_list.append(name)\n",
        "        \n",
        "auth_list = set(auth_list)\n",
        "auth_list.remove(\"\")\n",
        "auth_list = list(auth_list)\n",
        "\n",
        "author_to_index = dict(zip(auth_list, range(len(auth_list))))\n",
        "\n",
        "g_author = igraph.Graph()\n",
        "g_author.add_vertices(len(auth_list))\n",
        "\n",
        "lst_edges = []\n",
        "\n",
        "auth_src_l, auth_tgt_l = training_set[\"author_source\"], training_set[\"author_target\"]\n",
        "for i in range(len(auth_src_l)):\n",
        "    auth_src = auth_src_l[i]\n",
        "    auth_tgt = auth_tgt_l[i]\n",
        "    \n",
        "    if auth_src != \"\" and auth_tgt != \"\":\n",
        "        auth_src = auth_src.split(\"_\")\n",
        "        auth_tgt = auth_tgt.split(\"_\")\n",
        "        for name_scr in auth_src:\n",
        "            for name_tgt in auth_tgt:\n",
        "                if name_scr != \"\" and name_tgt!=\"\" and not g_author.are_connected(author_to_index[name_scr], author_to_index[name_tgt]):\n",
        "                    lst_edges.append((author_to_index[name_scr], author_to_index[name_tgt]))\n",
        "\n",
        "lst_edges = list(set(lst_edges))\n",
        "g_author.add_edges(lst_edges)    \n",
        "print(\"author graph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4e7ae2",
      "metadata": {
        "id": "1d4e7ae2"
      },
      "outputs": [],
      "source": [
        "betweenness = g_author.betweenness()\n",
        "\n",
        "def auth_betweenness(elt):\n",
        "    auth_list = []\n",
        "    for name in elt.split(\"_\"):\n",
        "        auth_list.append(name)\n",
        "    l = []\n",
        "    for auth in auth_list:\n",
        "        if auth != \"\" and auth in author_to_index:\n",
        "            l.append(betweenness[author_to_index[auth]])\n",
        "        else:\n",
        "            l.append(0)\n",
        "    return max(l)\n",
        "\n",
        "training_set[\"betweenness_author_target\"] = training_set[\"author_target\"].progress_apply(auth_betweenness)\n",
        "testing_set[\"betweenness_author_target\"] = testing_set[\"author_target\"].progress_apply(auth_betweenness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7acf3b7f",
      "metadata": {
        "id": "7acf3b7f"
      },
      "outputs": [],
      "source": [
        "inlinks = g_author.indegree()\n",
        "\n",
        "def auth_inlinks(elt):\n",
        "    auth_list = []\n",
        "    for name in elt.split(\"_\"):\n",
        "        auth_list.append(name)\n",
        "    l = []\n",
        "    for auth in auth_list:\n",
        "        if auth != \"\" and auth in author_to_index:\n",
        "            l.append(inlinks[author_to_index[auth]])\n",
        "        else:\n",
        "            l.append(0)\n",
        "    return max(l)\n",
        "\n",
        "training_set[\"inlinks_author_target\"] = training_set[\"author_target\"].progress_apply(auth_inlinks)\n",
        "testing_set[\"inlinks_author_target\"] = testing_set[\"author_target\"].progress_apply(auth_inlinks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a69cdf6",
      "metadata": {
        "id": "6a69cdf6"
      },
      "source": [
        "## Semantic Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce8ce4d",
      "metadata": {
        "id": "6ce8ce4d"
      },
      "outputs": [],
      "source": [
        "# Cos similarity in Doc2Vec title\n",
        "\n",
        "def cos_similarity_title(line):\n",
        "    scal = vectorized_title[line[\"pos_source\"],:].dot(vectorized_title[line[\"pos_target\"],:].T)[0,0]\n",
        "    source = vectorized_title[line[\"pos_source\"],:].dot(vectorized_title[line[\"pos_source\"],:].T)[0,0]\n",
        "    target = vectorized_title[line[\"pos_target\"],:].dot(vectorized_title[line[\"pos_target\"],:].T)[0,0]\n",
        "    return(scal/np.sqrt(target*source))\n",
        "\n",
        "training_set[\"cos_similarity_title\"] = training_set.progress_apply(cos_similarity_title,axis=1)\n",
        "testing_set[\"cos_similarity_title\"] = testing_set.progress_apply(cos_similarity_title,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3130acd",
      "metadata": {
        "id": "e3130acd"
      },
      "outputs": [],
      "source": [
        "# Cos similarity in Doc2Vec description\n",
        "\n",
        "def cos_similarity_description(line):\n",
        "    scal = vectorized_desc[line[\"pos_source\"],:].dot(vectorized_desc[line[\"pos_target\"],:].T)[0,0]\n",
        "    source = vectorized_desc[line[\"pos_source\"],:].dot(vectorized_desc[line[\"pos_source\"],:].T)[0,0]\n",
        "    target = vectorized_desc[line[\"pos_target\"],:].dot(vectorized_desc[line[\"pos_target\"],:].T)[0,0]\n",
        "    return(scal/np.sqrt(target*source))\n",
        "\n",
        "training_set[\"cos_similarity_desc\"] = training_set.progress_apply(cos_similarity_description,axis=1)\n",
        "testing_set[\"cos_similarity_desc\"] = testing_set.progress_apply(cos_similarity_description,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16c8b485",
      "metadata": {
        "id": "16c8b485"
      },
      "source": [
        "## Attributes Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1b8446",
      "metadata": {
        "id": "ed1b8446"
      },
      "outputs": [],
      "source": [
        "def diff_in_year(line):\n",
        "    return(line[\"year_target\"]-line[\"year_source\"])\n",
        "\n",
        "training_set[\"diff_in_year\"] = training_set.progress_apply(diff_in_year,axis=1)\n",
        "testing_set[\"diff_in_year\"] = testing_set.progress_apply(diff_in_year,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52b2ba9a",
      "metadata": {
        "id": "52b2ba9a"
      },
      "outputs": [],
      "source": [
        "def nb_common_author(line):\n",
        "    set1 = list(set(line[\"author_source\"].split(\" \")))\n",
        "    set2 = list(set(line[\"author_target\"].split(\" \")))\n",
        "    \n",
        "    set1 = list(filter(lambda a: a != \"\" and a!=\" \", set1))\n",
        "    set2 = list(filter(lambda a: a != \"\" and a!=\" \", set2))\n",
        "    \n",
        "    count = 0\n",
        "    for word in set1:\n",
        "        for word2 in set2:\n",
        "            if word in word2 or word2 in word:\n",
        "                count += 1\n",
        "                break\n",
        "    return count\n",
        "\n",
        "\n",
        "training_set[\"author_nb_common\"] = training_set.progress_apply(nb_common_author,axis=1)\n",
        "testing_set[\"author_nb_common\"] = testing_set.progress_apply(nb_common_author,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ceec6a",
      "metadata": {
        "id": "68ceec6a"
      },
      "outputs": [],
      "source": [
        "def one_common_author(line):\n",
        "    set1 = list(set(line[\"author_source\"].split(\" \")))\n",
        "    set2 = list(set(line[\"author_target\"].split(\" \")))\n",
        "    \n",
        "    set1 = list(filter(lambda a: a != \"\" and a!=\" \", set1))\n",
        "    set2 = list(filter(lambda a: a != \"\" and a!=\" \", set2))\n",
        "    \n",
        "    for word in set1:\n",
        "        for word2 in set2:\n",
        "            if word in word2 or word2 in word:\n",
        "                return 1\n",
        "    return 0\n",
        "\n",
        "training_set[\"author_is_one_common\"] = training_set.progress_apply(one_common_author,axis=1)\n",
        "testing_set[\"author_is_one_common\"] = testing_set.progress_apply(one_common_author,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3145a1c",
      "metadata": {
        "id": "f3145a1c"
      },
      "outputs": [],
      "source": [
        "def nb_common_classification(line):\n",
        "    if line[\"classification_source\"]!=line[\"classification_source\"]:\n",
        "        return 0\n",
        "    if line[\"classification_target\"]!=line[\"classification_target\"]:\n",
        "        return 0\n",
        "    set1 = list(set(line[\"classification_source\"].split(\".\")))\n",
        "    set2 = list(set(line[\"classification_target\"].split(\".\")))\n",
        "    \n",
        "    set1 = list(filter(lambda a: a != \"\" and a!=\" \", set1))\n",
        "    set2 = list(filter(lambda a: a != \"\" and a!=\" \", set2))\n",
        "    count = 0\n",
        "    \n",
        "    for word in set1:\n",
        "        for word2 in set2:\n",
        "            if (word in word2 or word2 in word):\n",
        "                count += 1\n",
        "                break\n",
        "    return 2*count/(len(set1)+len(set2))\n",
        "\n",
        "training_set[\"common_classification\"] = training_set.progress_apply(nb_common_classification,axis=1)\n",
        "testing_set[\"common_classification\"] = testing_set.progress_apply(nb_common_classification,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c743e766",
      "metadata": {
        "id": "c743e766"
      },
      "outputs": [],
      "source": [
        "def one_common_word(line):\n",
        "    set1 = set(line[\"title_source\"].split(\" \"))\n",
        "    set2 = set(line[\"title_target\"].split(\" \"))\n",
        "    set1 = set(filter(lambda a: a != \"\" and a!=\" \", set1))\n",
        "    set2 = set(filter(lambda a: a != \"\" and a!=\" \", set2))\n",
        "    return 1 if len(set1 & set2)>0 else 0\n",
        "\n",
        "training_set[\"title_is_one_common\"] = training_set.progress_apply(one_common_word,axis=1)\n",
        "testing_set[\"title_is_one_common\"] = testing_set.progress_apply(one_common_word,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1ebaa9",
      "metadata": {
        "id": "3c1ebaa9"
      },
      "outputs": [],
      "source": [
        "def nb_common_word(line):\n",
        "    set1 = set(line[\"title_source\"].split(\" \"))\n",
        "    set2 = set(line[\"title_target\"].split(\" \"))\n",
        "    set1 = set(filter(lambda a: a != \"\" and a!=\" \", set1))\n",
        "    set2 = set(filter(lambda a: a != \"\" and a!=\" \", set2))\n",
        "    return len(set1 & set2)\n",
        "\n",
        "training_set[\"title_nb_common_word\"] = training_set.progress_apply(nb_common_word,axis=1)\n",
        "testing_set[\"title_nb_common_word\"] = testing_set.progress_apply(nb_common_word,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a82faa4",
      "metadata": {
        "id": "2a82faa4"
      },
      "outputs": [],
      "source": [
        "#pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7095296",
      "metadata": {
        "id": "e7095296"
      },
      "outputs": [],
      "source": [
        "#pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b662339",
      "metadata": {
        "id": "9b662339"
      },
      "outputs": [],
      "source": [
        "N_VECTORIZATION = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a33c5185",
      "metadata": {
        "id": "a33c5185"
      },
      "source": [
        "## Preparation of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a7b756",
      "metadata": {
        "id": "59a7b756"
      },
      "outputs": [],
      "source": [
        "path_to_data = \"data/\"\n",
        "\n",
        "training_set = pd.read_csv(path_to_data+\"improved_training_set.csv\")\n",
        "testing_set = pd.read_csv(path_to_data+\"improved_testing_set.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e00ad38",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c2b2fc3d512a4cc3bd6298a7aba87abe",
            "5ac4aacb2dff4459871c8c68399c0fcb"
          ]
        },
        "id": "2e00ad38",
        "outputId": "0c6f05d9-745f-48a0-db03-c9ce6892873f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2b2fc3d512a4cc3bd6298a7aba87abe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ac4aacb2dff4459871c8c68399c0fcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#def cos_similarity_title_1(line):\n",
        "#    scal = vectorized_title[line[\"pos_source\"],:].dot(vectorized_title[line[\"pos_target\"],:].T)\n",
        "#    source = vectorized_title[line[\"pos_source\"],:].dot(vectorized_title[line[\"pos_source\"],:].T)\n",
        "#    target = vectorized_title[line[\"pos_target\"],:].dot(vectorized_title[line[\"pos_target\"],:].T)\n",
        "#    return(scal/np.sqrt(target*source))\n",
        "\n",
        "#training_set[\"cos_similarity_title_1\"] = training_set.progress_apply(cos_similarity_title_1,axis=1)\n",
        "#testing_set[\"cos_similarity_title_1\"] = testing_set.progress_apply(cos_similarity_title_1,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#More Feature Engineering (with BERT)"
      ],
      "metadata": {
        "id": "Z4-fRfMVsYIp"
      },
      "id": "Z4-fRfMVsYIp"
    },
    {
      "cell_type": "markdown",
      "id": "e653c205",
      "metadata": {
        "id": "e653c205"
      },
      "source": [
        "### creating sentence embeddings of titles with BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e71f2ee",
      "metadata": {
        "id": "5e71f2ee"
      },
      "outputs": [],
      "source": [
        "#######\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import re\n",
        "\n",
        "documents_df=pd.DataFrame(list(node_info.title),columns=['documents'])\n",
        "\n",
        "stop_words_l=stopwords.words('english')\n",
        "documents_df['documents_cleaned']=documents_df.documents.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
        "\n",
        "#pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "sentence_embeddings = sbert_model.encode(documents_df['documents_cleaned'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2983257e",
      "metadata": {
        "id": "2983257e"
      },
      "source": [
        "### cos similarity of titles with BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c63446",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c443812ffc994031ac0a1467dbb520d6",
            "244e7da997eb4701b1a3da5922db5c20"
          ]
        },
        "id": "d0c63446",
        "outputId": "769e7b23-b7e7-4a40-df56-576601a9649c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c443812ffc994031ac0a1467dbb520d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "244e7da997eb4701b1a3da5922db5c20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def cos_similarity_title_2(line):\n",
        "    scal = sentence_embeddings[line[\"pos_source\"],:].dot(sentence_embeddings[line[\"pos_target\"],:].T)\n",
        "    source = sentence_embeddings[line[\"pos_source\"],:].dot(sentence_embeddings[line[\"pos_source\"],:].T)\n",
        "    target = sentence_embeddings[line[\"pos_target\"],:].dot(sentence_embeddings[line[\"pos_target\"],:].T)\n",
        "    return(scal/np.sqrt(target*source))\n",
        "\n",
        "training_set[\"cos_similarity_title_2\"] = training_set.progress_apply(cos_similarity_title_2,axis=1)\n",
        "testing_set[\"cos_similarity_title_2\"] = testing_set.progress_apply(cos_similarity_title_2,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01fc3a38",
      "metadata": {
        "id": "01fc3a38"
      },
      "source": [
        "### Euclidean distance of titles with tfidf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f2f7d7",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "684c7fd9bed449ed922c88d4450665ad",
            "4d77cb5d0a4c43fbb796647b4868bc68"
          ]
        },
        "id": "34f2f7d7",
        "outputId": "1ebec50a-7ac2-4b47-a0e4-360a9a8f1cff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "684c7fd9bed449ed922c88d4450665ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d77cb5d0a4c43fbb796647b4868bc68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def euc_dis_title_tfidf(line):\n",
        "    scal = vectorized_title[line[\"pos_source\"],:].dot(vectorized_title[line[\"pos_target\"],:].T)[0,0]\n",
        "    source = vectorized_title[line[\"pos_source\"],:].dot(vectorized_title[line[\"pos_source\"],:].T)[0,0]\n",
        "    target = vectorized_title[line[\"pos_target\"],:].dot(vectorized_title[line[\"pos_target\"],:].T)[0,0]\n",
        "    return(np.sqrt(source - 2 * scal + target))\n",
        "\n",
        "training_set[\"euc_dis_title_tfidf\"] = training_set.progress_apply(euc_dis_title_tfidf,axis=1)\n",
        "testing_set[\"euc_dis_title_tfidf\"] = testing_set.progress_apply(euc_dis_title_tfidf,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bf158fd",
      "metadata": {
        "id": "7bf158fd"
      },
      "source": [
        "### Euclidean distance of titles with BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ab7c0e",
      "metadata": {
        "id": "25ab7c0e"
      },
      "outputs": [],
      "source": [
        "def euc_dis_title_bert(line):\n",
        "    scal = sentence_embeddings[line[\"pos_source\"],:].dot(sentence_embeddings[line[\"pos_target\"],:].T)\n",
        "    source = sentence_embeddings[line[\"pos_source\"],:].dot(sentence_embeddings[line[\"pos_source\"],:].T)\n",
        "    target = sentence_embeddings[line[\"pos_target\"],:].dot(sentence_embeddings[line[\"pos_target\"],:].T)\n",
        "    return(np.sqrt(source - 2 * scal + target))\n",
        "\n",
        "training_set[\"euc_dis_title_bert\"] = training_set.progress_apply(euc_dis_title_bert,axis=1)\n",
        "testing_set[\"euc_dis_title_bert\"] = testing_set.progress_apply(euc_dis_title_bert,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c2d714f",
      "metadata": {
        "id": "1c2d714f"
      },
      "source": [
        "### creating sentence embeddings of descriptions with BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da2873e",
      "metadata": {
        "id": "2da2873e"
      },
      "outputs": [],
      "source": [
        "documents_df=pd.DataFrame(list(node_info.description),columns=['documents'])\n",
        "\n",
        "stop_words_l=stopwords.words('english')\n",
        "documents_df['documents_cleaned']=documents_df.documents.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )\n",
        "\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "sentence_embeddings_des = sbert_model.encode(documents_df['documents_cleaned'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee25cace",
      "metadata": {
        "id": "ee25cace"
      },
      "source": [
        "### cos similarity of descriptions with BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6d2ca1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "302932ccb77347e8894366f334c04b49",
            "c3cd2ecdc2a04d32955c85e44572d2e5"
          ]
        },
        "id": "0f6d2ca1",
        "outputId": "c3efb2d3-62ac-4655-8b39-e7bf4711ef7f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "302932ccb77347e8894366f334c04b49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3cd2ecdc2a04d32955c85e44572d2e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cos similarity in Doc2Vec description\n",
        "\n",
        "def cos_similarity_description_1(line):\n",
        "    scal = sentence_embeddings_des[line[\"pos_source\"],:].dot(sentence_embeddings_des[line[\"pos_target\"],:].T)\n",
        "    source = sentence_embeddings_des[line[\"pos_source\"],:].dot(sentence_embeddings_des[line[\"pos_source\"],:].T)\n",
        "    target = sentence_embeddings_des[line[\"pos_target\"],:].dot(sentence_embeddings_des[line[\"pos_target\"],:].T)\n",
        "    return(scal/np.sqrt(target*source))\n",
        "\n",
        "training_set[\"cos_similarity_desc_1\"] = training_set.progress_apply(cos_similarity_description_1,axis=1)\n",
        "testing_set[\"cos_similarity_desc_1\"] = testing_set.progress_apply(cos_similarity_description_1,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3feaf15",
      "metadata": {
        "id": "c3feaf15"
      },
      "source": [
        "### Euclidaen distance of descriptions (BERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a908774",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "de57d16fe56d4a6b91fc7693383c3253",
            "07932a333167468694a5a4f1f357e288"
          ]
        },
        "id": "7a908774",
        "outputId": "7a2c5a21-f5ce-4180-e22b-55fc6f5ef2a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de57d16fe56d4a6b91fc7693383c3253",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07932a333167468694a5a4f1f357e288",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def euc_dis_description_bert(line):\n",
        "    scal = sentence_embeddings_des[line[\"pos_source\"],:].dot(sentence_embeddings_des[line[\"pos_target\"],:].T)\n",
        "    source = sentence_embeddings_des[line[\"pos_source\"],:].dot(sentence_embeddings_des[line[\"pos_source\"],:].T)\n",
        "    target = sentence_embeddings_des[line[\"pos_target\"],:].dot(sentence_embeddings_des[line[\"pos_target\"],:].T)\n",
        "    return(np.sqrt(source - 2 * scal + target))\n",
        "\n",
        "training_set[\"euc_dis_desc_bert\"] = training_set.progress_apply(euc_dis_description_bert,axis=1)\n",
        "testing_set[\"euc_dis_desc_bert\"] = testing_set.progress_apply(euc_dis_description_bert,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122f2794",
      "metadata": {
        "id": "122f2794"
      },
      "outputs": [],
      "source": [
        "# attach word_movers\n",
        "dist_wordmovers_title_train = pd.read_csv(\"dist_wordmovers_title_train.csv\")\n",
        "dist_wordmovers_title_test = pd.read_csv(\"dist_wordmovers_title_test.csv\")\n",
        "\n",
        "frames = [training_set, dist_wordmovers_title_train['dist_wordmovers_title']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "training_set = result\n",
        "frames = [testing_set, dist_wordmovers_title_test['dist_wordmovers_title']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "testing_set = result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51ab281",
      "metadata": {
        "id": "f51ab281"
      },
      "source": [
        "### eigenvector centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc0d3d7",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ddcde6a2881d44edb866e95b65dcdffc",
            "672e3a166a024aca9fb1d90de3501e4d"
          ]
        },
        "id": "bbc0d3d7",
        "outputId": "86d49788-afc3-4eec-9ae8-50db05459de6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddcde6a2881d44edb866e95b65dcdffc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "672e3a166a024aca9fb1d90de3501e4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "eig = ig.eigenvector_centrality()\n",
        "\n",
        "training_set[\"eigenvector_source\"] = training_set[\"pos_source\"].progress_apply(lambda x : eig[x])\n",
        "testing_set[\"eigenvector_source\"] = testing_set[\"pos_source\"].progress_apply(lambda x : eig[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cb449d",
      "metadata": {
        "id": "66cb449d"
      },
      "source": [
        "### Page rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac74068",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "22747fa3457a4e008e3232619571566b",
            "1f13ef75eef34a78a0a275f7b8ae2d52"
          ]
        },
        "id": "6ac74068",
        "outputId": "5a130fc4-1e97-4382-c31c-8ace4470c20d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22747fa3457a4e008e3232619571566b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f13ef75eef34a78a0a275f7b8ae2d52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Page Rank\n",
        "page_rank = ig.pagerank()\n",
        "\n",
        "training_set[\"Page_rank\"] = training_set[\"pos_source\"].progress_apply(lambda x : page_rank[x])\n",
        "testing_set[\"Page_rank\"] = testing_set[\"pos_source\"].progress_apply(lambda x : page_rank[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca812462",
      "metadata": {
        "id": "ca812462"
      },
      "source": [
        "### HITS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f206b1",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "80b6150a639c4da9a2492d85a45a771b",
            "ea1f7112f46a4d9aa3cd633f6bce117c",
            "3ec45ac268fb4c6b8eac7ae2f8122e75",
            "fe1480bba16f4fee9892ecb9b61af4c4"
          ]
        },
        "id": "a0f206b1",
        "outputId": "7908b379-a691-478c-860f-db283a7c3a75"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80b6150a639c4da9a2492d85a45a771b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea1f7112f46a4d9aa3cd633f6bce117c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ec45ac268fb4c6b8eac7ae2f8122e75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe1480bba16f4fee9892ecb9b61af4c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# HITS algorithm\n",
        "hub_score, authority_score = nx.hits(g)\n",
        "\n",
        "training_set[\"hub_score\"] = training_set[\"source\"].progress_apply(lambda x : hub_score[x])\n",
        "training_set[\"authority_score\"] = training_set[\"target\"].progress_apply(lambda x : authority_score[x])\n",
        "\n",
        "testing_set[\"hub_score\"] = testing_set[\"source\"].progress_apply(lambda x : hub_score[x])\n",
        "testing_set[\"authority_score\"] = testing_set[\"target\"].progress_apply(lambda x : authority_score[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec99561",
      "metadata": {
        "id": "9ec99561"
      },
      "outputs": [],
      "source": [
        "hits = nx.hits(g, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
        "\n",
        "training_set['hubs_s'] = training_set.source.apply(lambda x: hits[0].get(x,0))\n",
        "training_set['hubs_d'] = training_set.target.apply(lambda x: hits[0].get(x,0))\n",
        "training_set['authorities_s'] = training_set.source.apply(lambda x: hits[1].get(x,0))\n",
        "training_set['authorities_d'] = training_set.target.apply(lambda x: hits[1].get(x,0))\n",
        "\n",
        "\n",
        "testing_set['hubs_s'] = testing_set.source.apply(lambda x: hits[0].get(x,0))\n",
        "testing_set['hubs_d'] = testing_set.target.apply(lambda x: hits[0].get(x,0))\n",
        "testing_set['authorities_s'] = testing_set.source.apply(lambda x: hits[1].get(x,0))\n",
        "testing_set['authorities_d'] = testing_set.target.apply(lambda x: hits[1].get(x,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afbba0b0",
      "metadata": {
        "id": "afbba0b0"
      },
      "source": [
        "### en_core_web_lg, spacy model for similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e620fee6",
      "metadata": {
        "id": "e620fee6"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d8c7aa",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "87abe9b01522454d91d036e4405def06",
            "476bfe4503cb4cc8b2b45b846f573008"
          ]
        },
        "id": "19d8c7aa",
        "outputId": "c0a157eb-3036-4769-dc8b-7fb4d299ced7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87abe9b01522454d91d036e4405def06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\AppData\\Local\\Temp/ipykernel_31804/3754972098.py:4: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  return(title_t.similarity(title_s))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476bfe4503cb4cc8b2b45b846f573008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def en_core(line):\n",
        "    title_s = nlp(line['title_source'])\n",
        "    title_t = nlp(line['title_target'])\n",
        "    return(title_t.similarity(title_s))\n",
        "\n",
        "training_set[\"en_core\"] = training_set.progress_apply(en_core,axis=1)\n",
        "testing_set[\"en_core\"] = testing_set.progress_apply(en_core,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99358684",
      "metadata": {
        "id": "99358684"
      },
      "outputs": [],
      "source": [
        "training_set[\"en_core\"].to_csv('en_core_train.csv')\n",
        "testing_set[\"en_core\"].to_csv('en_core_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200503c5",
      "metadata": {
        "id": "200503c5"
      },
      "outputs": [],
      "source": [
        "# attach en_core_web_lg to the training set\n",
        "en_core_train = pd.read_csv(\"en_core_train.csv\")\n",
        "en_core_test = pd.read_csv(\"en_core_test.csv\")\n",
        "\n",
        "frames = [training_set, en_core_train['en_core']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "training_set = result\n",
        "frames = [testing_set, en_core_test['en_core']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "testing_set = result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f8de20f",
      "metadata": {
        "id": "3f8de20f"
      },
      "source": [
        "### Allocation, Adamic-Adar, Preferential, Jaccard coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a25853",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "02756847f7064363a7e623b0a793379c",
            "e9e83e6e37df41d6a8f28f80575f5c05",
            "c2593b78ab2f48e1b935e21d48ecfb23",
            "c69a89e6b83c4590a2c51c515170f121",
            "c8d1cde23ff34138af15edd1589c7e78",
            "62ab74fb91b742b180b6caaf199839c3",
            "b3a84c2474d84ad885bb677356154385",
            "fa34acdded0a4475a613b21dafea07cf"
          ]
        },
        "id": "d8a25853",
        "outputId": "33eb18aa-10f4-4bd1-f1c8-b84a1445a838"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02756847f7064363a7e623b0a793379c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e83e6e37df41d6a8f28f80575f5c05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2593b78ab2f48e1b935e21d48ecfb23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c69a89e6b83c4590a2c51c515170f121",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8d1cde23ff34138af15edd1589c7e78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62ab74fb91b742b180b6caaf199839c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3a84c2474d84ad885bb677356154385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa34acdded0a4475a613b21dafea07cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def alloca(line):\n",
        "    a = line['source']\n",
        "    b = line['target']\n",
        "    allocation = nx.resource_allocation_index(g, [(a, b)])\n",
        "    for u,v,p in allocation:\n",
        "        score = p\n",
        "    return score\n",
        "def adamic_adar(line):\n",
        "    a = line['source']\n",
        "    b = line['target']\n",
        "    adamic = nx.adamic_adar_index(g, [(a, b)])\n",
        "    for u,v,p in adamic:\n",
        "        score = p\n",
        "    return score\n",
        "def preferential(line):\n",
        "    a = line['source']\n",
        "    b = line['target']\n",
        "    prefer = nx.preferential_attachment(g, [(a, b)])\n",
        "    for u,v,p in prefer:\n",
        "        score = p\n",
        "    return score\n",
        "def jaccard_coef(line):\n",
        "    a = line['source']\n",
        "    b = line['target']\n",
        "    jaccard = nx.jaccard_coefficient(g, [(a, b)])\n",
        "    for u,v,p in jaccard:\n",
        "        score = p\n",
        "    return score\n",
        "    \n",
        "    \n",
        "training_set[\"allocation\"] = training_set.progress_apply(alloca,axis=1)\n",
        "training_set[\"adamic_adar\"] = training_set.progress_apply(adamic_adar,axis=1)\n",
        "training_set[\"preferential\"] = training_set.progress_apply(preferential,axis=1)\n",
        "training_set[\"jaccard_coef\"] = training_set.progress_apply(jaccard_coef,axis=1)\n",
        "\n",
        "testing_set[\"allocation\"] = testing_set.progress_apply(alloca,axis=1)\n",
        "testing_set[\"adamic_adar\"] = testing_set.progress_apply(adamic_adar,axis=1)\n",
        "testing_set[\"preferential\"] = testing_set.progress_apply(preferential,axis=1)\n",
        "testing_set[\"jaccard_coef\"] = testing_set.progress_apply(jaccard_coef,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dceb29e",
      "metadata": {
        "id": "0dceb29e"
      },
      "source": [
        "### Jaccard, cos for followees and followers, shortest path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c8cb9af",
      "metadata": {
        "id": "1c8cb9af"
      },
      "outputs": [],
      "source": [
        "#for followees\n",
        "import math\n",
        "def jaccard_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(dg.successors(a))) == 0  | len(set(dg.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(dg.successors(a)).intersection(set(dg.successors(b)))))/\\\n",
        "                                    (len(set(dg.successors(a)).union(set(dg.successors(b)))))\n",
        "    except:\n",
        "        return 0\n",
        "    return sim\n",
        "\n",
        "def jaccard_for_followers(a,b):\n",
        "    try:\n",
        "        if len(set(dg.predecessors(a))) == 0  | len(set(dg.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(dg.predecessors(a)).intersection(set(dg.predecessors(b)))))/\\\n",
        "                                 (len(set(dg.predecessors(a)).union(set(dg.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0\n",
        "    \n",
        "#for followees\n",
        "def cosine_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(dg.successors(a))) == 0  | len(set(dg.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(dg.successors(a)).intersection(set(dg.successors(b)))))/\\\n",
        "                                    (math.sqrt(len(set(dg.successors(a)))*len((set(dg.successors(b))))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0\n",
        "def cosine_for_followers(a,b):\n",
        "    try:\n",
        "        \n",
        "        if len(set(dg.predecessors(a))) == 0  | len(set(dg.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(dg.predecessors(a)).intersection(set(dg.predecessors(b)))))/\\\n",
        "                                     (math.sqrt(len(set(dg.predecessors(a))))*(len(set(dg.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0\n",
        "def compute_shortest_path_length(a,b):\n",
        "    p=-1\n",
        "    try:\n",
        "        if dg.has_edge(a,b):\n",
        "            dg.remove_edge(a,b)\n",
        "            p= nx.shortest_path_length(dg,source=a,target=b)\n",
        "            dg.add_edge(a,b)\n",
        "        else:\n",
        "            p= nx.shortest_path_length(dg,source=a,target=b)\n",
        "        return p\n",
        "    except:\n",
        "        return -1\n",
        "    \n",
        "#getting weakly connected edges from graph \n",
        "wcc=list(nx.weakly_connected_components(dg))\n",
        "def belongs_to_same_wcc(a,b):\n",
        "    index = []\n",
        "    if dg.has_edge(b,a):\n",
        "        return 1\n",
        "    if dg.has_edge(a,b):\n",
        "            for i in wcc:\n",
        "                if a in i:\n",
        "                    index= i\n",
        "                    break\n",
        "            if (b in index):\n",
        "                dg.remove_edge(a,b)\n",
        "                if compute_shortest_path_length(a,b)==-1:\n",
        "                    dg.add_edge(a,b)\n",
        "                    return 0\n",
        "                else:\n",
        "                    dg.add_edge(a,b)\n",
        "                    return 1\n",
        "            else:\n",
        "                return 0\n",
        "    else:\n",
        "            for i in wcc:\n",
        "                if a in i:\n",
        "                    index= i\n",
        "                    break\n",
        "            if(b in index):\n",
        "                return 1\n",
        "            else:\n",
        "                return 0\n",
        "def follows_back(a,b):\n",
        "    if dg.has_edge(b,a):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca9706ea",
      "metadata": {
        "id": "ca9706ea"
      },
      "source": [
        "### katz_centrality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375c9c5f",
      "metadata": {
        "id": "375c9c5f"
      },
      "outputs": [],
      "source": [
        "katz = nx.katz.katz_centrality(g,alpha=0.005,beta=1)\n",
        "pr = nx.pagerank(g, alpha=0.85)\n",
        "mean_pr=float(sum(pr.values())) / len(pr)\n",
        "mean_katz = float(sum(katz.values())) / len(katz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bf7e7d",
      "metadata": {
        "id": "30bf7e7d"
      },
      "outputs": [],
      "source": [
        "training_set['jaccard_followers'] = training_set.apply(lambda row:jaccard_for_followers(row['source'],row['target']),axis=1)\n",
        "training_set['jaccard_followees'] = training_set.apply(lambda row:jaccard_for_followees(row['source'],row['target']),axis=1)\n",
        "training_set['cosine_followers'] = training_set.apply(lambda row: cosine_for_followers(row['source'],row['target']),axis=1)\n",
        "training_set['cosine_followees'] = training_set.apply(lambda row: cosine_for_followees(row['source'],row['target']),axis=1)\n",
        "training_set['follows_back'] = training_set.apply(lambda row: follows_back(row['source'],row['target']),axis=1)\n",
        "training_set['same_comp'] = training_set.apply(lambda row: belongs_to_same_wcc(row['source'],row['target']),axis=1)\n",
        "training_set['shortest_path'] = training_set.apply(lambda row: compute_shortest_path_length(row['source'],row['target']),axis=1)\n",
        "training_set['page_rank_s'] = training_set.source.apply(lambda x:pr.get(x,mean_pr))\n",
        "training_set['page_rank_d'] = training_set.target.apply(lambda x:pr.get(x,mean_pr))\n",
        "training_set['katz_s'] = training_set.source.apply(lambda x: katz.get(x,mean_katz))\n",
        "training_set['katz_d'] = training_set.target.apply(lambda x: katz.get(x,mean_katz))\n",
        "\n",
        "testing_set['jaccard_followers'] = testing_set.apply(lambda row:jaccard_for_followers(row['source'],row['target']),axis=1)\n",
        "testing_set['jaccard_followees'] = testing_set.apply(lambda row:jaccard_for_followees(row['source'],row['target']),axis=1)\n",
        "testing_set['cosine_followers'] = testing_set.apply(lambda row: cosine_for_followers(row['source'],row['target']),axis=1)\n",
        "testing_set['cosine_followees'] = testing_set.apply(lambda row: cosine_for_followees(row['source'],row['target']),axis=1)\n",
        "testing_set['follows_back'] = testing_set.apply(lambda row: follows_back(row['source'],row['target']),axis=1)\n",
        "testing_set['same_comp'] = testing_set.apply(lambda row: belongs_to_same_wcc(row['source'],row['target']),axis=1)\n",
        "testing_set['shortest_path'] = testing_set.apply(lambda row: compute_shortest_path_length(row['source'],row['target']),axis=1)\n",
        "testing_set['page_rank_s'] = testing_set.source.apply(lambda x:pr.get(x,mean_pr))\n",
        "testing_set['page_rank_d'] = testing_set.target.apply(lambda x:pr.get(x,mean_pr))\n",
        "testing_set['katz_s'] = testing_set.source.apply(lambda x: katz.get(x,mean_katz))\n",
        "testing_set['katz_d'] = testing_set.target.apply(lambda x: katz.get(x,mean_katz))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9489c6ec",
      "metadata": {
        "id": "9489c6ec"
      },
      "source": [
        "### num of follwers and followees\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a41f7fc",
      "metadata": {
        "id": "6a41f7fc"
      },
      "outputs": [],
      "source": [
        "def compute_features_stage1(training_set):\n",
        "    num_followers_s=[]\n",
        "    num_followees_s=[]\n",
        "    num_followers_d=[]\n",
        "    num_followees_d=[]\n",
        "    inter_followers=[]\n",
        "    inter_followees=[]\n",
        "    for i,row in training_set.iterrows():\n",
        "        try:\n",
        "            s1=set(dg.predecessors(row['source']))\n",
        "            s2=set(dg.successors(row['source']))\n",
        "        except:\n",
        "            s1 = set()\n",
        "            s2 = set()\n",
        "        try:\n",
        "            d1=set(dg.predecessors(row['target']))\n",
        "            d2=set(dg.successors(row['target']))\n",
        "        except:\n",
        "            d1 = set()\n",
        "            d2 = set()\n",
        "        num_followers_s.append(len(s1))\n",
        "        num_followees_s.append(len(s2))\n",
        "\n",
        "        num_followers_d.append(len(d1))\n",
        "        num_followees_d.append(len(d2))\n",
        "\n",
        "        inter_followers.append(len(s1.intersection(d1)))\n",
        "        inter_followees.append(len(s2.intersection(d2)))\n",
        "    \n",
        "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09958065",
      "metadata": {
        "id": "09958065"
      },
      "outputs": [],
      "source": [
        "training_set['num_followers_s'], training_set['num_followers_d'], \\\n",
        "training_set['num_followees_s'], training_set['num_followees_d'], \\\n",
        "training_set['inter_followers'], training_set['inter_followees'] = compute_features_stage1(training_set)\n",
        "\n",
        "testing_set['num_followers_s'], testing_set['num_followers_d'], \\\n",
        "testing_set['num_followees_s'], testing_set['num_followees_d'], \\\n",
        "testing_set['inter_followers'], testing_set['inter_followees'] = compute_features_stage1(testing_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b2f1f7",
      "metadata": {
        "id": "a3b2f1f7"
      },
      "outputs": [],
      "source": [
        "# dimension of vector (word embedding)\n",
        "#frames = [training_set, new_train]\n",
        "#result = pd.concat(frames, axis=1)\n",
        "#training_set = result\n",
        "\n",
        "#frames = [testing_set, new_test]\n",
        "#result = pd.concat(frames, axis=1)\n",
        "#testing_set = result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8af2c7fa",
      "metadata": {
        "id": "8af2c7fa"
      },
      "source": [
        "### Harmonic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b8cc1f",
      "metadata": {
        "id": "78b8cc1f"
      },
      "outputs": [],
      "source": [
        "harmonic = nx.harmonic_centrality(g)\n",
        "#(pd.DataFrame.from_dict(data=harmonic, orient='index').to_csv('harmonic_1.csv', header=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f59f0d03",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7ffd3ca7d8894d36b9cd63dac538ebee",
            "bbbb2a262c91421d96d9cce0a3c907bb",
            "8ff6468bd5104999b21cd6cc711c199b",
            "eb9982728e9e43749d52a84afeafeb6c"
          ]
        },
        "id": "f59f0d03",
        "outputId": "9d8d551d-5b6f-4162-e60a-5ca0ea822342"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ffd3ca7d8894d36b9cd63dac538ebee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbbb2a262c91421d96d9cce0a3c907bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/615512 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ff6468bd5104999b21cd6cc711c199b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb9982728e9e43749d52a84afeafeb6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32648 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_set[\"harmonic_s\"] = training_set[\"source\"].progress_apply(lambda x : harmonic[x])\n",
        "training_set[\"harmonic_t\"] = training_set[\"target\"].progress_apply(lambda x : harmonic[x])\n",
        "\n",
        "testing_set[\"harmonic_s\"] = testing_set[\"source\"].progress_apply(lambda x : harmonic[x])\n",
        "testing_set[\"harmonic_t\"] = testing_set[\"target\"].progress_apply(lambda x : harmonic[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f65875f7",
      "metadata": {
        "id": "f65875f7"
      },
      "source": [
        "### jaccard between words in descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20e9ef8",
      "metadata": {
        "id": "d20e9ef8"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def calculate_jaccard(word_tokens1, word_tokens2):\n",
        "    both_tokens = word_tokens1 + word_tokens2\n",
        "    union = set(both_tokens)\n",
        "\n",
        "# Calculate intersection.\n",
        "    intersection = set()\n",
        "    for w in word_tokens1:\n",
        "        if w in word_tokens2:\n",
        "            intersection.add(w)\n",
        "\n",
        "    jaccard_score = len(intersection)/len(union)\n",
        "    return jaccard_score\n",
        "\n",
        "def desc_jaccard(line):\n",
        "    a = word_tokenize(line['description_source'])\n",
        "    b = word_tokenize(line['description_target'])\n",
        "    return calculate_jaccard(a,b)\n",
        "\n",
        "training_set['desc_jaccard'] = training_set.progress_apply(desc_jaccard,axis=1)\n",
        "testing_set['desc_jaccard'] = testing_set.progress_apply(desc_jaccard,axis=1)\n",
        "training_set['desc_jaccard'].to_csv('desc_jacc_train.csv')\n",
        "testing_set['desc_jaccard'].to_csv('desc_jacc_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c47a92ef",
      "metadata": {
        "id": "c47a92ef"
      },
      "source": [
        "### Universal Sentence Encoder's TF Hub module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf350eae",
      "metadata": {
        "id": "bf350eae"
      },
      "outputs": [],
      "source": [
        "# Make all the capital letters small\n",
        "node_info['n_desc'] = node_info['description'].str.lower()\n",
        "node_info['n_desc'] = node_info['n_desc'].apply(lambda x: clean_data(x)) \n",
        "for x in node_info['n_desc']:\n",
        "    x = re.sub('[^a-zA-Z]', ' ', x)\n",
        "node_info['n_desc'] = node_info['n_desc'].apply(lambda x: re.sub('\\W+', ' ', x))\n",
        "node_info['n_desc'] = node_info['n_desc'].apply(lambda x: lemmatization(x))\n",
        "node_info['n_desc'] = node_info['n_desc'].apply(lambda x: clean_stop(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebb05c2",
      "metadata": {
        "id": "3ebb05c2"
      },
      "outputs": [],
      "source": [
        "#title Load the Universal Sentence Encoder's TF Hub module\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import seaborn as sns\n",
        "\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
        "model = hub.load(module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4561513f",
      "metadata": {
        "id": "4561513f"
      },
      "outputs": [],
      "source": [
        "def process_text(text):\n",
        "    text = text.encode('ascii', errors='ignore').decode()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', ' ', text)\n",
        "    text = re.sub(r'#+', ' ', text )\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text)\n",
        "    text = re.sub(r\"([A-Za-z]+)'s\", r\"\\1 is\", text)\n",
        "    #text = re.sub(r\"\\'s\", \" \", text)     text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"won't\", \"will not \", text)\n",
        "    text = re.sub(r\"isn't\", \"is not \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d041d76",
      "metadata": {
        "id": "7d041d76"
      },
      "outputs": [],
      "source": [
        "def universal(line):\n",
        "    source = line['n_desc']\n",
        "    temp = []\n",
        "    temp.append(process_text(source))\n",
        "    embeddings = model(temp)\n",
        "    return embeddings[0]\n",
        "\n",
        "node_info['universal'] = node_info.progress_apply(universal, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9e15a0",
      "metadata": {
        "id": "2a9e15a0"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    mag1 = np.linalg.norm(v1)\n",
        "    mag2 = np.linalg.norm(v2)\n",
        "    if (not mag1) or (not mag2):\n",
        "        return 0\n",
        "    return np.dot(v1, v2) / (mag1 * mag2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eebd0f7",
      "metadata": {
        "id": "4eebd0f7"
      },
      "outputs": [],
      "source": [
        "def univ(line):\n",
        "    pos_source = line['pos_source']\n",
        "    pos_target = line['pos_target']\n",
        "    vec1 = node_info['universal'][pos_source]\n",
        "    vec2 = node_info['universal'][pos_target]\n",
        "    return cosine_similarity(vec1, vec2)\n",
        "\n",
        "training_set['universal'] = training_set.progress_apply(univ, axis = 1)\n",
        "testing_set['universal'] = testing_set.progress_apply(univ, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c1fae5",
      "metadata": {
        "id": "b1c1fae5"
      },
      "source": [
        "#Load improved DataSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "539e1060",
      "metadata": {
        "id": "539e1060"
      },
      "outputs": [],
      "source": [
        "#training_set.to_csv(path_to_data+\"improved_training_set_3.csv\")\n",
        "#testing_set.to_csv(path_to_data+\"improved_testing_set_3.csv\")\n",
        "path_to_data = \"data/\"\n",
        "\n",
        "training_set = pd.read_csv(path_to_data+\"improved_training_set_3.csv\")\n",
        "testing_set = pd.read_csv(path_to_data+\"improved_testing_set_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1268fef",
      "metadata": {
        "id": "f1268fef"
      },
      "outputs": [],
      "source": [
        "# attach universal\n",
        "univ_train = pd.read_csv(\"universal_train.csv\")\n",
        "univ_test = pd.read_csv(\"universal_test.csv\")\n",
        "\n",
        "frames = [training_set, univ_train['universal']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "training_set = result\n",
        "frames = [testing_set, univ_test['universal']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "testing_set = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995eabe2",
      "metadata": {
        "id": "995eabe2"
      },
      "outputs": [],
      "source": [
        "# attach jaccard\n",
        "desc_jacc_train = pd.read_csv(\"desc_jacc_train.csv\")\n",
        "desc_jacc_test = pd.read_csv(\"desc_jacc_test.csv\")\n",
        "\n",
        "frames = [training_set, desc_jacc_train['desc_jaccard']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "training_set = result\n",
        "frames = [testing_set, desc_jacc_test['desc_jaccard']]\n",
        "result = pd.concat(frames, axis=1)\n",
        "testing_set = result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a30a09d",
      "metadata": {
        "id": "8a30a09d"
      },
      "source": [
        "### correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ee941b",
      "metadata": {
        "id": "a1ee941b",
        "outputId": "6fd1c5fb-7b7c-44f7-e920-a4cbf1d7626d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label                        1.000000\n",
              "common_neighbor              0.911748\n",
              "same_cluster                 0.001237\n",
              "jaccard                      0.581025\n",
              "diff_in_bc                   0.136187\n",
              "diff_in_inlinks              0.205395\n",
              "diff_in_year                -0.298960\n",
              "author_nb_common             0.130071\n",
              "author_is_one_common         0.145108\n",
              "common_classification        0.156298\n",
              "title_is_one_common          0.200877\n",
              "title_nb_common_word         0.285134\n",
              "cos_similarity_title         0.343256\n",
              "cos_similarity_desc          0.559010\n",
              "cos_similarity_title_2       0.206094\n",
              "cos_similarity_desc_1        0.308578\n",
              "euc_dis_title_bert          -0.221648\n",
              "euc_dis_desc_bert           -0.322953\n",
              "target_eccentricty          -0.202825\n",
              "betweenness_author_target    0.142262\n",
              "inlinks_author_target        0.214047\n",
              "en_core                      0.178434\n",
              "hub_score                    0.219285\n",
              "authority_score              0.249057\n",
              "hubs_s                       0.219285\n",
              "hubs_d                       0.249057\n",
              "authorities_s                0.219285\n",
              "authorities_d                0.249057\n",
              "allocation                   0.461592\n",
              "adamic_adar                  0.500275\n",
              "preferential                 0.182953\n",
              "jaccard_coef                 0.581308\n",
              "harmonic_s                   0.379173\n",
              "harmonic_t                   0.437187\n",
              "jaccard_followers            0.368592\n",
              "jaccard_followees            0.499867\n",
              "cosine_followers             0.326241\n",
              "cosine_followees             0.563644\n",
              "follows_back                 0.034610\n",
              "same_comp                   -0.148372\n",
              "page_rank_s                  0.150896\n",
              "page_rank_d                  0.255060\n",
              "katz_s                       0.232315\n",
              "katz_d                       0.276317\n",
              "num_followers_s              0.082077\n",
              "num_followers_d              0.250508\n",
              "num_followees_s              0.301282\n",
              "num_followees_d              0.150739\n",
              "inter_followers              0.232348\n",
              "inter_followees              0.425478\n",
              "universal                    0.439651\n",
              "desc_jaccard                 0.526667\n",
              "Name: label, dtype: float64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set[['label', 'common_neighbor', 'same_cluster', 'jaccard', 'diff_in_bc',\n",
        "             'diff_in_inlinks', 'diff_in_year', 'author_nb_common','author_is_one_common',\n",
        "             'common_classification', 'title_is_one_common', 'title_nb_common_word',\n",
        "             'cos_similarity_title', 'cos_similarity_desc', 'cos_similarity_title_2',\n",
        "              'cos_similarity_desc_1', 'euc_dis_title_bert',\n",
        "             'euc_dis_desc_bert', 'target_eccentricty', 'betweenness_author_target',\n",
        "             'inlinks_author_target', 'en_core', 'hub_score', 'authority_score',\n",
        "              'hubs_s','hubs_d','authorities_s', 'authorities_d',\n",
        "             'allocation', 'adamic_adar', 'preferential', 'jaccard_coef',\n",
        "              'harmonic_s', 'harmonic_t', 'jaccard_followers', 'jaccard_followees',\n",
        "              'cosine_followers', 'cosine_followees', 'follows_back', 'same_comp',\n",
        "              'page_rank_s', 'page_rank_d', 'katz_s', 'katz_d', 'num_followers_s',\n",
        "              'num_followers_d', 'num_followees_s', 'num_followees_d', 'inter_followers',\n",
        "              'inter_followees', 'universal','desc_jaccard']].corr()['label'][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e41990f5",
      "metadata": {
        "id": "e41990f5",
        "outputId": "b66d372b-f9d8-45e8-f3b0-dd24af06c14a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149\n"
          ]
        }
      ],
      "source": [
        "N_VECTORIZATION = 30\n",
        "selected_features = [\"description_d2v_\"+str(i)+\"_source\" for i in range(N_VECTORIZATION)]+[\"description_d2v_\"+str(i)+\"_target\" for i in range(N_VECTORIZATION)]\n",
        "selected_features += [\"title_d2v_\"+str(i)+\"_source\" for i in range(N_VECTORIZATION)]+[\"title_d2v_\"+str(i)+\"_target\" for i in range(N_VECTORIZATION)]\n",
        "selected_features += [\"common_neighbor\",\n",
        "                     \"same_cluster\",\n",
        "                     #\"jaccard\",\n",
        "                     \"diff_in_bc\",\n",
        "                     \"diff_in_inlinks\",\n",
        "                     \"diff_in_year\",\n",
        "                     \"author_nb_common\",\n",
        "                     \"author_is_one_common\",\n",
        "                     \"common_classification\",\n",
        "                     \"title_is_one_common\",\n",
        "                     \"title_nb_common_word\",\n",
        "                     \"cos_similarity_title\",  #tfidf\n",
        "                     \"cos_similarity_desc\", #### #tfidf\n",
        "                     #'cos_similarity_title_2', #bert\n",
        "                     #'cos_similarity_desc_1', #bert\n",
        "                     'euc_dis_title_bert', #eucl bert\n",
        "                     'euc_dis_desc_bert', #eucl bert\n",
        "                     \"target_eccentricty\",\n",
        "                     #'inlinks_target', ##\n",
        "                     'betweenness_author_target',\n",
        "                     'inlinks_author_target',\n",
        "                     'en_core',\n",
        "                      'hub_score',\n",
        "                      'authority_score',\n",
        "                      #'hubs_s',\n",
        "                      #'hubs_d',\n",
        "                      #'authorities_s',\n",
        "                      #'authorities_d',\n",
        "                      'allocation',\n",
        "                      'adamic_adar',\n",
        "                      'preferential',\n",
        "                       #'jaccard_coef',\n",
        "                       #'harmonic_s',\n",
        "                       #'harmonic_t',\n",
        "                      'jaccard_followers',\n",
        "                      'jaccard_followees',\n",
        "                      'cosine_followers',\n",
        "                      'cosine_followees',\n",
        "                      #'follows_back',\n",
        "                      #'same_comp',\n",
        "                      #'page_rank_s',\n",
        "                      #'page_rank_d',\n",
        "                      #'katz_s',\n",
        "                      #'katz_d',\n",
        "                      #'num_followers_s',\n",
        "                      #'num_followers_d',\n",
        "                      #'num_followees_s',\n",
        "                      #'num_followees_d',\n",
        "                      #'inter_followers',\n",
        "                      #'inter_followees',\n",
        "                      'universal',\n",
        "                      'desc_jaccard'\n",
        "                      #'dist_wordmovers_title',\n",
        "                      #'eigenvector_source',\n",
        "                      #'Page_rank'\n",
        "                      #'shortest_path'   ###\n",
        "                     #'cos_similarity_tf_title', ##\n",
        "                     #'cos_similarity_tf_description', ##\n",
        "                      \n",
        "                    ]\n",
        "\n",
        "print(len(selected_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eefbbed",
      "metadata": {
        "id": "5eefbbed"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e95a74f",
      "metadata": {
        "id": "3e95a74f"
      },
      "outputs": [],
      "source": [
        "#X[\"common_neighbor\"] = X[\"common_neighbor\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df1cfb3",
      "metadata": {
        "id": "4df1cfb3"
      },
      "outputs": [],
      "source": [
        "#new_x = X.values.astype(np.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7174d925",
      "metadata": {
        "id": "7174d925"
      },
      "outputs": [],
      "source": [
        "#(X.cos_similarity_title < 0).any()\n",
        "#X = X.reset_index()\n",
        "#X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "#X['cos_similarity_title'].isin([np.nan, np.inf, -np.inf]).any()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "104901ce",
      "metadata": {
        "id": "104901ce"
      },
      "source": [
        "### features selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a978083",
      "metadata": {
        "id": "8a978083"
      },
      "outputs": [],
      "source": [
        "selected_features = ['common_neighbor', 'same_cluster', 'jaccard', 'diff_in_bc',\n",
        "             'diff_in_inlinks', 'diff_in_year', 'author_nb_common','author_is_one_common',\n",
        "             'common_classification', 'title_is_one_common', 'title_nb_common_word',\n",
        "             'cos_similarity_title', 'cos_similarity_desc', 'euc_dis_title_bert',\n",
        "             'euc_dis_desc_bert', 'target_eccentricty', 'betweenness_author_target',\n",
        "             'inlinks_author_target', 'en_core', 'hub_score', 'authority_score',\n",
        "              'hubs_s','hubs_d','authorities_s', 'authorities_d',\n",
        "             'allocation', 'adamic_adar', 'preferential', 'jaccard_coef',\n",
        "              'harmonic_s', 'harmonic_t', 'jaccard_followers', 'jaccard_followees',\n",
        "              'cosine_followers', 'cosine_followees', 'follows_back', 'same_comp',\n",
        "              'page_rank_s', 'page_rank_d', 'katz_s', 'katz_d', 'num_followers_s',\n",
        "              'num_followers_d', 'num_followees_s', 'num_followees_d', 'inter_followers',\n",
        "              'inter_followees']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f77f5b",
      "metadata": {
        "id": "73f77f5b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "X = training_set[selected_features]  #independent columns\n",
        "y = training_set.label    #target column i.e price range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46cf49dd",
      "metadata": {
        "id": "46cf49dd",
        "outputId": "fddb63fe-8004-437a-c87a-c6391972f692"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:5176: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().fillna(\n"
          ]
        }
      ],
      "source": [
        "X.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc16712",
      "metadata": {
        "id": "2dc16712"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "x = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "X = pd.DataFrame(x_scaled, columns = X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57317c66",
      "metadata": {
        "id": "57317c66",
        "outputId": "90403219-e863-482b-a2a7-1f4421819843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Specs          Score\n",
            "0             common_neighbor  238501.988822\n",
            "34           cosine_followees   44940.721057\n",
            "28               jaccard_coef   33046.101747\n",
            "2                     jaccard   29069.472094\n",
            "32          jaccard_followees   25090.154450\n",
            "11       cos_similarity_title   23256.426383\n",
            "12        cos_similarity_desc   21161.346064\n",
            "31          jaccard_followers   17499.448765\n",
            "42            num_followers_d   12063.024721\n",
            "40                     katz_d   11525.636522\n",
            "33           cosine_followers   11496.978800\n",
            "9         title_is_one_common   11373.036025\n",
            "7        author_is_one_common   11346.392852\n",
            "46            inter_followees   10262.509725\n",
            "24              authorities_d   10235.337427\n",
            "20            authority_score   10235.337427\n",
            "22                     hubs_d   10235.337427\n",
            "38                page_rank_d    9679.373024\n",
            "8       common_classification    6833.834663\n",
            "17      inlinks_author_target    6167.405702\n",
            "10       title_nb_common_word    5791.311379\n",
            "43            num_followees_s    5030.233827\n",
            "16  betweenness_author_target    4727.310314\n",
            "5                diff_in_year    3150.646476\n",
            "30                 harmonic_t    2951.362848\n",
            "6            author_nb_common    2515.864924\n",
            "19                  hub_score    1999.230447\n",
            "21                     hubs_s    1999.230447\n",
            "23              authorities_s    1999.230447\n",
            "26                adamic_adar    1916.668824\n"
          ]
        }
      ],
      "source": [
        "#apply SelectKBest class to extract top 10 best features\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=30)\n",
        "fit = bestfeatures.fit(X,y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(30,'Score'))  #print 10 best features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cb5b194",
      "metadata": {
        "id": "2cb5b194",
        "outputId": "18a27406-b61b-4d3f-9b76-989b8b0a95c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.87616209e-01 4.31356788e-03 4.50532773e-02 3.63742571e-03\n",
            " 4.68339019e-03 2.56122522e-02 7.20143454e-04 2.46753449e-03\n",
            " 2.36465024e-03 5.08437953e-03 3.25949874e-03 1.77666533e-02\n",
            " 3.48829472e-02 3.86104797e-03 8.08072908e-03 9.86435304e-03\n",
            " 3.24428329e-03 4.79188205e-03 2.71440753e-03 3.46048831e-03\n",
            " 7.45784806e-03 2.78469649e-03 7.75259296e-03 4.16116620e-03\n",
            " 8.79823677e-03 1.62306362e-02 1.23578221e-02 3.58120277e-03\n",
            " 4.40820625e-02 1.23078138e-02 1.93578678e-02 1.44758417e-02\n",
            " 2.74648951e-02 8.73591264e-03 3.98154563e-02 5.67117265e-05\n",
            " 2.98342183e-02 2.44127996e-03 1.16567990e-02 5.02001572e-03\n",
            " 8.47756732e-03 2.23770798e-03 1.81272607e-02 5.11761675e-03\n",
            " 3.30784184e-03 1.58315964e-03 9.29664893e-03]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cecf0306",
      "metadata": {
        "id": "cecf0306"
      },
      "outputs": [],
      "source": [
        "#sklearn.feature_selection.f_classif \n",
        "#sklearn.feature_selection.mutual_info_classif "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28921951",
      "metadata": {
        "id": "28921951"
      },
      "outputs": [],
      "source": [
        "N_VECTORIZATION = 30\n",
        "selected_features = [\"description_d2v_\"+str(i)+\"_source\" for i in range(N_VECTORIZATION)]+[\"description_d2v_\"+str(i)+\"_target\" for i in range(N_VECTORIZATION)]\n",
        "selected_features += [\"title_d2v_\"+str(i)+\"_source\" for i in range(N_VECTORIZATION)]+[\"title_d2v_\"+str(i)+\"_target\" for i in range(N_VECTORIZATION)]\n",
        "selected_features += featureScores.nlargest(30,'Score').Specs.tolist()[:35]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f590b9",
      "metadata": {
        "id": "64f590b9"
      },
      "outputs": [],
      "source": [
        "selected_features = ['common_neighbor', 'cosine_followees', 'jaccard_coef', 'jaccard', \n",
        " 'jaccard_followees', 'cos_similarity_title', 'cos_similarity_desc', \n",
        " 'jaccard_followers', 'num_followers_d', 'katz_d', 'cosine_followers', \n",
        " 'title_is_one_common', 'author_is_one_common', 'inter_followees', \n",
        " 'authorities_d', 'authority_score', 'hubs_d', 'page_rank_d', 'common_classification', \n",
        " 'inlinks_author_target', 'title_nb_common_word', 'num_followees_s', \n",
        " 'betweenness_author_target', 'diff_in_year', 'harmonic_t', 'author_nb_common', \n",
        " 'hub_score', 'hubs_s', 'authorities_s', 'adamic_adar', 'harmonic_s', 'katz_s',  'allocation', 'num_followees_d']\n",
        "#,'same_comp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61278d36",
      "metadata": {
        "id": "61278d36"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea680c8",
      "metadata": {
        "id": "5ea680c8"
      },
      "source": [
        "### Split to train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9835d9",
      "metadata": {
        "id": "8a9835d9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train = training_set[selected_features],testing_set[selected_features],training_set.label\n",
        "#del (training_set,testing_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5bf8b27",
      "metadata": {
        "id": "f5bf8b27"
      },
      "outputs": [],
      "source": [
        "# run this only if using the above feature selection\n",
        "\n",
        "x = X_train.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "X_train = pd.DataFrame(x_scaled, columns = X_train.columns)\n",
        "x = X_test.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "X_test = pd.DataFrame(x_scaled, columns = X_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different Results with Different Combination of features\n",
        "1. all except shortest_path   -   0.97477\n",
        "2. all withouht bert cos_sim   -   0.9748\n",
        "3. all withouht bert cos_sim and shortestpath   -   0.97484\n",
        "4. all, withouht bert cos_sim and shortestpath, with dist_wordmovers_title  -  0.9747\n",
        "5. all, withouht bert cos_sim and shortestpath and dist_wordmovers_title, with page rank and eigen -\n",
        "6. like 3 but with 50 vector - \n",
        "7. only tf idf and en_core - 0.9745\n",
        "8. only tf idf and en_core with alloc,adami,prefer - 0.97748\n",
        "9. with all the features (no bert cos_sim, hub aut score) - 0.9861\n",
        "11. like 9 un until jaccard_coef + cosine_follow -  0.9775\n",
        "12. only tf idf and en_core with alloc,adami,prefer,jaccard - 0.97754\n",
        "13. like 8 with harmonic on source - 0.97768"
      ],
      "metadata": {
        "id": "L04eM7oODzTJ"
      },
      "id": "L04eM7oODzTJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling"
      ],
      "metadata": {
        "id": "zwhWNV3sD7RA"
      },
      "id": "zwhWNV3sD7RA"
    },
    {
      "cell_type": "markdown",
      "id": "49c93d7c",
      "metadata": {
        "id": "49c93d7c"
      },
      "source": [
        "## LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "469ce236",
      "metadata": {
        "id": "469ce236"
      },
      "outputs": [],
      "source": [
        "# Parameters for lgbm\n",
        "        \n",
        "parameters = {\n",
        "        'application': 'binary',\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'is_unbalance': 'true',\n",
        "        'boosting': 'gbdt', #'dart'\n",
        "        'num_leaves': 80,\n",
        "        'feature_fraction': 0.7,\n",
        "        'min_data_in_leaf': 500,\n",
        "        'learning_rate': 0.1,\n",
        "        'num_iterations': 500,\n",
        "        'max_bin': 255,\n",
        "        #'max_bin': 510,\n",
        "        'verbosity': -2,\n",
        "        'lambda_l1': 10, # L1 regularization\n",
        "        'lambda_l2': 10, # L2 regularization\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d44274",
      "metadata": {
        "scrolled": false,
        "id": "f9d44274",
        "outputId": "97f9d6aa-e480-470c-8cf0-e8379cf20e57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] Number of positive: 268104, number of negative: 224305\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.241809 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 36009\n",
            "[LightGBM] [Info] Number of data points in the train set: 492409, number of used features: 149\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544474 -> initscore=0.178368\n",
            "[LightGBM] [Info] Start training from score 0.178368\n",
            "f1 score is for this fold : 0.9779051104744476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] Number of positive: 268104, number of negative: 224305\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.279742 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 36010\n",
            "[LightGBM] [Info] Number of data points in the train set: 492409, number of used features: 149\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544474 -> initscore=0.178368\n",
            "[LightGBM] [Info] Start training from score 0.178368\n",
            "f1 score is for this fold : 0.9786324465811164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] Number of positive: 268104, number of negative: 224306\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.308873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 36011\n",
            "[LightGBM] [Info] Number of data points in the train set: 492410, number of used features: 149\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544473 -> initscore=0.178364\n",
            "[LightGBM] [Info] Start training from score 0.178364\n",
            "f1 score is for this fold : 0.9781769384741099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] Number of positive: 268104, number of negative: 224306\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.346130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 36009\n",
            "[LightGBM] [Info] Number of data points in the train set: 492410, number of used features: 149\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544473 -> initscore=0.178364\n",
            "[LightGBM] [Info] Start training from score 0.178364\n",
            "f1 score is for this fold : 0.9783300318146347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] Number of positive: 268104, number of negative: 224306\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.316658 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 36009\n",
            "[LightGBM] [Info] Number of data points in the train set: 492410, number of used features: 149\n",
            "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544473 -> initscore=0.178364\n",
            "[LightGBM] [Info] Start training from score 0.178364\n"
          ]
        }
      ],
      "source": [
        "average_score = 0\n",
        "n_splits = 5\n",
        "prediction = [] #final prediction on X_test after Kfold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=n_splits)\n",
        "for train_index, test_index in skf.split(X_train, Y_train):\n",
        "    sub_X_train, sub_X_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    sub_Y_train, sub_Y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
        "        \n",
        "    lgb_train = lgb.Dataset(sub_X_train, sub_Y_train)\n",
        "    lgb_eval = lgb.Dataset(sub_X_test, sub_Y_test, reference=lgb_train)\n",
        "    \n",
        "    rfc = lgb.train(parameters,\n",
        "                       lgb_train,\n",
        "                       valid_sets=lgb_eval,\n",
        "                       num_boost_round=5000,\n",
        "                       early_stopping_rounds=100,\n",
        "                       verbose_eval=False)\n",
        "    \n",
        "    #prediction_sub is the prediction on the validation set\n",
        "    prediction_sub = rfc.predict(sub_X_test)\n",
        "    \n",
        "    #prediction_test is the prediction on the testing set\n",
        "    prediction_test = rfc.predict(X_test)\n",
        "    \n",
        "    prediction_sub = [1 if p>0.5 else 0 for p in prediction_sub]\n",
        "    \n",
        "    score_tmp = f1_score(sub_Y_test, prediction_sub)\n",
        "    average_score += score_tmp\n",
        "    print(\"f1 score is for this fold :\", score_tmp)\n",
        "    \n",
        "    # Combination with previous fold\n",
        "    if len(prediction)==0:\n",
        "        prediction = prediction_test\n",
        "    prediction += prediction_test\n",
        "        \n",
        "    del(sub_X_train, sub_X_test, sub_Y_train, sub_Y_test, prediction_sub, prediction_test)\n",
        "    \n",
        "prediction = [1 if p>=n_splits/2 else 0 for p in prediction]\n",
        "print(\"final f1 score is\", average_score/n_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e8416e9",
      "metadata": {
        "id": "8e8416e9"
      },
      "outputs": [],
      "source": [
        "df_sub = pd.DataFrame(prediction, columns=[\"category\"])\n",
        "df_sub.to_csv('output_new_22.csv', float_format='%.6f', index_label=\"ID\")\n",
        "\n",
        "print(\"done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LGBM Trial 2"
      ],
      "metadata": {
        "id": "oXlQQWT4ELTG"
      },
      "id": "oXlQQWT4ELTG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9105db06",
      "metadata": {
        "id": "9105db06",
        "outputId": "016ff0f0-0ab4-473a-8934-7c2f29cb6416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq', 'max_bin'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters = {\n",
        "        'application': 'binary',\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'is_unbalance': 'true',\n",
        "        'boosting': 'gbdt', #'dart'\n",
        "        'num_leaves': 80,\n",
        "        'feature_fraction': 0.7,\n",
        "        'min_data_in_leaf': 500,\n",
        "        'learning_rate': 0.1,\n",
        "        'num_iterations': 500,\n",
        "        'max_bin': 255,\n",
        "        #'max_bin': 510,\n",
        "        'verbosity': -2,\n",
        "        'lambda_l1': 10, # L1 regularization\n",
        "        'lambda_l2': 10, # L2 regularization\n",
        "        }\n",
        "\n",
        "    \n",
        "# Initiate classifier to use\n",
        "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
        "          objective = 'binary', \n",
        "          n_jobs = 5, \n",
        "          silent = True,\n",
        "          max_depth = params['max_depth'],\n",
        "          max_bin = params['max_bin'], \n",
        "          subsample_for_bin = params['subsample_for_bin'],\n",
        "          subsample = params['subsample'], \n",
        "          min_split_gain = params['min_split_gain'], \n",
        "          min_child_weight = params['min_child_weight'], \n",
        "          min_child_samples = params['min_child_samples'])\n",
        "\n",
        "# To view the default model parameters:\n",
        "mdl.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bab44ff",
      "metadata": {
        "id": "1bab44ff"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "        'application': 'binary',\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'is_unbalance': 'true',\n",
        "        'boosting': 'gbdt', #'dart'\n",
        "        'num_leaves': 80,\n",
        "        'feature_fraction': 0.7,\n",
        "        'min_data_in_leaf': 500,\n",
        "        'learning_rate': 0.1,\n",
        "        'num_iterations': 500,\n",
        "        'max_bin': 255,\n",
        "        #'max_bin': 510,\n",
        "        'verbosity': -2,\n",
        "        'lambda_l1': 10, # L1 regularization\n",
        "        'lambda_l2': 10, # L2 regularization\n",
        "        }\n",
        "\n",
        "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
        "          objective = 'binary', \n",
        "          n_jobs = 5, \n",
        "          silent = True,\n",
        "          learning_rate = params['learning_rate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62668ed2",
      "metadata": {
        "id": "62668ed2"
      },
      "outputs": [],
      "source": [
        "gridParams = {\n",
        "    'learning_rate': [0.01, 0.05, 0.075, 0.1, 0.15]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f73467e1",
      "metadata": {
        "id": "f73467e1"
      },
      "outputs": [],
      "source": [
        "gridParams = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [8,16,24],\n",
        "    'num_leaves': [40,80,120], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
        "    'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n",
        "    'objective' : ['binary'],\n",
        "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
        "    'random_state' : [500],\n",
        "    'colsample_bytree' : [0.64, 0.65, 0.66],\n",
        "    'subsample' : [0.7,0.75],\n",
        "    'reg_alpha' : [1,1.2],\n",
        "    'reg_lambda' : [1,1.2,1.4],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31dfe1ab",
      "metadata": {
        "id": "31dfe1ab"
      },
      "outputs": [],
      "source": [
        "X, y = training_set[selected_features], training_set.label\n",
        "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=4, n_jobs=-1)\n",
        "# Run the grid\n",
        "grid.fit(X, y)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3cc249",
      "metadata": {
        "id": "ad3cc249"
      },
      "source": [
        "## XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de7e8ba",
      "metadata": {
        "id": "1de7e8ba"
      },
      "outputs": [],
      "source": [
        "#pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbdfbdd",
      "metadata": {
        "id": "3cbdfbdd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "#from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 12, 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecfce2c4",
      "metadata": {
        "id": "ecfce2c4",
        "outputId": "a93c9f49-bc37-4004-8de1-f36cc03f4610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting hyperopt\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "Requirement already satisfied: future in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (0.18.2)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (2.0.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (4.62.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (1.5.4)\n",
            "Requirement already satisfied: networkx>=2.2 in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (2.6.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (1.22.2)\n",
            "Requirement already satisfied: six in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ofir6\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.4)\n",
            "Installing collected packages: py4j, hyperopt\n",
            "Successfully installed hyperopt-0.2.7 py4j-0.10.9.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error processing line 1 of C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\vision-1.0.0-py3.9-nspkg.pth:\n",
            "\n",
            "  Traceback (most recent call last):\n",
            "    File \"C:\\Users\\ofir6\\Anaconda3\\lib\\site.py\", line 169, in addpackage\n",
            "      exec(line)\n",
            "    File \"<string>\", line 1, in <module>\n",
            "    File \"<frozen importlib._bootstrap>\", line 562, in module_from_spec\n",
            "  AttributeError: 'NoneType' object has no attribute 'loader'\n",
            "\n",
            "Remainder of file ignored\n"
          ]
        }
      ],
      "source": [
        "pip install hyperopt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "Ttws_wOnEi9A"
      },
      "id": "Ttws_wOnEi9A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da583bb",
      "metadata": {
        "id": "8da583bb"
      },
      "outputs": [],
      "source": [
        "X = training_set[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e127ff",
      "metadata": {
        "id": "08e127ff"
      },
      "outputs": [],
      "source": [
        "#np.where(X.values >= np.finfo(np.float64).max)\n",
        "X = X.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29153c23",
      "metadata": {
        "id": "29153c23"
      },
      "outputs": [],
      "source": [
        "y = training_set.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81ac8b2",
      "metadata": {
        "scrolled": true,
        "id": "a81ac8b2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4af574",
      "metadata": {
        "id": "4d4af574"
      },
      "outputs": [],
      "source": [
        "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
        "        'gamma': hp.uniform ('gamma', 1,9),\n",
        "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
        "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
        "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
        "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
        "        'n_estimators': 180,\n",
        "        'seed': 0\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4966f988",
      "metadata": {
        "id": "4966f988"
      },
      "outputs": [],
      "source": [
        "def objective(space):\n",
        "    clf=xgb.XGBClassifier(\n",
        "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
        "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
        "                    colsample_bytree=int(space['colsample_bytree']))\n",
        "    \n",
        "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
        "    \n",
        "    clf.fit(X_train, y_train,\n",
        "            eval_set=evaluation, eval_metric=\"auc\",\n",
        "            early_stopping_rounds=10,verbose=False)\n",
        "    \n",
        "\n",
        "    pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, pred>0.5)\n",
        "    print (\"SCORE:\", accuracy)\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78ebdf8",
      "metadata": {
        "id": "e78ebdf8",
        "outputId": "777c3e3b-8ba2-4d2c-ae05-42c2e8b09a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r",
            "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476372025517996                                                                                                     \n",
            "  1%|▍                                              | 1/100 [00:18<30:32, 18.51s/trial, best loss: -0.9476372025517996]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947929641383344                                                                                                      \n",
            "  2%|▉                                               | 2/100 [00:39<32:38, 19.98s/trial, best loss: -0.947929641383344]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476209559500471                                                                                                     \n",
            "  3%|█▍                                              | 3/100 [01:05<36:41, 22.69s/trial, best loss: -0.947929641383344]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947707604492727                                                                                                      \n",
            "  4%|█▉                                              | 4/100 [01:26<35:08, 21.97s/trial, best loss: -0.947929641383344]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476805268231395                                                                                                     \n",
            "  5%|██▍                                             | 5/100 [01:47<34:20, 21.69s/trial, best loss: -0.947929641383344]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9473664258559251                                                                                                     \n",
            "  6%|██▉                                             | 6/100 [02:09<33:56, 21.66s/trial, best loss: -0.947929641383344]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479783811886013                                                                                                     \n",
            "  7%|███▎                                           | 7/100 [02:33<34:48, 22.46s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476805268231395                                                                                                     \n",
            "  8%|███▊                                           | 8/100 [02:56<34:52, 22.75s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9474584899325225                                                                                                     \n",
            "  9%|████▏                                          | 9/100 [03:18<34:08, 22.51s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9473880879915951                                                                                                     \n",
            " 10%|████▌                                         | 10/100 [03:40<33:37, 22.42s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477780064336543                                                                                                     \n",
            " 11%|█████                                         | 11/100 [04:01<32:22, 21.83s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477725908997368                                                                                                     \n",
            " 12%|█████▌                                        | 12/100 [04:24<32:44, 22.33s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477130200266445                                                                                                     \n",
            " 13%|█████▉                                        | 13/100 [04:45<31:54, 22.00s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477346821623144                                                                                                     \n",
            " 14%|██████▍                                       | 14/100 [05:13<33:51, 23.63s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9473772569237601                                                                                                     \n",
            " 15%|██████▉                                       | 15/100 [05:38<34:01, 24.01s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477617598319018                                                                                                     \n",
            " 16%|███████▎                                      | 16/100 [06:01<33:19, 23.80s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476534491535521                                                                                                     \n",
            " 17%|███████▊                                      | 17/100 [06:28<34:06, 24.65s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475830472126247                                                                                                     \n",
            " 18%|████████▎                                     | 18/100 [06:52<33:24, 24.44s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9473664258559251                                                                                                     \n",
            " 19%|████████▋                                     | 19/100 [07:12<31:31, 23.35s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9474205811951                                                                                                        \n",
            " 20%|█████████▏                                    | 20/100 [07:37<31:35, 23.69s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479458879850965                                                                                                     \n",
            " 21%|█████████▋                                    | 21/100 [08:00<30:55, 23.49s/trial, best loss: -0.9479783811886013]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480758607991162                                                                                                     \n",
            " 22%|██████████                                    | 22/100 [08:24<30:43, 23.64s/trial, best loss: -0.9480758607991162]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481516782739611                                                                                                     \n",
            " 23%|██████████▌                                   | 23/100 [08:46<29:50, 23.26s/trial, best loss: -0.9481516782739611]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481787559435485                                                                                                     \n",
            " 24%|███████████                                   | 24/100 [09:11<30:07, 23.78s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478321617728291                                                                                                     \n",
            " 25%|███████████▌                                  | 25/100 [09:33<28:58, 23.18s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481516782739611                                                                                                     \n",
            " 26%|███████████▉                                  | 26/100 [09:55<28:12, 22.87s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947875486044169                                                                                                      \n",
            " 27%|████████████▍                                 | 27/100 [10:18<27:47, 22.85s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481246006043735                                                                                                     \n",
            " 28%|████████████▉                                 | 28/100 [10:43<28:16, 23.57s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947897148179839                                                                                                      \n",
            " 29%|█████████████▎                                | 29/100 [11:10<28:50, 24.37s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947875486044169                                                                                                      \n",
            " 30%|█████████████▊                                | 30/100 [11:34<28:20, 24.29s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476913578909745                                                                                                     \n",
            " 31%|██████████████▎                               | 31/100 [12:00<28:34, 24.85s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479133947815915                                                                                                     \n",
            " 32%|██████████████▋                               | 32/100 [12:22<27:24, 24.19s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947696773424892                                                                                                      \n",
            " 33%|███████████████▏                              | 33/100 [12:44<26:09, 23.42s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477563442979844                                                                                                     \n",
            " 34%|███████████████▋                              | 34/100 [13:12<27:19, 24.84s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947940472451179                                                                                                      \n",
            " 35%|████████████████                              | 35/100 [13:34<25:46, 23.80s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475018142038624                                                                                                     \n",
            " 36%|████████████████▌                             | 36/100 [13:58<25:38, 24.04s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477509287640669                                                                                                     \n",
            " 37%|█████████████████                             | 37/100 [14:24<25:39, 24.44s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477455132301493                                                                                                     \n",
            " 38%|█████████████████▍                            | 38/100 [14:48<25:12, 24.40s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475938782804597                                                                                                     \n",
            " 39%|█████████████████▉                            | 39/100 [15:12<24:35, 24.18s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481300161382911                                                                                                     \n",
            " 40%|██████████████████▍                           | 40/100 [15:35<23:53, 23.88s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476372025517996                                                                                                     \n",
            " 41%|██████████████████▊                           | 41/100 [15:57<23:02, 23.44s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479025637137566                                                                                                     \n",
            " 42%|███████████████████▎                          | 42/100 [16:18<22:01, 22.79s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.94744224333077                                                                                                       \n",
            " 43%|███████████████████▊                          | 43/100 [16:39<21:09, 22.27s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477563442979844                                                                                                     \n",
            " 44%|████████████████████▏                         | 44/100 [17:02<20:49, 22.32s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476101248822122                                                                                                     \n",
            " 45%|████████████████████▋                         | 45/100 [17:27<21:09, 23.08s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481191850704561                                                                                                     \n",
            " 46%|█████████████████████▏                        | 46/100 [17:50<20:54, 23.23s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475126452716973                                                                                                     \n",
            " 47%|█████████████████████▌                        | 47/100 [18:15<20:49, 23.57s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477455132301493                                                                                                     \n",
            " 48%|██████████████████████                        | 48/100 [18:37<19:58, 23.04s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475776316787072                                                                                                     \n",
            " 49%|██████████████████████▌                       | 49/100 [18:56<18:35, 21.88s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476263714839646                                                                                                     \n",
            " 50%|███████████████████████                       | 50/100 [19:21<19:06, 22.92s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477400976962319                                                                                                     \n",
            " 51%|███████████████████████▍                      | 51/100 [19:48<19:46, 24.21s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475072297377799                                                                                                     \n",
            " 52%|███████████████████████▉                      | 52/100 [20:14<19:50, 24.80s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478700705102516                                                                                                     \n",
            " 53%|████████████████████████▍                     | 53/100 [20:36<18:38, 23.79s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479892122564364                                                                                                     \n",
            " 54%|████████████████████████▊                     | 54/100 [20:59<18:04, 23.58s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479729656546839                                                                                                     \n",
            " 55%|█████████████████████████▎                    | 55/100 [21:22<17:35, 23.46s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477130200266445                                                                                                     \n",
            " 56%|█████████████████████████▊                    | 56/100 [21:48<17:41, 24.14s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479242258494265                                                                                                     \n",
            " 57%|██████████████████████████▏                   | 57/100 [22:09<16:44, 23.37s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479350569172614                                                                                                     \n",
            " 58%|██████████████████████████▋                   | 58/100 [22:30<15:51, 22.66s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477292666283968                                                                                                     \n",
            " 59%|███████████████████████████▏                  | 59/100 [22:52<15:11, 22.24s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476696957553045                                                                                                     \n",
            " 60%|███████████████████████████▌                  | 60/100 [23:15<14:56, 22.42s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947897148179839                                                                                                      \n",
            " 61%|████████████████████████████                  | 61/100 [23:36<14:21, 22.09s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9473176860506677                                                                                                     \n",
            " 62%|████████████████████████████▌                 | 62/100 [23:56<13:40, 21.59s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476155404161296                                                                                                     \n",
            " 63%|████████████████████████████▉                 | 63/100 [24:18<13:22, 21.69s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947707604492727                                                                                                      \n",
            " 64%|█████████████████████████████▍                | 64/100 [24:41<13:10, 21.97s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475722161447897                                                                                                     \n",
            " 65%|█████████████████████████████▉                | 65/100 [25:02<12:38, 21.68s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478538239084991                                                                                                     \n",
            " 66%|██████████████████████████████▎               | 66/100 [25:26<12:44, 22.48s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480271209938588                                                                                                     \n",
            " 67%|██████████████████████████████▊               | 67/100 [25:50<12:34, 22.85s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480433675956113                                                                                                     \n",
            " 68%|███████████████████████████████▎              | 68/100 [26:12<12:02, 22.58s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480866918669512                                                                                                     \n",
            " 69%|███████████████████████████████▋              | 69/100 [26:33<11:26, 22.14s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478863171120041                                                                                                     \n",
            " 70%|████████████████████████████████▏             | 70/100 [26:54<10:55, 21.84s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480054588581889                                                                                                     \n",
            " 71%|████████████████████████████████▋             | 71/100 [27:15<10:24, 21.55s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480596141973637                                                                                                     \n",
            " 72%|█████████████████████████████████             | 72/100 [27:36<09:59, 21.41s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480650297312813                                                                                                     \n",
            " 73%|█████████████████████████████████▌            | 73/100 [27:58<09:40, 21.51s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476209559500471                                                                                                     \n",
            " 74%|██████████████████████████████████            | 74/100 [28:21<09:32, 22.02s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479675501207664                                                                                                     \n",
            " 75%|██████████████████████████████████▌           | 75/100 [28:43<09:08, 21.95s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479458879850965                                                                                                     \n",
            " 76%|██████████████████████████████████▉           | 76/100 [29:05<08:48, 22.02s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478213307049942                                                                                                     \n",
            " 77%|███████████████████████████████████▍          | 77/100 [29:26<08:22, 21.84s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476534491535521                                                                                                     \n",
            " 78%|███████████████████████████████████▉          | 78/100 [29:50<08:09, 22.24s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478484083745816                                                                                                     \n",
            " 79%|████████████████████████████████████▎         | 79/100 [30:14<08:00, 22.89s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481354316722086                                                                                                     \n",
            " 80%|████████████████████████████████████▊         | 80/100 [30:36<07:33, 22.65s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480217054599412                                                                                                     \n",
            " 81%|█████████████████████████████████████▎        | 81/100 [30:58<07:04, 22.37s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9476047093482947                                                                                                     \n",
            " 82%|█████████████████████████████████████▋        | 82/100 [31:21<06:44, 22.49s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480054588581889                                                                                                     \n",
            " 83%|██████████████████████████████████████▏       | 83/100 [31:42<06:14, 22.05s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9477346821623144                                                                                                     \n",
            " 84%|██████████████████████████████████████▋       | 84/100 [32:04<05:54, 22.13s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480162899260238                                                                                                     \n",
            " 85%|███████████████████████████████████████       | 85/100 [32:28<05:38, 22.59s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475343074073673                                                                                                     \n",
            " 86%|███████████████████████████████████████▌      | 86/100 [32:49<05:12, 22.32s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947875486044169                                                                                                      \n",
            " 87%|████████████████████████████████████████      | 87/100 [33:12<04:50, 22.36s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479946277903538                                                                                                     \n",
            " 88%|████████████████████████████████████████▍     | 88/100 [33:32<04:21, 21.81s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479729656546839                                                                                                     \n",
            " 89%|████████████████████████████████████████▉     | 89/100 [33:53<03:55, 21.45s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9471822977027305                                                                                                     \n",
            " 90%|█████████████████████████████████████████▍    | 90/100 [34:16<03:40, 22.04s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.94744224333077                                                                                                       \n",
            " 91%|█████████████████████████████████████████▊    | 91/100 [34:39<03:19, 22.15s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479133947815915                                                                                                     \n",
            " 92%|██████████████████████████████████████████▎   | 92/100 [35:01<02:58, 22.25s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.947875486044169                                                                                                      \n",
            " 93%|██████████████████████████████████████████▊   | 93/100 [35:23<02:34, 22.03s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9480108743921063                                                                                                     \n",
            " 94%|███████████████████████████████████████████▏  | 94/100 [35:45<02:12, 22.17s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9478484083745816                                                                                                     \n",
            " 95%|███████████████████████████████████████████▋  | 95/100 [36:08<01:52, 22.51s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9479675501207664                                                                                                     \n",
            " 96%|████████████████████████████████████████████▏ | 96/100 [36:33<01:32, 23.25s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9481191850704561                                                                                                     \n",
            " 97%|████████████████████████████████████████████▌ | 97/100 [36:55<01:08, 22.68s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9475938782804597                                                                                                     \n",
            " 98%|█████████████████████████████████████████████ | 98/100 [37:20<00:47, 23.57s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9474909831360274                                                                                                     \n",
            " 99%|█████████████████████████████████████████████▌| 99/100 [37:44<00:23, 23.68s/trial, best loss: -0.9481787559435485]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ofir6\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCORE:                                                                                                                 \n",
            "0.9474205811951                                                                                                        \n",
            "100%|█████████████████████████████████████████████| 100/100 [38:07<00:00, 22.88s/trial, best loss: -0.9481787559435485]\n"
          ]
        }
      ],
      "source": [
        "trials = Trials()\n",
        "\n",
        "best_hyperparams = fmin(fn = objective,\n",
        "                        space = space,\n",
        "                        algo = tpe.suggest,\n",
        "                        max_evals = 100,\n",
        "                        trials = trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd163e1f",
      "metadata": {
        "id": "cd163e1f",
        "outputId": "a6bd3b58-ad87-4022-df94-538cc013429f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best hyperparameters are :  \n",
            "\n",
            "{'colsample_bytree': 0.9444474601154215, 'gamma': 3.1699862893984703, 'max_depth': 15.0, 'min_child_weight': 7.0, 'reg_alpha': 179.0, 'reg_lambda': 0.6438833546180566}\n"
          ]
        }
      ],
      "source": [
        "print(\"The best hyperparameters are : \",\"\\n\")\n",
        "print(best_hyperparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee70390e",
      "metadata": {
        "id": "ee70390e"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9557ea27",
      "metadata": {
        "id": "9557ea27",
        "outputId": "c529c123-0c92-403a-f3fb-e578a6e15cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=0.9444474601154215,\n",
              "              enable_categorical=False, gamma=3.1699862893984703, gpu_id=-1,\n",
              "              importance_type=None, interaction_constraints='',\n",
              "              learning_rate=0.300000012, max_delta_step=0, max_depth=15,\n",
              "              min_child_weight=7, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=180, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
              "              random_state=0, reg_alpha=179.0, reg_lambda=0.6438833546180566,\n",
              "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
              "              validate_parameters=1, verbosity=None)"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 0)\n",
        "\n",
        "clf=xgb.XGBClassifier(n_estimators = 180, \n",
        "                      max_depth = 15,\n",
        "                      gamma = 3.1699862893984703, \n",
        "                      reg_alpha = 179.0,\n",
        "                      min_child_weight= 7, \n",
        "                      reg_lambda = 0.6438833546180566,\n",
        "                      colsample_bytree= 0.9444474601154215)\n",
        "\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "#x_trainScaled = scaler.fit_transform(X_train)\n",
        "#evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
        "#clf.fit(x_trainScaled, y_train,\n",
        "#            eval_set=evaluation, eval_metric=\"auc\",\n",
        "#            early_stopping_rounds=10,verbose=False)\n",
        "\n",
        "evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
        "clf.fit(X_train, y_train,\n",
        "            eval_set=evaluation, eval_metric=\"auc\",\n",
        "            early_stopping_rounds=10,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b4705f",
      "metadata": {
        "id": "96b4705f"
      },
      "outputs": [],
      "source": [
        "X_test = testing_set[selected_features]\n",
        "pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f44314",
      "metadata": {
        "id": "d9f44314"
      },
      "outputs": [],
      "source": [
        "df_sub = pd.DataFrame(pred, columns=[\"category\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44fd9a48",
      "metadata": {
        "id": "44fd9a48",
        "outputId": "4e64e8cf-54b5-4dd9-99b5-6da65320b543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_sub.to_csv('output_new_8.csv', float_format='%.6f', index_label=\"ID\")\n",
        "\n",
        "print(\"done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18ef9ad6",
      "metadata": {
        "id": "18ef9ad6"
      },
      "outputs": [],
      "source": [
        "pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, pred>0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03593ebc"
      },
      "source": [
        "##Random Forest"
      ],
      "id": "03593ebc"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.fillna(0)\n",
        "Y_train = Y_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_train,Y_train, test_size=.2, random_state=555)"
      ],
      "metadata": {
        "id": "vpM_inBzxlY_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vpM_inBzxlY_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(bootstrap= True,n_estimators= 500)\n",
        "\n",
        "rf_model = model.fit(X_train_, y_train_)\n",
        "\n",
        "#Predict\n",
        "y_pred = rf_model.predict(X_test_)"
      ],
      "metadata": {
        "id": "beCtfg6vlwfB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "beCtfg6vlwfB"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy_score of Random Forest : %f'  %(accuracy_score(y_test_, y_pred)))\n",
        "print(roc_auc_score(y_test_, y_pred))"
      ],
      "metadata": {
        "id": "4EZxfsLjl46Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9aca6ae-00ad-4f44-c363-c1a0ac199bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy_score of Random Forest : 0.984119\n",
            "0.9842435705649882\n"
          ]
        }
      ],
      "id": "4EZxfsLjl46Y"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a6d871-efd8-4f52-e48e-ce34b1eb00d6",
        "id": "n8cl7SnOl46Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=500)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "id": "n8cl7SnOl46Y"
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "id": "defS9Xogxfj1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "defS9Xogxfj1"
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = pd.DataFrame(prediction, columns=[\"category\"])\n",
        "df_sub.to_csv('output_rf.csv', float_format='%.6f', index_label=\"ID\")\n",
        "\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf76270b-0d03-41c4-ec19-ce7c48e3d9bd",
        "id": "O71n17GIl46Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ],
      "id": "O71n17GIl46Z"
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(estimator=model, X= X_train_, y_true=y_train_, xticks_rotation='vertical', cmap='Blues', ax=None, include_values=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "XTKT8vbMsUTX",
        "outputId": "14751142-22ba-472b-f1c3-3d732c573508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb8e9d28b10>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAEDCAYAAAC8vCafAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgV1ZnH8e/b3ez7LgKKC6i4oaK4xN0o6EzQiSZoDERRTBSNiU7UTBTEZeKYqNGocUMBF0xcAlEEkUAEFQVcWEVQIezY7Mja3e/8UafxAt19q6AvvdzfJ089fe9bp06d6jYvp+qcqjJ3R0REypZT0Q0QEakKlCxFRGJQshQRiUHJUkQkBiVLEZEYlCxFRGLIq+gGpMqp3cBz6rWo6GZIAke3b1rRTZAEFiyYT35+vu1JHbkN93cv2BSrrG/6ZrS7d9uT/VUWlStZ1mtB/e4DK7oZksB7z11e0U2QBE7p2mWP6/CCzdQ6tGessps/eaT5Hu+wkqhUyVJEqgADbI86p1WSkqWIJGfZN9yhZCkiyalnKSKSjmVlzzL7jlhE9owBObnxlrKqMWtnZuPMbJaZzTSzX4b4ADNbbGafhuX8lG1uM7N5ZjbHzM5LiXcLsXlmdmtK/AAz+zDEXzazmiFeK3yfF9a3T3fYSpYikpBFp+FxlrIVADe5eyfgROA6M+sU1j3o7p3DMhIgrOsJHA50Ax4zs1wzywUeBboDnYBLU+q5L9R1MLAa6BPifYDVIf5gKFcmJUsRSc5y4i1lcPel7v5x+LwemA20KWOTHsAwd9/i7l8D84ATwjLP3b9y963AMKCHmRlwFvBK2H4wcGFKXYPD51eAs0P5UilZikhy5dOzTKnO2gPHAB+GUD8zm2Zmg8ysSYi1ARambLYoxEqLNwPWuHvBTvEd6grr14bypVKyFJGELEnPsrmZTUlZ+u5Sm1l94FXgRndfBzwOHAR0BpYCf9yLB1cqjYaLSDLJJqXnu3uptw2ZWQ2iRPmCu78G4O7LU9Y/BbwRvi4G2qVs3jbEKCW+EmhsZnmh95havriuRWaWBzQK5UulnqWIJGSQkxdvKauW6BrhM8Bsd38gJd46pdhFwIzweQTQM4xkHwB0AD4CJgMdwsh3TaJBoBEevTNnHHBx2L43MDylrt7h88XAPz3NO3bUsxSR5HLKZVL6KcBPgelm9mmI/ZZoNLsz4MB84BoAd59pZn8FZhGNpF/n7oUAZtYPGA3kAoPcfWao7xZgmJndDXxClJwJP4ea2TxgFVGCLZOSpYgkY5TLpHR3nxhq29nIMra5B7inhPjIkrZz96+IRst3jm8GLknSXiVLEUlOtzuKiKSTnbc7KlmKSHJpbmWsjpQsRSSZhBPOqwslSxFJTqfhIiIxqGcpIpKOBnhEROJRz1JEJA2ztLcyVkfZd8QisufUsxQRiUHXLEVEYlDPUkQkDdNouIhIPOpZioiUzYCcHPUsRUTKZpT8FMpqTslSRBIy0rw1tlpSshSRxJQsRURiULIUEUnHwMrnhWVVipKliCRiumYpIhKPkqWISAxKliIiMShZioiko0npIiLpGabbHUVE4tBpuIhIHNmXK5UsRSQhU89SRCQWJUsRkTQ0wCMiElf2dSyVLEUkIV2zFBGJJxuTZfZdeBCRPWZmsZY0dbQzs3FmNsvMZprZL0O8qZmNMbO54WeTEDcze9jM5pnZNDM7NqWu3qH8XDPrnRI/zsymh20ettCo0vZRFvUsy7Bv07o8cvXJtGhYGweGjp/L02Pm8J/H78fNFx5Fh9aN6D7wLT6bvwqAGrk53P+zrhzdvilFDre/OIX3P18OwGu3fp+WjeqweVsBAD3vH0v++i20aVqXh68+mYZ1a5KbY9zzt08YO20JAIe1bcz9P+tKgzo1KCpyug18iy3biirkd1EdFBYWcWav/6N1y0a8/OAvcHfufvwfDB/7Cbk5OVz5w1O5pucZ/PWtyfxpyBjcnfp1a/PHW3/MkR3bsnnLNi7o+xBbthVQWFDID84+htuuuaCiD6tilE/HsgC4yd0/NrMGwFQzGwP8DBjr7r83s1uBW4FbgO5Ah7B0BR4HuppZU6A/0AXwUM8Id18dylwNfAiMBLoBb4U6S9pHqTKaLM2sG/AnIBd42t1/n8n9lbeCQmfAsI+ZvmAV9Wrn8faA83l35jI+X7SGKx95l/t/1nWH8pefcTAAZ97+Js0b1OKFm86i251v4R6tv+6JidsTa7Ebf3AkIz5awOBxc+m4byNe+PWZHH/z38nNMR695hT6PfkesxauoUm9mmwr8L1y3NXVX4aNo+MBrVj/7WYAXvzHJBYvX8NHf7udnJwcvlm1HoD9923Gm0/cSOOGdRnz3kx+de9LvPPcf1OrZh7DH7+B+nVrsa2gkO5XPcA5J3fi+CMPqMjD2uvMymc03N2XAkvD5/VmNhtoA/QAzgjFBgPjiRJZD2CIuzswycwam1nrUHaMu68K7RsDdDOz8UBDd58U4kOAC4mSZWn7KFXGTsPNLBd4lOhfg07ApWbWKVP7y4QVazcxfUGU3L7dXMDcJWvZp0kd5i5dx5fL1u1SvuO+jZg4exkA+eu3sG7jVjq3b1bmPtyhQZ0aQPRz2epNAJxxRGtmLVzDrIVrAFj97VaKXMlydy1evpq3J86kV4+Tt8cGvTqR31zVffv/8Vs0bQBA16MPpHHDugAcf+QBLFkR/Q3MjPp1awGwraCQbQWFWXntDhKdhjc3sykpS99S6msPHEPUA2wVEinAMqBV+NwGWJiy2aIQKyu+qIQ4ZeyjVJnsWZ4AzHP3rwDMbBhRNp+VwX1mTLvm9Thi/6Z8/OXKUsvM/PdqzjumLa9Pmk+bpnU5qn0z9m1Wl0++jrZ5qM9JFLrz5pSFPDhiOgB/+Ps0Xr75LK485xDq1srjR/83FoAD92mI47x001k0a1Cb4R/O59G3quSvrlL47QOvcucNF7Jh4+btsa8Xf8NrY6by5vjPaNa4AffdfDEH7ddyh+2GDn+fc07+7t/4wsIizvjpfXy96Bv6XHIaXY5ov7cOoVJJ8I9Evrt3SVNXfeBV4EZ3X5dat7u7mWW0lxB3H5kc4Ckt2+/AzPoW/6tTtHnX3lplULdWHk/3O407XpzChs3bSi330oQvWbJqI6MHdGfgZV2YMvcbCouiv8G1f5nImbe/SY9736ZrxxZccnJ06nbRie15+b2vOPbXr/OTB8bx574nYwZ5OUbXDi257on36HHvaLof147vHbbPXjne6mbUhOk0b9KAzoftt0N869YCateswbght9D7wpPpd9cLO6yfMOULnh/xAQP69dgey83NYcKLtzHzzbv5eOYCZs1bsleOodKxmEu6asxqECXKF9z9tRBeHk6vCT9XhPhioF3K5m1DrKx42xLiZe2jVBU+Gu7uT7p7F3fvklO7YUU3Zxd5ucYz/U7jtQ/mM3LqwjLLFhY5/V+ayjl3jORnD/+LhnVr8tWy6DrYsjXR6fW3mwt4fdJ8jjmwOQCXnXYQIz5aAMDUL/OpVSOXZvVrsWT1RibNWc6qDVvYtLWQsdOWcFT7ppk70Grsw8++YtSE6Rz1gzvo89tnmTD5C/rePph9WzbhP888GoD/OPNoZs5dvH2bGXMXc8PdL/LCH/rStHH9Xeps1KAupx7XkbEfZGdvv5xGww14Bpjt7g+krBoBFI9o9waGp8R7hVHxE4G14VR6NHCumTUJo9rnAqPDunVmdmLYV6+d6ippH6XKZLIsLdtXKQ9eeRJzl67lidGz05atUzOXujVzATjt8H0oKCriiyVryc0xmtaPrnXl5RrfP7oNny+OroMtXvktp3aKeowdWjekVo1c8tdvYfz0pRzatgl1auaSm2OcdEhLvliyNkNHWb3179eDmW/ezbQRA3nm3is49fiOPHlXb84//SgmTJ0LwHsfz+XgcAq+cNkqev3mKf5yZy8O3v+7S1n5q9ezdv1GADZt3sq4jz6nQ/u0l7qqHyufZAmcAvwUOMvMPg3L+cDvge+b2VzgnPAdotHsr4B5wFPAtQBhYOcuYHJYBhYP9oQyT4dtviQa3KGMfZQqk9csJwMdzOwAoiTZE7gsg/srdyd0aMElpxzIrIWreWfg+QD87yufUjMvl3su70KzBrV5/ldnMuPfq7n0j/+kecPavHTT2RS5s2z1Rq5/8n0AauXl8NLNZ1EjN4fcHOPdmct4fvw8AAYM+5g/XNGVvucehuP88ukPAFi7cStPjJ7NqP7dcYex0xbzzmdV7t+aSu1XP/s+V98+mMde/Cf169biT7+L/vO8/+m3WLX2W26+72UA8vJyGDfkFpblr+PaAUMpLCqiqMi56Jxj6XbqkRV5CBUiujd8zwe23H0ipZ+sn11CeQeuK6WuQcCgEuJTgCNKiK8saR9lMc/gCGv4V+IhoqlDg9z9nrLK5zU70Ot3H5ix9kj5W/bc5RXdBEnglK5dmDp1yh5lutr7dPT9ej0cq+zc+7tPTTfAU1VkdJ6lu48k6jqLSDWSjVOmdAePiCRjkIW5UslSRJIxKJdrllWNkqWIJKZkKSKSjk7DRUTSMzTAIyISQ6wJ59WOkqWIJJaFuVLJUkSSU89SRCQNM42Gi4jEkoUdSyVLEUlOp+EiIjFkYa5UshSRhEw9SxGRtKJJ6RXdir1PyVJEEiqfh/9WNUqWIpKYTsNFRNLRgzRERNLTgzRERGJSshQRiUEDPCIi6eiapYhIeqbnWYqIxJOFuVLJUkSSy8nCbKlkKSKJZWGuVLIUkWTMIFej4d8xs0cAL229u9+QkRaJSKWnAZ4dTdlrrRCRKiULc2XpydLdB6d+N7O67r4x800SkcrMiKYPZZucdAXM7CQzmwV8Hr4fbWaPZbxlIlJp5Vi8pTpJmyyBh4DzgJUA7v4ZcFomGyUilZhFk9LjLNVJnGSJuy/cKVSYgbaISBVgRKPhcZa0dZkNMrMVZjYjJTbAzBab2adhOT9l3W1mNs/M5pjZeSnxbiE2z8xuTYkfYGYfhvjLZlYzxGuF7/PC+vbp2honWS40s5MBN7MaZnYzMDvGdiJSTZnFW2J4DuhWQvxBd+8clpHRPq0T0BM4PGzzmJnlmlku8CjQHegEXBrKAtwX6joYWA30CfE+wOoQfzCUK1OcZPlz4DqgDbAE6By+i0iWKq/TcHd/F1gVc7c9gGHuvsXdvwbmASeEZZ67f+XuW4FhQA+LGnAW8ErYfjBwYUpdxYPYrwBnW5oGp52U7u75wE9iHoyIVHMJeo17op+Z9SKawniTu68m6rBNSimzKMQAFu4U7wo0A9a4e0EJ5dsUb+PuBWa2NpTPL61BcUbDDzSzf5jZN+HawnAzOzDddiJSfeWYxVqA5mY2JWXpG6P6x4GDiM5ilwJ/zOChxBbndscXia4HXBS+9wReIsrcIpKFEjxII9/duySp292XF382s6eAN8LXxUC7lKJtQ4xS4iuBxmaWF3qXqeWL61pkZnlAo1C+VHGuWdZ196HuXhCW54HaMbYTkWrIyOw8SzNrnfL1IqB4pHwE0DOMZB8AdAA+AiYDHcLId02iDt0Id3dgHHBx2L43MDylrt7h88XAP0P5UpV1b3jT8PGtMBQ/jOhe8R8DI9Mcr4hUV+U4h9LMXgLOIDpdXwT0B84ws85E+WY+cA2Au880s78Cs4AC4Dp3Lwz19ANGA7nAIHefGXZxCzDMzO4GPgGeCfFngKFmNo9ogKlnuraWdRo+NTS2+LdyTco6B25LV7mIVE/lNcDj7peWEH6mhFhx+XuAe0qIj6SETpy7f0U0Wr5zfDNwSZK2lnVv+AFJKhKR7FHd7s6JI9bzLM3sCKLJntuvVbr7kEw1SkQqr+JrltkmbbI0s/5E1xQ6EXVzuwMTASVLkSyVja+ViDMafjFwNrDM3a8AjiYaZheRLGSWaJ5ltRHnNHyTuxeZWYGZNQRWsOOcJhHJMtUsD8YSJ1lOMbPGwFNEI+QbgA8y2ioRqdQ0wFMCd782fPyLmY0CGrr7tMw2S0QqsyzMlWVOSj+2rHXu/nFmmiQilZlR/a5HxlFWz7Ksm9ed6NFH5eqo9k1571k94KgqaXJ8v4pugiSwZc6/97wSg5wsnDtU1qT0M/dmQ0Sk6oj1ioVqJtakdBGRYoYGeEREYsnCs3AlSxFJLhuTZZwnpZuZXW5md4Tv+5nZLk/xEJHsYFZ+b3esSuJcp30MOAkofpTSeqInp4tIlirHtztWGXFOw7u6+7Fm9gmAu68ufveuiGSf6KlD1SwTxhAnWW4L7+V1ADNrARRltFUiUqll49ShOMf8MPA60NLM7iF6PNu9GW2ViFRqOg0vgbu/YGZTiR7TZsCF7j474y0TkUrJquHj1+KI8/Df/YCNwD9SY+5eDvdNiUhVlJuF5+Fxrlm+yXcvLqsNHADMAQ7PYLtEpJLSAE8p3P3I1O/haUTXllJcRLJAFubK5HfwuPvHZtY1E40RkSrAsvMOnjjXLH+d8jUHOBZYkrEWiUilZ2RftozTs2yQ8rmA6Brmq5lpjohUdgbkaYBnR2EyegN3v3kvtUdEqgA9oi2FmeW5e4GZnbI3GyQilVs0Gl7Rrdj7yupZfkR0ffJTMxsB/A34tnilu7+W4baJSGVUDe/OiSPONcvawEqid+4Uz7d0QMlSJEtpnuWOWoaR8Bl8lySLeUZbJSKVlk7Dd5UL1IcS5wgoWYpkLSNXPcsdLHX3gXutJSJSJUQvLKvoVux9ZSXLLPx1iEhaWXoHT1lTS8/ea60QkSolJzymLd2SjpkNMrMVZjYjJdbUzMaY2dzws0mIm5k9bGbzzGxaeE5F8Ta9Q/m5ZtY7JX6cmU0P2zxsYYJoafso85hLW+Huq9IeqYhkneLT8HJ6+O9zQLedYrcCY929AzA2fAfoDnQIS1/gcYgSH9Af6AqcAPRPSX6PA1enbNctzT5KlYU3LYnIniqvnqW7vwvs3DHrAQwOnwcDF6bEh3hkEtDYzFoD5wFj3H2Vu68GxgDdwrqG7j7J3R0YslNdJe2jVHpvuIgkYkBuZq9ZtnL3peHzMqBV+NwGWJhSblGIlRVfVEK8rH2USslSRJKxRPeGNzezKSnfn3T3J+Nu7O5uZhmdqhh3H0qWIpJYgo5lvrt3SVj9cjNr7e5Lw6n0ihBfDLRLKdc2xBYDZ+wUHx/ibUsoX9Y+SqVrliKSSPFrJcrjmmUpRgDFI9q9geEp8V5hVPxEYG04lR4NnGtmTcLAzrnA6LBunZmdGEbBe+1UV0n7KJV6liKSWHldsjSzl4h6hc3NbBHRqPbvgb+aWR9gAfCjUHwkcD4wj+glildANHPHzO4CJodyA1Nm81xLNOJeB3grLJSxj1IpWYpIQkZOOc1Kd/dLS1m1yzzvMKJ9XSn1DAIGlRCfAhxRQnxlSfsoi5KliCRiZOf1OyVLEUlMT0oXEYkh+1KlkqWIJJVsnmW1oWQpIonomqWISEx6rYSISAxZmCuVLEUkmeg0PPuypZKliCSmnqWISFqGqWcpIpKeepYiImmYoVfhiojEkYW5UslSRJLTNUsRkTSih/9WdCv2PiVLEUlMPUuJbe36jdxwz0t8/uUSMOOR3/2EDvu35Mr/eZaFS1fRrnVTnr33Sho3rMvDQ9/hlVHRO5sKCov4Yv4y5o7+X/LXbKDPb5/dXuf8JSu5re/5/OLSMyvqsKq0Nq0a8/iAXrRo2gAHBr/+Hk8MGw/A1T86nasuOZXCImfMxBn0f2Q4Z5xwKP37/YCaNfLYuq2AOx7+OxOmfAHA737xn/S84AQaNahLu9Nv2r6Pay87i5/2OInCwiLy12zg+oHPs3DZatrt04Sh9/clJ8fIy8vlqZf/xbOvTayA38LekY23O1r08OEMVGw2CPgPYIW77/Kk4pIce1wXf2/S5PQFK4FrBwzlxM4H0evCk9m6rYBNm7fywLNv06RRXW7sfS4PDX6bNes2MeD6HjtsN2rCdB5/cRzDH79hh3hhYRGHX/A7xjx7M+1aN92bh7JHmp5wfUU3YbtWzRrSqnlDps1ZRP26tRg35BYu/+8nadG0ATddeR4/vvEvbN1WQPMm9clfvYEjO7blm1XrWZa/lsMOas0rD1/H4Rf8DoAuR7Rn4dJVTHmt/w7J8nvHdWDqjPls2rKNK3/4PU45rgN9fvssNfJyMTO2biugXp2avD/sfzivzwMsy19bUb+OEm2Z81eKNq7Yo0x36BGd/cnX/hmr7OmHNJu6Gy8sq5Qy+fCQ54BuGay/wqzbsIn3P5nHT3ucBEDNGnk0alCXt96dTs8LugLQ84KujPzXtF22fXX0VP7rvON2if9r8hzat21epRJlZbN85TqmzYleE71h4xa+mL+M1i0ac+UPT+WhwWPYuq0AgPzVGwCY/sWi7cls9pdLqVOrBjVrRCdbU2bMZ/nKdbvsY+LUuWzasg2AydPn06ZlYwC2FRRur79mzRrl9tqFysli/686yViydPd3gVVpC1ZBC5aspHmT+vQb+DynX34fN9z9It9u2sKKVevZp3kjIOrlrFi1foftNm7eythJs/nBmZ13qfO1MR/zw3N3TaKye9q1bspRh7Rl6sz5HLx/S07qfBBjnr2ZN574Jcd02m+X8j84qzOfzVm4PeHF8dMeJzHm/Vnbv7dp1ZiJL97GjDfu4k9D3ql0vcpyY9HUoThLdZKNj6XbYwUFRXw2ZxFX/PBU/vX8LdStU5OHBo/ZoYyZ7fIfy6gJ0+l61IE0aVRvh/jWbQWMenc6Pc4+JtNNzwr16tRkyH1XcdsDr7L+283k5ebQpGE9vn/FH7jjT3/n2Xuv3KH8oQfuw4Dre/Cre4fF3sePuh9P58P245GhY7fHFi9fw/cu+1+Ou+hOel5wAi2aNii3Y6psLOZSnVR4sjSzvmY2xcym5Od/U9HNiWXflo3Zt2VjuhzRHoAeZ3Vm2pyFtGzaYHtvYln+Wlo02fH/LK+/XXLv8Z33Z3HUoe1o2axhxtte3eXl5jD4vqv526gpvDHuMwAWr1jDP8Z9CsDHsxZQ5E6zxvWB6G859P/68ov+Q5m/OD/WPk4/4RB+fcV5XHbTEyX2RJflr2X2l0s5qfNB5XRUlcteeG94pVThydLdn3T3Lu7epXnzFhXdnFhaNW9Im5aNmbtgOQD/mvwFhxzQmm6nHcmwNz8EYNibH9L9tCO3b7Nuwybe+2Qe3U8/cpf6Xn17qk7By8kjt/+EL+Yv47EXvxuAGDl+Gqd26QjAQfu1pGaNPFau2UDD+nV4+cGfc+ejw/lw2lex6j+yY1sevK0nl930xPZrnxAl3dq1agDQqEEdTjz6IOYtWFGOR1a5ZONpuKYO7ab7/vsSrrl9MFsLCmm/bzP+fMflFBU5V/52EM+PmES7fZowKOV0743xn3Fm10OpV6fWDvV8u2kL4z/8nAdv67m3D6HaOfHoA+l5QVdmzl3Muy/cCsBdj47g+REf8Oc7fsL7w37L1m2F/GLAUACu/tFpHNCuBb+5qju/uao7AP/V78/kr97Andf34IfndaFu7RrMeOMuhg7/gPueGsnAX15IvTq1eO73fQBYtGw1l930BB3b78PdN16Eu2Nm/PmFscz6cknF/CL2guo2eBNHJqcOvQScATQHlgP93f2ZsrapSlOHJFKZpg5JeuUxdeiwI4/xwcPHxyrb9aDG1WbqUMZ6lu5+aabqFpGKlX39Sp2Gi8juyMJsqWQpIolE04KyL1sqWYpIMqanDomIxKNkKSKSTvW77zsOJUsRSay6TTiPQ8lSRBKpjvd9x1HhtzuKSNUTPSgm/RKjnvlmNt3MPjWzKSHW1MzGmNnc8LNJiJuZPWxm88xsmpkdm1JP71B+rpn1TokfF+qfF7bd7TyvZCkiiZXzveFnunvnlDt9bgXGunsHYGz4DtAd6BCWvsDjUVusKdAf6AqcAPQvTrChzNUp2+32M3aVLEUksQw/oq0HMDh8HgxcmBIf4pFJQGMzaw2cB4xx91XuvhoYA3QL6xq6+ySP7useklJXYkqWIpJM3EwZL1s68LaZTTWzviHWyt2Xhs/LgFbhcxtgYcq2i0KsrPiiEuK7RQM8IpJYgqlDzYuvRQZPuvuTKd+/5+6LzawlMMbMPk/d2N3dzDLztJ+ElCxFJBEj0fXI/LKeOuTui8PPFWb2OtE1x+Vm1trdl4ZT6eIHgy4G2qVs3jbEFhM94Sw1Pj7E25ZQfrfoNFxEEiuPAR4zq2dmDYo/A+cCM4ARQPGIdm9gePg8AugVRsVPBNaG0/XRwLlm1iQM7JwLjA7r1pnZiWEUvFdKXYmpZykiiZXTHTytgNfDbJ484EV3H2Vmk4G/mlkfYAHwo1B+JHA+MA/YCFwB4O6rzOwuoPhhuAPdvfhlidcSvWm2DvBWWHaLkqWIJFYed/C4+1fA0SXEVwJnlxB34LpS6hoEDCohPgU4Yo8bi5KliOyGbLyDR8lSRJLLwmypZCkiiZhR7V5zG4eSpYgkln2pUslSRHZHFmZLJUsRSUgP/xURiSULL1kqWYpIMtn68F8lSxFJbA+eoVtlKVmKSGJZmCuVLEUkuSzMlUqWIpJQsldGVBtKliKyG7IvWypZikgiCR/+W20oWYpIYjlKliIi6ekOHhGROLIvVypZikhyWZgrlSxFJJk4LyOrjpQsRSQx3e4oIhJD9qVKJUsR2Q1Z2LFUshSRpPTwXxGRtLL1Dp6cim6AiEhVoJ6liCSmV+GKiKSjeZYiIunpHTwiInFlYbZUshSRxDR1SEQkBl2zFBGJQclSRCSGbDwNN3ev6DZsZ2bfAAsquh0Z0BzIr+hGSCLV9W+2v7u32JMKzGwU0e8njnx377Yn+6ssKlWyrK7MbIq7d6nodkh8+pvJznS7o4hIDEqWIiIxKFnuHU9WdAMkMf3NZAe6ZikiEoN6liIiMShZiojEoGQpIhKD7uDJADM7FOgBtAmhxcAId59dca0SkT2hnmU5M7NbgGFED7H6KCwGvGRmt1Zk2yQ5M7uiotsglYNGw8uZmX0BHO7u23aK1wRmunuHimmZ7A4z+7e771fR7ZCKp9Pw8lcE7Muu97i3DuukkjGzaaWtAlrtzbZI5aVkWf5uBMaa2VxgYfBLz4IAAANmSURBVIjtBxwM9KuwVklZWgHnAat3ihvw/t5vjlRGSpblzN1HmVlH4AR2HOCZ7O6FFdcyKcMbQH13/3TnFWY2fu83RyojXbMUEYlBo+EiIjEoWYqIxKBkWYWYWaGZfWpmM8zsb2ZWdw/qes7MLg6fnzazTmWUPcPMTt6Nfcw3s12eqF1afKcyGxLua4CZ3Zy0jSJxKVlWLZvcvbO7HwFsBX6eutLMdmvAzt2vcvdZZRQ5A0icLEWqEyXLqmsCcHDo9U0wsxHALDPLNbP7zWyymU0zs2sALPJnM5tjZu8ALYsrMrPxZtYlfO5mZh+b2WdmNtbM2hMl5V+FXu2pZtbCzF4N+5hsZqeEbZuZ2dtmNtPMnob0b7Uys7+b2dSwTd+d1j0Y4mPNrEWIHWRmo8I2E8KtpSIZp6lDVVDoQXYHRoXQscAR7v51SDhr3f14M6sFvGdmbwPHAIcAnYjmFc4CBu1UbwvgKeC0UFdTd19lZn8BNrj7H0K5F4EH3X2ime0HjAYOA/oDE919oJldAPSJcThXhn3UASab2avuvhKoB0xx91+Z2R2h7n5ED+X9ubvPNbOuwGPAWbvxaxRJRMmyaqljZsVzAScAzxCdHn/k7l+H+LnAUcXXI4FGQAfgNOClMNdziZn9s4T6TwTeLa7L3VeV0o5zgE723cujG5pZ/bCP/wrbvmlmO0/yLskNZnZR+NwutHUl0d1OL4f488BrYR8nA39L2XetGPsQ2WNKllXLJnfvnBoISePb1BBwvbuP3qnc+eXYjhzgRHffXEJbYjOzM4gS70nuvjFMAK9dSnEP+12z8+9AZG/QNcvqZzTwCzOrAWBmHc2sHvAu8ONwTbM1cGYJ204CTjOzA8K2TUN8PdAgpdzbwPXFX8ysOHm9C1wWYt2BJmna2ghYHRLloUQ922I5QHHv+DKi0/t1wNdmdknYh5nZ0Wn2IVIulCyrn6eJrkd+bGYzgCeIziBeB+aGdUOAD3be0N2/AfoSnfJ+xnenwf8ALioe4AFuALqEAaRZfDcqfydRsp1JdDr+7zRtHQXkmdls4PdEybrYt8AJ4RjOAgaG+E+APqF9M4meGyqScbrdUUQkBvUsRURiULIUEYlByVJEJAYlSxGRGJQsRURiULIUEYlByVJEJAYlSxGRGP4fzHiA0dHWTBEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "id": "XTKT8vbMsUTX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Catboost"
      ],
      "metadata": {
        "id": "aY0X2Fh92AR1"
      },
      "id": "aY0X2Fh92AR1"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.fillna(0)\n",
        "Y_train = Y_train.fillna(0)"
      ],
      "metadata": {
        "id": "m6RasBE5n1GO"
      },
      "execution_count": null,
      "outputs": [],
      "id": "m6RasBE5n1GO"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_train,Y_train, test_size=.2, random_state=555)"
      ],
      "metadata": {
        "id": "5Jrdi_3_Aaab"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5Jrdi_3_Aaab"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model = CatBoostClassifier()\n",
        "catboost_model = model.fit(X_train_, y_train_)\n",
        "\n",
        "#Predict\n",
        "y_pred = catboost_model.predict(X_test_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xLB0QlT4ENS",
        "outputId": "962ea5af-d00e-4e61-e47a-566f88e68307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.145398\n",
            "0:\tlearn: 0.4147267\ttotal: 390ms\tremaining: 6m 29s\n",
            "1:\tlearn: 0.2624790\ttotal: 806ms\tremaining: 6m 42s\n",
            "2:\tlearn: 0.1906977\ttotal: 1.26s\tremaining: 6m 57s\n",
            "3:\tlearn: 0.1385768\ttotal: 1.58s\tremaining: 6m 33s\n",
            "4:\tlearn: 0.1083071\ttotal: 1.79s\tremaining: 5m 56s\n",
            "5:\tlearn: 0.0935593\ttotal: 1.91s\tremaining: 5m 16s\n",
            "6:\tlearn: 0.0819187\ttotal: 2.04s\tremaining: 4m 50s\n",
            "7:\tlearn: 0.0756855\ttotal: 2.17s\tremaining: 4m 28s\n",
            "8:\tlearn: 0.0711090\ttotal: 2.4s\tremaining: 4m 24s\n",
            "9:\tlearn: 0.0679143\ttotal: 2.65s\tremaining: 4m 22s\n",
            "10:\tlearn: 0.0650298\ttotal: 2.91s\tremaining: 4m 22s\n",
            "11:\tlearn: 0.0629492\ttotal: 3.21s\tremaining: 4m 23s\n",
            "12:\tlearn: 0.0614989\ttotal: 3.54s\tremaining: 4m 29s\n",
            "13:\tlearn: 0.0601395\ttotal: 3.84s\tremaining: 4m 30s\n",
            "14:\tlearn: 0.0582696\ttotal: 4.08s\tremaining: 4m 27s\n",
            "15:\tlearn: 0.0575817\ttotal: 4.41s\tremaining: 4m 31s\n",
            "16:\tlearn: 0.0565509\ttotal: 4.79s\tremaining: 4m 36s\n",
            "17:\tlearn: 0.0560442\ttotal: 5.26s\tremaining: 4m 47s\n",
            "18:\tlearn: 0.0550580\ttotal: 5.57s\tremaining: 4m 47s\n",
            "19:\tlearn: 0.0546229\ttotal: 5.9s\tremaining: 4m 49s\n",
            "20:\tlearn: 0.0541336\ttotal: 6.23s\tremaining: 4m 50s\n",
            "21:\tlearn: 0.0538489\ttotal: 6.51s\tremaining: 4m 49s\n",
            "22:\tlearn: 0.0535375\ttotal: 6.92s\tremaining: 4m 53s\n",
            "23:\tlearn: 0.0532615\ttotal: 7.22s\tremaining: 4m 53s\n",
            "24:\tlearn: 0.0529923\ttotal: 7.64s\tremaining: 4m 58s\n",
            "25:\tlearn: 0.0527374\ttotal: 7.9s\tremaining: 4m 55s\n",
            "26:\tlearn: 0.0524887\ttotal: 8.3s\tremaining: 4m 59s\n",
            "27:\tlearn: 0.0519058\ttotal: 8.72s\tremaining: 5m 2s\n",
            "28:\tlearn: 0.0516746\ttotal: 9.16s\tremaining: 5m 6s\n",
            "29:\tlearn: 0.0513214\ttotal: 9.55s\tremaining: 5m 8s\n",
            "30:\tlearn: 0.0510271\ttotal: 9.94s\tremaining: 5m 10s\n",
            "31:\tlearn: 0.0508851\ttotal: 10.3s\tremaining: 5m 11s\n",
            "32:\tlearn: 0.0507608\ttotal: 10.8s\tremaining: 5m 15s\n",
            "33:\tlearn: 0.0506017\ttotal: 11.1s\tremaining: 5m 15s\n",
            "34:\tlearn: 0.0504442\ttotal: 11.4s\tremaining: 5m 15s\n",
            "35:\tlearn: 0.0503090\ttotal: 11.9s\tremaining: 5m 17s\n",
            "36:\tlearn: 0.0501507\ttotal: 12.2s\tremaining: 5m 18s\n",
            "37:\tlearn: 0.0498658\ttotal: 12.6s\tremaining: 5m 18s\n",
            "38:\tlearn: 0.0496726\ttotal: 12.9s\tremaining: 5m 18s\n",
            "39:\tlearn: 0.0495635\ttotal: 13.3s\tremaining: 5m 20s\n",
            "40:\tlearn: 0.0493865\ttotal: 13.7s\tremaining: 5m 19s\n",
            "41:\tlearn: 0.0492829\ttotal: 14.1s\tremaining: 5m 20s\n",
            "42:\tlearn: 0.0491285\ttotal: 14.5s\tremaining: 5m 22s\n",
            "43:\tlearn: 0.0489959\ttotal: 14.9s\tremaining: 5m 24s\n",
            "44:\tlearn: 0.0488995\ttotal: 15.4s\tremaining: 5m 27s\n",
            "45:\tlearn: 0.0488183\ttotal: 15.8s\tremaining: 5m 26s\n",
            "46:\tlearn: 0.0487354\ttotal: 16.1s\tremaining: 5m 26s\n",
            "47:\tlearn: 0.0486159\ttotal: 16.4s\tremaining: 5m 25s\n",
            "48:\tlearn: 0.0485262\ttotal: 16.7s\tremaining: 5m 25s\n",
            "49:\tlearn: 0.0483872\ttotal: 17.2s\tremaining: 5m 26s\n",
            "50:\tlearn: 0.0483094\ttotal: 17.6s\tremaining: 5m 27s\n",
            "51:\tlearn: 0.0482021\ttotal: 18s\tremaining: 5m 28s\n",
            "52:\tlearn: 0.0481072\ttotal: 18.5s\tremaining: 5m 30s\n",
            "53:\tlearn: 0.0480400\ttotal: 18.8s\tremaining: 5m 30s\n",
            "54:\tlearn: 0.0479465\ttotal: 19.2s\tremaining: 5m 30s\n",
            "55:\tlearn: 0.0477686\ttotal: 19.7s\tremaining: 5m 31s\n",
            "56:\tlearn: 0.0476955\ttotal: 20s\tremaining: 5m 31s\n",
            "57:\tlearn: 0.0476057\ttotal: 20.4s\tremaining: 5m 31s\n",
            "58:\tlearn: 0.0475456\ttotal: 20.8s\tremaining: 5m 31s\n",
            "59:\tlearn: 0.0474385\ttotal: 21.1s\tremaining: 5m 31s\n",
            "60:\tlearn: 0.0473449\ttotal: 21.5s\tremaining: 5m 30s\n",
            "61:\tlearn: 0.0472676\ttotal: 21.9s\tremaining: 5m 31s\n",
            "62:\tlearn: 0.0471939\ttotal: 22.3s\tremaining: 5m 31s\n",
            "63:\tlearn: 0.0471383\ttotal: 22.7s\tremaining: 5m 31s\n",
            "64:\tlearn: 0.0470628\ttotal: 23s\tremaining: 5m 31s\n",
            "65:\tlearn: 0.0470001\ttotal: 23.4s\tremaining: 5m 30s\n",
            "66:\tlearn: 0.0469499\ttotal: 23.8s\tremaining: 5m 30s\n",
            "67:\tlearn: 0.0468988\ttotal: 24.1s\tremaining: 5m 30s\n",
            "68:\tlearn: 0.0468068\ttotal: 24.4s\tremaining: 5m 29s\n",
            "69:\tlearn: 0.0467174\ttotal: 24.8s\tremaining: 5m 30s\n",
            "70:\tlearn: 0.0466541\ttotal: 25.2s\tremaining: 5m 29s\n",
            "71:\tlearn: 0.0466210\ttotal: 25.5s\tremaining: 5m 28s\n",
            "72:\tlearn: 0.0465825\ttotal: 25.8s\tremaining: 5m 27s\n",
            "73:\tlearn: 0.0465329\ttotal: 26.2s\tremaining: 5m 28s\n",
            "74:\tlearn: 0.0464172\ttotal: 26.6s\tremaining: 5m 28s\n",
            "75:\tlearn: 0.0463448\ttotal: 27s\tremaining: 5m 28s\n",
            "76:\tlearn: 0.0462382\ttotal: 27.4s\tremaining: 5m 28s\n",
            "77:\tlearn: 0.0461812\ttotal: 27.8s\tremaining: 5m 28s\n",
            "78:\tlearn: 0.0461326\ttotal: 28.1s\tremaining: 5m 28s\n",
            "79:\tlearn: 0.0460819\ttotal: 28.5s\tremaining: 5m 28s\n",
            "80:\tlearn: 0.0460199\ttotal: 28.9s\tremaining: 5m 27s\n",
            "81:\tlearn: 0.0459678\ttotal: 29.3s\tremaining: 5m 27s\n",
            "82:\tlearn: 0.0458615\ttotal: 29.6s\tremaining: 5m 27s\n",
            "83:\tlearn: 0.0458204\ttotal: 30s\tremaining: 5m 26s\n",
            "84:\tlearn: 0.0457819\ttotal: 30.3s\tremaining: 5m 26s\n",
            "85:\tlearn: 0.0457048\ttotal: 30.7s\tremaining: 5m 25s\n",
            "86:\tlearn: 0.0456584\ttotal: 31s\tremaining: 5m 25s\n",
            "87:\tlearn: 0.0456133\ttotal: 31.4s\tremaining: 5m 25s\n",
            "88:\tlearn: 0.0455692\ttotal: 31.7s\tremaining: 5m 24s\n",
            "89:\tlearn: 0.0455050\ttotal: 32s\tremaining: 5m 23s\n",
            "90:\tlearn: 0.0454279\ttotal: 32.4s\tremaining: 5m 23s\n",
            "91:\tlearn: 0.0453753\ttotal: 32.6s\tremaining: 5m 22s\n",
            "92:\tlearn: 0.0453214\ttotal: 32.9s\tremaining: 5m 20s\n",
            "93:\tlearn: 0.0452711\ttotal: 33.3s\tremaining: 5m 20s\n",
            "94:\tlearn: 0.0452247\ttotal: 33.7s\tremaining: 5m 20s\n",
            "95:\tlearn: 0.0451769\ttotal: 34s\tremaining: 5m 20s\n",
            "96:\tlearn: 0.0451262\ttotal: 34.3s\tremaining: 5m 19s\n",
            "97:\tlearn: 0.0450799\ttotal: 34.6s\tremaining: 5m 18s\n",
            "98:\tlearn: 0.0450328\ttotal: 35.1s\tremaining: 5m 19s\n",
            "99:\tlearn: 0.0449937\ttotal: 35.4s\tremaining: 5m 18s\n",
            "100:\tlearn: 0.0449453\ttotal: 35.9s\tremaining: 5m 19s\n",
            "101:\tlearn: 0.0448265\ttotal: 36.4s\tremaining: 5m 20s\n",
            "102:\tlearn: 0.0447906\ttotal: 36.9s\tremaining: 5m 21s\n",
            "103:\tlearn: 0.0447289\ttotal: 37.2s\tremaining: 5m 20s\n",
            "104:\tlearn: 0.0446836\ttotal: 37.6s\tremaining: 5m 20s\n",
            "105:\tlearn: 0.0446469\ttotal: 38s\tremaining: 5m 20s\n",
            "106:\tlearn: 0.0446102\ttotal: 38.4s\tremaining: 5m 20s\n",
            "107:\tlearn: 0.0445797\ttotal: 38.8s\tremaining: 5m 20s\n",
            "108:\tlearn: 0.0445292\ttotal: 39.1s\tremaining: 5m 19s\n",
            "109:\tlearn: 0.0445078\ttotal: 39.5s\tremaining: 5m 19s\n",
            "110:\tlearn: 0.0444677\ttotal: 39.8s\tremaining: 5m 18s\n",
            "111:\tlearn: 0.0444450\ttotal: 40.2s\tremaining: 5m 18s\n",
            "112:\tlearn: 0.0443987\ttotal: 40.5s\tremaining: 5m 18s\n",
            "113:\tlearn: 0.0443139\ttotal: 40.9s\tremaining: 5m 17s\n",
            "114:\tlearn: 0.0442736\ttotal: 41.2s\tremaining: 5m 17s\n",
            "115:\tlearn: 0.0442430\ttotal: 41.6s\tremaining: 5m 17s\n",
            "116:\tlearn: 0.0442159\ttotal: 42s\tremaining: 5m 16s\n",
            "117:\tlearn: 0.0441877\ttotal: 42.4s\tremaining: 5m 16s\n",
            "118:\tlearn: 0.0441072\ttotal: 42.8s\tremaining: 5m 16s\n",
            "119:\tlearn: 0.0440757\ttotal: 43.1s\tremaining: 5m 16s\n",
            "120:\tlearn: 0.0440382\ttotal: 43.5s\tremaining: 5m 16s\n",
            "121:\tlearn: 0.0439807\ttotal: 43.9s\tremaining: 5m 16s\n",
            "122:\tlearn: 0.0439559\ttotal: 44.3s\tremaining: 5m 16s\n",
            "123:\tlearn: 0.0439263\ttotal: 44.7s\tremaining: 5m 15s\n",
            "124:\tlearn: 0.0438899\ttotal: 45.1s\tremaining: 5m 15s\n",
            "125:\tlearn: 0.0438513\ttotal: 45.6s\tremaining: 5m 16s\n",
            "126:\tlearn: 0.0438203\ttotal: 46s\tremaining: 5m 15s\n",
            "127:\tlearn: 0.0437247\ttotal: 46.3s\tremaining: 5m 15s\n",
            "128:\tlearn: 0.0436990\ttotal: 46.6s\tremaining: 5m 14s\n",
            "129:\tlearn: 0.0436540\ttotal: 47s\tremaining: 5m 14s\n",
            "130:\tlearn: 0.0436278\ttotal: 47.4s\tremaining: 5m 14s\n",
            "131:\tlearn: 0.0435935\ttotal: 47.7s\tremaining: 5m 13s\n",
            "132:\tlearn: 0.0435620\ttotal: 48.1s\tremaining: 5m 13s\n",
            "133:\tlearn: 0.0435306\ttotal: 48.5s\tremaining: 5m 13s\n",
            "134:\tlearn: 0.0435009\ttotal: 49s\tremaining: 5m 13s\n",
            "135:\tlearn: 0.0434893\ttotal: 49.3s\tremaining: 5m 13s\n",
            "136:\tlearn: 0.0434613\ttotal: 49.7s\tremaining: 5m 13s\n",
            "137:\tlearn: 0.0434216\ttotal: 50s\tremaining: 5m 12s\n",
            "138:\tlearn: 0.0433746\ttotal: 50.4s\tremaining: 5m 12s\n",
            "139:\tlearn: 0.0433415\ttotal: 50.8s\tremaining: 5m 12s\n",
            "140:\tlearn: 0.0433100\ttotal: 51.2s\tremaining: 5m 11s\n",
            "141:\tlearn: 0.0432571\ttotal: 51.5s\tremaining: 5m 11s\n",
            "142:\tlearn: 0.0432381\ttotal: 51.8s\tremaining: 5m 10s\n",
            "143:\tlearn: 0.0432130\ttotal: 52.2s\tremaining: 5m 10s\n",
            "144:\tlearn: 0.0431911\ttotal: 52.6s\tremaining: 5m 10s\n",
            "145:\tlearn: 0.0431773\ttotal: 52.9s\tremaining: 5m 9s\n",
            "146:\tlearn: 0.0431514\ttotal: 53.2s\tremaining: 5m 8s\n",
            "147:\tlearn: 0.0431322\ttotal: 53.5s\tremaining: 5m 7s\n",
            "148:\tlearn: 0.0430973\ttotal: 53.9s\tremaining: 5m 7s\n",
            "149:\tlearn: 0.0430686\ttotal: 54.2s\tremaining: 5m 7s\n",
            "150:\tlearn: 0.0430406\ttotal: 54.4s\tremaining: 5m 6s\n",
            "151:\tlearn: 0.0430048\ttotal: 54.7s\tremaining: 5m 5s\n",
            "152:\tlearn: 0.0429647\ttotal: 55.1s\tremaining: 5m 4s\n",
            "153:\tlearn: 0.0429490\ttotal: 55.3s\tremaining: 5m 3s\n",
            "154:\tlearn: 0.0429161\ttotal: 55.6s\tremaining: 5m 3s\n",
            "155:\tlearn: 0.0428856\ttotal: 55.9s\tremaining: 5m 2s\n",
            "156:\tlearn: 0.0428636\ttotal: 56.2s\tremaining: 5m 1s\n",
            "157:\tlearn: 0.0428302\ttotal: 56.3s\tremaining: 5m\n",
            "158:\tlearn: 0.0427799\ttotal: 56.5s\tremaining: 4m 58s\n",
            "159:\tlearn: 0.0427425\ttotal: 56.6s\tremaining: 4m 57s\n",
            "160:\tlearn: 0.0427219\ttotal: 56.7s\tremaining: 4m 55s\n",
            "161:\tlearn: 0.0426994\ttotal: 56.9s\tremaining: 4m 54s\n",
            "162:\tlearn: 0.0426822\ttotal: 57s\tremaining: 4m 52s\n",
            "163:\tlearn: 0.0426551\ttotal: 57.1s\tremaining: 4m 51s\n",
            "164:\tlearn: 0.0426283\ttotal: 57.2s\tremaining: 4m 49s\n",
            "165:\tlearn: 0.0425989\ttotal: 57.4s\tremaining: 4m 48s\n",
            "166:\tlearn: 0.0425903\ttotal: 57.5s\tremaining: 4m 46s\n",
            "167:\tlearn: 0.0425728\ttotal: 57.6s\tremaining: 4m 45s\n",
            "168:\tlearn: 0.0425514\ttotal: 57.7s\tremaining: 4m 43s\n",
            "169:\tlearn: 0.0425247\ttotal: 57.9s\tremaining: 4m 42s\n",
            "170:\tlearn: 0.0424985\ttotal: 58s\tremaining: 4m 41s\n",
            "171:\tlearn: 0.0424648\ttotal: 58.1s\tremaining: 4m 39s\n",
            "172:\tlearn: 0.0424461\ttotal: 58.2s\tremaining: 4m 38s\n",
            "173:\tlearn: 0.0424179\ttotal: 58.3s\tremaining: 4m 36s\n",
            "174:\tlearn: 0.0423741\ttotal: 58.5s\tremaining: 4m 35s\n",
            "175:\tlearn: 0.0423503\ttotal: 58.6s\tremaining: 4m 34s\n",
            "176:\tlearn: 0.0423206\ttotal: 58.7s\tremaining: 4m 33s\n",
            "177:\tlearn: 0.0423135\ttotal: 58.8s\tremaining: 4m 31s\n",
            "178:\tlearn: 0.0422991\ttotal: 58.9s\tremaining: 4m 30s\n",
            "179:\tlearn: 0.0422721\ttotal: 59.1s\tremaining: 4m 29s\n",
            "180:\tlearn: 0.0422508\ttotal: 59.2s\tremaining: 4m 27s\n",
            "181:\tlearn: 0.0422108\ttotal: 59.3s\tremaining: 4m 26s\n",
            "182:\tlearn: 0.0421870\ttotal: 59.4s\tremaining: 4m 25s\n",
            "183:\tlearn: 0.0421531\ttotal: 59.6s\tremaining: 4m 24s\n",
            "184:\tlearn: 0.0421282\ttotal: 59.7s\tremaining: 4m 23s\n",
            "185:\tlearn: 0.0421076\ttotal: 59.8s\tremaining: 4m 21s\n",
            "186:\tlearn: 0.0420798\ttotal: 60s\tremaining: 4m 20s\n",
            "187:\tlearn: 0.0420629\ttotal: 1m\tremaining: 4m 19s\n",
            "188:\tlearn: 0.0420161\ttotal: 1m\tremaining: 4m 18s\n",
            "189:\tlearn: 0.0419893\ttotal: 1m\tremaining: 4m 17s\n",
            "190:\tlearn: 0.0419761\ttotal: 1m\tremaining: 4m 16s\n",
            "191:\tlearn: 0.0419761\ttotal: 1m\tremaining: 4m 14s\n",
            "192:\tlearn: 0.0419503\ttotal: 1m\tremaining: 4m 13s\n",
            "193:\tlearn: 0.0419503\ttotal: 1m\tremaining: 4m 12s\n",
            "194:\tlearn: 0.0419503\ttotal: 1m\tremaining: 4m 11s\n",
            "195:\tlearn: 0.0419503\ttotal: 1m 1s\tremaining: 4m 10s\n",
            "196:\tlearn: 0.0419292\ttotal: 1m 1s\tremaining: 4m 9s\n",
            "197:\tlearn: 0.0419292\ttotal: 1m 1s\tremaining: 4m 8s\n",
            "198:\tlearn: 0.0419292\ttotal: 1m 1s\tremaining: 4m 6s\n",
            "199:\tlearn: 0.0419064\ttotal: 1m 1s\tremaining: 4m 5s\n",
            "200:\tlearn: 0.0418919\ttotal: 1m 1s\tremaining: 4m 4s\n",
            "201:\tlearn: 0.0418745\ttotal: 1m 1s\tremaining: 4m 3s\n",
            "202:\tlearn: 0.0418745\ttotal: 1m 1s\tremaining: 4m 2s\n",
            "203:\tlearn: 0.0418745\ttotal: 1m 1s\tremaining: 4m 1s\n",
            "204:\tlearn: 0.0418745\ttotal: 1m 2s\tremaining: 4m\n",
            "205:\tlearn: 0.0418745\ttotal: 1m 2s\tremaining: 3m 59s\n",
            "206:\tlearn: 0.0418416\ttotal: 1m 2s\tremaining: 3m 58s\n",
            "207:\tlearn: 0.0418416\ttotal: 1m 2s\tremaining: 3m 57s\n",
            "208:\tlearn: 0.0418166\ttotal: 1m 2s\tremaining: 3m 56s\n",
            "209:\tlearn: 0.0418159\ttotal: 1m 2s\tremaining: 3m 55s\n",
            "210:\tlearn: 0.0418024\ttotal: 1m 2s\tremaining: 3m 54s\n",
            "211:\tlearn: 0.0417805\ttotal: 1m 2s\tremaining: 3m 53s\n",
            "212:\tlearn: 0.0417590\ttotal: 1m 3s\tremaining: 3m 52s\n",
            "213:\tlearn: 0.0417590\ttotal: 1m 3s\tremaining: 3m 51s\n",
            "214:\tlearn: 0.0417590\ttotal: 1m 3s\tremaining: 3m 50s\n",
            "215:\tlearn: 0.0417373\ttotal: 1m 3s\tremaining: 3m 49s\n",
            "216:\tlearn: 0.0417373\ttotal: 1m 3s\tremaining: 3m 48s\n",
            "217:\tlearn: 0.0417146\ttotal: 1m 3s\tremaining: 3m 47s\n",
            "218:\tlearn: 0.0417041\ttotal: 1m 3s\tremaining: 3m 47s\n",
            "219:\tlearn: 0.0417041\ttotal: 1m 3s\tremaining: 3m 46s\n",
            "220:\tlearn: 0.0416856\ttotal: 1m 3s\tremaining: 3m 45s\n",
            "221:\tlearn: 0.0416857\ttotal: 1m 3s\tremaining: 3m 44s\n",
            "222:\tlearn: 0.0416856\ttotal: 1m 4s\tremaining: 3m 43s\n",
            "223:\tlearn: 0.0416563\ttotal: 1m 4s\tremaining: 3m 42s\n",
            "224:\tlearn: 0.0416563\ttotal: 1m 4s\tremaining: 3m 41s\n",
            "225:\tlearn: 0.0416563\ttotal: 1m 4s\tremaining: 3m 40s\n",
            "226:\tlearn: 0.0416296\ttotal: 1m 4s\tremaining: 3m 39s\n",
            "227:\tlearn: 0.0416296\ttotal: 1m 4s\tremaining: 3m 38s\n",
            "228:\tlearn: 0.0416296\ttotal: 1m 4s\tremaining: 3m 38s\n",
            "229:\tlearn: 0.0416296\ttotal: 1m 4s\tremaining: 3m 37s\n",
            "230:\tlearn: 0.0415972\ttotal: 1m 4s\tremaining: 3m 36s\n",
            "231:\tlearn: 0.0415818\ttotal: 1m 5s\tremaining: 3m 35s\n",
            "232:\tlearn: 0.0415640\ttotal: 1m 5s\tremaining: 3m 34s\n",
            "233:\tlearn: 0.0415640\ttotal: 1m 5s\tremaining: 3m 33s\n",
            "234:\tlearn: 0.0415433\ttotal: 1m 5s\tremaining: 3m 33s\n",
            "235:\tlearn: 0.0415433\ttotal: 1m 5s\tremaining: 3m 32s\n",
            "236:\tlearn: 0.0415433\ttotal: 1m 5s\tremaining: 3m 31s\n",
            "237:\tlearn: 0.0415433\ttotal: 1m 5s\tremaining: 3m 30s\n",
            "238:\tlearn: 0.0415165\ttotal: 1m 5s\tremaining: 3m 29s\n",
            "239:\tlearn: 0.0415165\ttotal: 1m 5s\tremaining: 3m 28s\n",
            "240:\tlearn: 0.0415165\ttotal: 1m 6s\tremaining: 3m 28s\n",
            "241:\tlearn: 0.0414921\ttotal: 1m 6s\tremaining: 3m 27s\n",
            "242:\tlearn: 0.0414692\ttotal: 1m 6s\tremaining: 3m 26s\n",
            "243:\tlearn: 0.0414692\ttotal: 1m 6s\tremaining: 3m 25s\n",
            "244:\tlearn: 0.0414690\ttotal: 1m 6s\tremaining: 3m 24s\n",
            "245:\tlearn: 0.0414690\ttotal: 1m 6s\tremaining: 3m 24s\n",
            "246:\tlearn: 0.0414689\ttotal: 1m 6s\tremaining: 3m 23s\n",
            "247:\tlearn: 0.0414505\ttotal: 1m 6s\tremaining: 3m 22s\n",
            "248:\tlearn: 0.0414445\ttotal: 1m 6s\tremaining: 3m 21s\n",
            "249:\tlearn: 0.0414445\ttotal: 1m 7s\tremaining: 3m 21s\n",
            "250:\tlearn: 0.0414445\ttotal: 1m 7s\tremaining: 3m 20s\n",
            "251:\tlearn: 0.0414445\ttotal: 1m 7s\tremaining: 3m 19s\n",
            "252:\tlearn: 0.0414445\ttotal: 1m 7s\tremaining: 3m 18s\n",
            "253:\tlearn: 0.0414445\ttotal: 1m 7s\tremaining: 3m 18s\n",
            "254:\tlearn: 0.0414445\ttotal: 1m 7s\tremaining: 3m 17s\n",
            "255:\tlearn: 0.0414444\ttotal: 1m 7s\tremaining: 3m 16s\n",
            "256:\tlearn: 0.0414152\ttotal: 1m 7s\tremaining: 3m 15s\n",
            "257:\tlearn: 0.0413882\ttotal: 1m 7s\tremaining: 3m 15s\n",
            "258:\tlearn: 0.0413701\ttotal: 1m 8s\tremaining: 3m 14s\n",
            "259:\tlearn: 0.0413526\ttotal: 1m 8s\tremaining: 3m 13s\n",
            "260:\tlearn: 0.0413526\ttotal: 1m 8s\tremaining: 3m 13s\n",
            "261:\tlearn: 0.0413526\ttotal: 1m 8s\tremaining: 3m 12s\n",
            "262:\tlearn: 0.0413309\ttotal: 1m 8s\tremaining: 3m 11s\n",
            "263:\tlearn: 0.0413125\ttotal: 1m 8s\tremaining: 3m 11s\n",
            "264:\tlearn: 0.0413125\ttotal: 1m 8s\tremaining: 3m 10s\n",
            "265:\tlearn: 0.0413122\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "266:\tlearn: 0.0413121\ttotal: 1m 8s\tremaining: 3m 9s\n",
            "267:\tlearn: 0.0412819\ttotal: 1m 9s\tremaining: 3m 8s\n",
            "268:\tlearn: 0.0412726\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "269:\tlearn: 0.0412550\ttotal: 1m 9s\tremaining: 3m 7s\n",
            "270:\tlearn: 0.0412374\ttotal: 1m 9s\tremaining: 3m 6s\n",
            "271:\tlearn: 0.0412146\ttotal: 1m 9s\tremaining: 3m 6s\n",
            "272:\tlearn: 0.0412145\ttotal: 1m 9s\tremaining: 3m 5s\n",
            "273:\tlearn: 0.0411929\ttotal: 1m 9s\tremaining: 3m 4s\n",
            "274:\tlearn: 0.0411804\ttotal: 1m 9s\tremaining: 3m 4s\n",
            "275:\tlearn: 0.0411600\ttotal: 1m 10s\tremaining: 3m 3s\n",
            "276:\tlearn: 0.0411600\ttotal: 1m 10s\tremaining: 3m 3s\n",
            "277:\tlearn: 0.0411600\ttotal: 1m 10s\tremaining: 3m 2s\n",
            "278:\tlearn: 0.0411599\ttotal: 1m 10s\tremaining: 3m 1s\n",
            "279:\tlearn: 0.0411407\ttotal: 1m 10s\tremaining: 3m 1s\n",
            "280:\tlearn: 0.0411280\ttotal: 1m 10s\tremaining: 3m\n",
            "281:\tlearn: 0.0411280\ttotal: 1m 10s\tremaining: 2m 59s\n",
            "282:\tlearn: 0.0411100\ttotal: 1m 10s\tremaining: 2m 59s\n",
            "283:\tlearn: 0.0411100\ttotal: 1m 10s\tremaining: 2m 58s\n",
            "284:\tlearn: 0.0410958\ttotal: 1m 11s\tremaining: 2m 58s\n",
            "285:\tlearn: 0.0410958\ttotal: 1m 11s\tremaining: 2m 57s\n",
            "286:\tlearn: 0.0410758\ttotal: 1m 11s\tremaining: 2m 56s\n",
            "287:\tlearn: 0.0410523\ttotal: 1m 11s\tremaining: 2m 56s\n",
            "288:\tlearn: 0.0410162\ttotal: 1m 11s\tremaining: 2m 55s\n",
            "289:\tlearn: 0.0410162\ttotal: 1m 11s\tremaining: 2m 55s\n",
            "290:\tlearn: 0.0409873\ttotal: 1m 11s\tremaining: 2m 54s\n",
            "291:\tlearn: 0.0409873\ttotal: 1m 11s\tremaining: 2m 54s\n",
            "292:\tlearn: 0.0409873\ttotal: 1m 11s\tremaining: 2m 53s\n",
            "293:\tlearn: 0.0409695\ttotal: 1m 12s\tremaining: 2m 53s\n",
            "294:\tlearn: 0.0409653\ttotal: 1m 12s\tremaining: 2m 52s\n",
            "295:\tlearn: 0.0409532\ttotal: 1m 12s\tremaining: 2m 51s\n",
            "296:\tlearn: 0.0409292\ttotal: 1m 12s\tremaining: 2m 51s\n",
            "297:\tlearn: 0.0409209\ttotal: 1m 12s\tremaining: 2m 50s\n",
            "298:\tlearn: 0.0409048\ttotal: 1m 12s\tremaining: 2m 50s\n",
            "299:\tlearn: 0.0409048\ttotal: 1m 12s\tremaining: 2m 49s\n",
            "300:\tlearn: 0.0408924\ttotal: 1m 12s\tremaining: 2m 49s\n",
            "301:\tlearn: 0.0408739\ttotal: 1m 13s\tremaining: 2m 48s\n",
            "302:\tlearn: 0.0408644\ttotal: 1m 13s\tremaining: 2m 48s\n",
            "303:\tlearn: 0.0408573\ttotal: 1m 13s\tremaining: 2m 47s\n",
            "304:\tlearn: 0.0408425\ttotal: 1m 13s\tremaining: 2m 47s\n",
            "305:\tlearn: 0.0408229\ttotal: 1m 13s\tremaining: 2m 46s\n",
            "306:\tlearn: 0.0408060\ttotal: 1m 13s\tremaining: 2m 46s\n",
            "307:\tlearn: 0.0407831\ttotal: 1m 13s\tremaining: 2m 45s\n",
            "308:\tlearn: 0.0407831\ttotal: 1m 13s\tremaining: 2m 45s\n",
            "309:\tlearn: 0.0407831\ttotal: 1m 13s\tremaining: 2m 44s\n",
            "310:\tlearn: 0.0407828\ttotal: 1m 14s\tremaining: 2m 44s\n",
            "311:\tlearn: 0.0407827\ttotal: 1m 14s\tremaining: 2m 43s\n",
            "312:\tlearn: 0.0407678\ttotal: 1m 14s\tremaining: 2m 43s\n",
            "313:\tlearn: 0.0407678\ttotal: 1m 14s\tremaining: 2m 42s\n",
            "314:\tlearn: 0.0407678\ttotal: 1m 14s\tremaining: 2m 41s\n",
            "315:\tlearn: 0.0407678\ttotal: 1m 14s\tremaining: 2m 41s\n",
            "316:\tlearn: 0.0407678\ttotal: 1m 14s\tremaining: 2m 40s\n",
            "317:\tlearn: 0.0407566\ttotal: 1m 14s\tremaining: 2m 40s\n",
            "318:\tlearn: 0.0407296\ttotal: 1m 14s\tremaining: 2m 39s\n",
            "319:\tlearn: 0.0407128\ttotal: 1m 15s\tremaining: 2m 39s\n",
            "320:\tlearn: 0.0406983\ttotal: 1m 15s\tremaining: 2m 38s\n",
            "321:\tlearn: 0.0406687\ttotal: 1m 15s\tremaining: 2m 38s\n",
            "322:\tlearn: 0.0406687\ttotal: 1m 15s\tremaining: 2m 37s\n",
            "323:\tlearn: 0.0406502\ttotal: 1m 15s\tremaining: 2m 37s\n",
            "324:\tlearn: 0.0406502\ttotal: 1m 15s\tremaining: 2m 36s\n",
            "325:\tlearn: 0.0406291\ttotal: 1m 15s\tremaining: 2m 36s\n",
            "326:\tlearn: 0.0406084\ttotal: 1m 15s\tremaining: 2m 36s\n",
            "327:\tlearn: 0.0405924\ttotal: 1m 15s\tremaining: 2m 35s\n",
            "328:\tlearn: 0.0405742\ttotal: 1m 16s\tremaining: 2m 35s\n",
            "329:\tlearn: 0.0405639\ttotal: 1m 16s\tremaining: 2m 34s\n",
            "330:\tlearn: 0.0405593\ttotal: 1m 16s\tremaining: 2m 34s\n",
            "331:\tlearn: 0.0405408\ttotal: 1m 16s\tremaining: 2m 33s\n",
            "332:\tlearn: 0.0405233\ttotal: 1m 16s\tremaining: 2m 33s\n",
            "333:\tlearn: 0.0405044\ttotal: 1m 16s\tremaining: 2m 32s\n",
            "334:\tlearn: 0.0404878\ttotal: 1m 16s\tremaining: 2m 32s\n",
            "335:\tlearn: 0.0404809\ttotal: 1m 16s\tremaining: 2m 31s\n",
            "336:\tlearn: 0.0404665\ttotal: 1m 17s\tremaining: 2m 31s\n",
            "337:\tlearn: 0.0404569\ttotal: 1m 17s\tremaining: 2m 31s\n",
            "338:\tlearn: 0.0404418\ttotal: 1m 17s\tremaining: 2m 30s\n",
            "339:\tlearn: 0.0404181\ttotal: 1m 17s\tremaining: 2m 30s\n",
            "340:\tlearn: 0.0404059\ttotal: 1m 17s\tremaining: 2m 29s\n",
            "341:\tlearn: 0.0403918\ttotal: 1m 17s\tremaining: 2m 29s\n",
            "342:\tlearn: 0.0403791\ttotal: 1m 17s\tremaining: 2m 28s\n",
            "343:\tlearn: 0.0403667\ttotal: 1m 17s\tremaining: 2m 28s\n",
            "344:\tlearn: 0.0403444\ttotal: 1m 18s\tremaining: 2m 28s\n",
            "345:\tlearn: 0.0403371\ttotal: 1m 18s\tremaining: 2m 27s\n",
            "346:\tlearn: 0.0403145\ttotal: 1m 18s\tremaining: 2m 27s\n",
            "347:\tlearn: 0.0402934\ttotal: 1m 18s\tremaining: 2m 26s\n",
            "348:\tlearn: 0.0402774\ttotal: 1m 18s\tremaining: 2m 26s\n",
            "349:\tlearn: 0.0402702\ttotal: 1m 18s\tremaining: 2m 26s\n",
            "350:\tlearn: 0.0402701\ttotal: 1m 18s\tremaining: 2m 25s\n",
            "351:\tlearn: 0.0402607\ttotal: 1m 18s\tremaining: 2m 25s\n",
            "352:\tlearn: 0.0402606\ttotal: 1m 18s\tremaining: 2m 24s\n",
            "353:\tlearn: 0.0402607\ttotal: 1m 19s\tremaining: 2m 24s\n",
            "354:\tlearn: 0.0402607\ttotal: 1m 19s\tremaining: 2m 23s\n",
            "355:\tlearn: 0.0402606\ttotal: 1m 19s\tremaining: 2m 23s\n",
            "356:\tlearn: 0.0402606\ttotal: 1m 19s\tremaining: 2m 22s\n",
            "357:\tlearn: 0.0402606\ttotal: 1m 19s\tremaining: 2m 22s\n",
            "358:\tlearn: 0.0402606\ttotal: 1m 19s\tremaining: 2m 22s\n",
            "359:\tlearn: 0.0402606\ttotal: 1m 19s\tremaining: 2m 21s\n",
            "360:\tlearn: 0.0402604\ttotal: 1m 19s\tremaining: 2m 21s\n",
            "361:\tlearn: 0.0402604\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "362:\tlearn: 0.0402604\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "363:\tlearn: 0.0402604\ttotal: 1m 20s\tremaining: 2m 19s\n",
            "364:\tlearn: 0.0402603\ttotal: 1m 20s\tremaining: 2m 19s\n",
            "365:\tlearn: 0.0402603\ttotal: 1m 20s\tremaining: 2m 19s\n",
            "366:\tlearn: 0.0402602\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "367:\tlearn: 0.0402602\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "368:\tlearn: 0.0402601\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "369:\tlearn: 0.0402586\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "370:\tlearn: 0.0402436\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "371:\tlearn: 0.0402283\ttotal: 1m 20s\tremaining: 2m 16s\n",
            "372:\tlearn: 0.0402131\ttotal: 1m 21s\tremaining: 2m 16s\n",
            "373:\tlearn: 0.0401918\ttotal: 1m 21s\tremaining: 2m 15s\n",
            "374:\tlearn: 0.0401822\ttotal: 1m 21s\tremaining: 2m 15s\n",
            "375:\tlearn: 0.0401590\ttotal: 1m 21s\tremaining: 2m 15s\n",
            "376:\tlearn: 0.0401371\ttotal: 1m 21s\tremaining: 2m 14s\n",
            "377:\tlearn: 0.0401163\ttotal: 1m 21s\tremaining: 2m 14s\n",
            "378:\tlearn: 0.0400986\ttotal: 1m 21s\tremaining: 2m 14s\n",
            "379:\tlearn: 0.0400782\ttotal: 1m 21s\tremaining: 2m 13s\n",
            "380:\tlearn: 0.0400622\ttotal: 1m 22s\tremaining: 2m 13s\n",
            "381:\tlearn: 0.0400460\ttotal: 1m 22s\tremaining: 2m 12s\n",
            "382:\tlearn: 0.0400445\ttotal: 1m 22s\tremaining: 2m 12s\n",
            "383:\tlearn: 0.0400257\ttotal: 1m 22s\tremaining: 2m 12s\n",
            "384:\tlearn: 0.0400123\ttotal: 1m 22s\tremaining: 2m 11s\n",
            "385:\tlearn: 0.0399949\ttotal: 1m 22s\tremaining: 2m 11s\n",
            "386:\tlearn: 0.0399712\ttotal: 1m 22s\tremaining: 2m 11s\n",
            "387:\tlearn: 0.0399562\ttotal: 1m 22s\tremaining: 2m 10s\n",
            "388:\tlearn: 0.0399436\ttotal: 1m 23s\tremaining: 2m 10s\n",
            "389:\tlearn: 0.0399285\ttotal: 1m 23s\tremaining: 2m 10s\n",
            "390:\tlearn: 0.0399179\ttotal: 1m 23s\tremaining: 2m 9s\n",
            "391:\tlearn: 0.0399126\ttotal: 1m 23s\tremaining: 2m 9s\n",
            "392:\tlearn: 0.0398874\ttotal: 1m 23s\tremaining: 2m 9s\n",
            "393:\tlearn: 0.0398815\ttotal: 1m 23s\tremaining: 2m 8s\n",
            "394:\tlearn: 0.0398687\ttotal: 1m 23s\tremaining: 2m 8s\n",
            "395:\tlearn: 0.0398540\ttotal: 1m 23s\tremaining: 2m 7s\n",
            "396:\tlearn: 0.0398383\ttotal: 1m 24s\tremaining: 2m 7s\n",
            "397:\tlearn: 0.0398383\ttotal: 1m 24s\tremaining: 2m 7s\n",
            "398:\tlearn: 0.0398015\ttotal: 1m 24s\tremaining: 2m 6s\n",
            "399:\tlearn: 0.0397906\ttotal: 1m 24s\tremaining: 2m 6s\n",
            "400:\tlearn: 0.0397704\ttotal: 1m 24s\tremaining: 2m 6s\n",
            "401:\tlearn: 0.0397459\ttotal: 1m 24s\tremaining: 2m 5s\n",
            "402:\tlearn: 0.0397288\ttotal: 1m 24s\tremaining: 2m 5s\n",
            "403:\tlearn: 0.0397283\ttotal: 1m 24s\tremaining: 2m 5s\n",
            "404:\tlearn: 0.0397283\ttotal: 1m 24s\tremaining: 2m 4s\n",
            "405:\tlearn: 0.0397283\ttotal: 1m 25s\tremaining: 2m 4s\n",
            "406:\tlearn: 0.0397146\ttotal: 1m 25s\tremaining: 2m 4s\n",
            "407:\tlearn: 0.0397145\ttotal: 1m 25s\tremaining: 2m 3s\n",
            "408:\tlearn: 0.0397145\ttotal: 1m 25s\tremaining: 2m 3s\n",
            "409:\tlearn: 0.0397145\ttotal: 1m 25s\tremaining: 2m 3s\n",
            "410:\tlearn: 0.0397145\ttotal: 1m 25s\tremaining: 2m 2s\n",
            "411:\tlearn: 0.0397145\ttotal: 1m 25s\tremaining: 2m 2s\n",
            "412:\tlearn: 0.0397145\ttotal: 1m 25s\tremaining: 2m 2s\n",
            "413:\tlearn: 0.0396929\ttotal: 1m 25s\tremaining: 2m 1s\n",
            "414:\tlearn: 0.0396806\ttotal: 1m 26s\tremaining: 2m 1s\n",
            "415:\tlearn: 0.0396806\ttotal: 1m 26s\tremaining: 2m 1s\n",
            "416:\tlearn: 0.0396659\ttotal: 1m 26s\tremaining: 2m\n",
            "417:\tlearn: 0.0396512\ttotal: 1m 26s\tremaining: 2m\n",
            "418:\tlearn: 0.0396395\ttotal: 1m 26s\tremaining: 2m\n",
            "419:\tlearn: 0.0396217\ttotal: 1m 26s\tremaining: 1m 59s\n",
            "420:\tlearn: 0.0396082\ttotal: 1m 26s\tremaining: 1m 59s\n",
            "421:\tlearn: 0.0395961\ttotal: 1m 26s\tremaining: 1m 59s\n",
            "422:\tlearn: 0.0395961\ttotal: 1m 27s\tremaining: 1m 58s\n",
            "423:\tlearn: 0.0395961\ttotal: 1m 27s\tremaining: 1m 58s\n",
            "424:\tlearn: 0.0395961\ttotal: 1m 27s\tremaining: 1m 58s\n",
            "425:\tlearn: 0.0395960\ttotal: 1m 27s\tremaining: 1m 57s\n",
            "426:\tlearn: 0.0395960\ttotal: 1m 27s\tremaining: 1m 57s\n",
            "427:\tlearn: 0.0395960\ttotal: 1m 27s\tremaining: 1m 57s\n",
            "428:\tlearn: 0.0395960\ttotal: 1m 27s\tremaining: 1m 56s\n",
            "429:\tlearn: 0.0395959\ttotal: 1m 27s\tremaining: 1m 56s\n",
            "430:\tlearn: 0.0395872\ttotal: 1m 27s\tremaining: 1m 56s\n",
            "431:\tlearn: 0.0395871\ttotal: 1m 28s\tremaining: 1m 55s\n",
            "432:\tlearn: 0.0395871\ttotal: 1m 28s\tremaining: 1m 55s\n",
            "433:\tlearn: 0.0395871\ttotal: 1m 28s\tremaining: 1m 55s\n",
            "434:\tlearn: 0.0395593\ttotal: 1m 28s\tremaining: 1m 54s\n",
            "435:\tlearn: 0.0395538\ttotal: 1m 28s\tremaining: 1m 54s\n",
            "436:\tlearn: 0.0395297\ttotal: 1m 28s\tremaining: 1m 54s\n",
            "437:\tlearn: 0.0395115\ttotal: 1m 28s\tremaining: 1m 53s\n",
            "438:\tlearn: 0.0394947\ttotal: 1m 28s\tremaining: 1m 53s\n",
            "439:\tlearn: 0.0394809\ttotal: 1m 28s\tremaining: 1m 53s\n",
            "440:\tlearn: 0.0394670\ttotal: 1m 29s\tremaining: 1m 52s\n",
            "441:\tlearn: 0.0394670\ttotal: 1m 29s\tremaining: 1m 52s\n",
            "442:\tlearn: 0.0394612\ttotal: 1m 29s\tremaining: 1m 52s\n",
            "443:\tlearn: 0.0394492\ttotal: 1m 29s\tremaining: 1m 51s\n",
            "444:\tlearn: 0.0394334\ttotal: 1m 29s\tremaining: 1m 51s\n",
            "445:\tlearn: 0.0394187\ttotal: 1m 29s\tremaining: 1m 51s\n",
            "446:\tlearn: 0.0394086\ttotal: 1m 29s\tremaining: 1m 51s\n",
            "447:\tlearn: 0.0393911\ttotal: 1m 29s\tremaining: 1m 50s\n",
            "448:\tlearn: 0.0393911\ttotal: 1m 29s\tremaining: 1m 50s\n",
            "449:\tlearn: 0.0393872\ttotal: 1m 30s\tremaining: 1m 50s\n",
            "450:\tlearn: 0.0393872\ttotal: 1m 30s\tremaining: 1m 49s\n",
            "451:\tlearn: 0.0393805\ttotal: 1m 30s\tremaining: 1m 49s\n",
            "452:\tlearn: 0.0393597\ttotal: 1m 30s\tremaining: 1m 49s\n",
            "453:\tlearn: 0.0393529\ttotal: 1m 30s\tremaining: 1m 48s\n",
            "454:\tlearn: 0.0393329\ttotal: 1m 30s\tremaining: 1m 48s\n",
            "455:\tlearn: 0.0393095\ttotal: 1m 30s\tremaining: 1m 48s\n",
            "456:\tlearn: 0.0392937\ttotal: 1m 30s\tremaining: 1m 48s\n",
            "457:\tlearn: 0.0392937\ttotal: 1m 31s\tremaining: 1m 47s\n",
            "458:\tlearn: 0.0392937\ttotal: 1m 31s\tremaining: 1m 47s\n",
            "459:\tlearn: 0.0392839\ttotal: 1m 31s\tremaining: 1m 47s\n",
            "460:\tlearn: 0.0392617\ttotal: 1m 31s\tremaining: 1m 46s\n",
            "461:\tlearn: 0.0392519\ttotal: 1m 31s\tremaining: 1m 46s\n",
            "462:\tlearn: 0.0392378\ttotal: 1m 31s\tremaining: 1m 46s\n",
            "463:\tlearn: 0.0392378\ttotal: 1m 31s\tremaining: 1m 46s\n",
            "464:\tlearn: 0.0392377\ttotal: 1m 31s\tremaining: 1m 45s\n",
            "465:\tlearn: 0.0392377\ttotal: 1m 31s\tremaining: 1m 45s\n",
            "466:\tlearn: 0.0392377\ttotal: 1m 32s\tremaining: 1m 45s\n",
            "467:\tlearn: 0.0392377\ttotal: 1m 32s\tremaining: 1m 44s\n",
            "468:\tlearn: 0.0392377\ttotal: 1m 32s\tremaining: 1m 44s\n",
            "469:\tlearn: 0.0392142\ttotal: 1m 32s\tremaining: 1m 44s\n",
            "470:\tlearn: 0.0392010\ttotal: 1m 32s\tremaining: 1m 43s\n",
            "471:\tlearn: 0.0391838\ttotal: 1m 32s\tremaining: 1m 43s\n",
            "472:\tlearn: 0.0391653\ttotal: 1m 32s\tremaining: 1m 43s\n",
            "473:\tlearn: 0.0391511\ttotal: 1m 32s\tremaining: 1m 43s\n",
            "474:\tlearn: 0.0391333\ttotal: 1m 33s\tremaining: 1m 42s\n",
            "475:\tlearn: 0.0391161\ttotal: 1m 33s\tremaining: 1m 42s\n",
            "476:\tlearn: 0.0391041\ttotal: 1m 33s\tremaining: 1m 42s\n",
            "477:\tlearn: 0.0390898\ttotal: 1m 33s\tremaining: 1m 42s\n",
            "478:\tlearn: 0.0390802\ttotal: 1m 33s\tremaining: 1m 41s\n",
            "479:\tlearn: 0.0390573\ttotal: 1m 33s\tremaining: 1m 41s\n",
            "480:\tlearn: 0.0390396\ttotal: 1m 33s\tremaining: 1m 41s\n",
            "481:\tlearn: 0.0390209\ttotal: 1m 33s\tremaining: 1m 40s\n",
            "482:\tlearn: 0.0390095\ttotal: 1m 34s\tremaining: 1m 40s\n",
            "483:\tlearn: 0.0389957\ttotal: 1m 34s\tremaining: 1m 40s\n",
            "484:\tlearn: 0.0389957\ttotal: 1m 34s\tremaining: 1m 40s\n",
            "485:\tlearn: 0.0389875\ttotal: 1m 34s\tremaining: 1m 39s\n",
            "486:\tlearn: 0.0389875\ttotal: 1m 34s\tremaining: 1m 39s\n",
            "487:\tlearn: 0.0389875\ttotal: 1m 34s\tremaining: 1m 39s\n",
            "488:\tlearn: 0.0389875\ttotal: 1m 34s\tremaining: 1m 39s\n",
            "489:\tlearn: 0.0389874\ttotal: 1m 34s\tremaining: 1m 38s\n",
            "490:\tlearn: 0.0389874\ttotal: 1m 34s\tremaining: 1m 38s\n",
            "491:\tlearn: 0.0389874\ttotal: 1m 35s\tremaining: 1m 38s\n",
            "492:\tlearn: 0.0389874\ttotal: 1m 35s\tremaining: 1m 37s\n",
            "493:\tlearn: 0.0389874\ttotal: 1m 35s\tremaining: 1m 37s\n",
            "494:\tlearn: 0.0389874\ttotal: 1m 35s\tremaining: 1m 37s\n",
            "495:\tlearn: 0.0389862\ttotal: 1m 35s\tremaining: 1m 37s\n",
            "496:\tlearn: 0.0389862\ttotal: 1m 35s\tremaining: 1m 36s\n",
            "497:\tlearn: 0.0389862\ttotal: 1m 35s\tremaining: 1m 36s\n",
            "498:\tlearn: 0.0389862\ttotal: 1m 35s\tremaining: 1m 36s\n",
            "499:\tlearn: 0.0389862\ttotal: 1m 36s\tremaining: 1m 36s\n",
            "500:\tlearn: 0.0389862\ttotal: 1m 36s\tremaining: 1m 35s\n",
            "501:\tlearn: 0.0389749\ttotal: 1m 36s\tremaining: 1m 35s\n",
            "502:\tlearn: 0.0389600\ttotal: 1m 36s\tremaining: 1m 35s\n",
            "503:\tlearn: 0.0389499\ttotal: 1m 36s\tremaining: 1m 34s\n",
            "504:\tlearn: 0.0389399\ttotal: 1m 36s\tremaining: 1m 34s\n",
            "505:\tlearn: 0.0389294\ttotal: 1m 36s\tremaining: 1m 34s\n",
            "506:\tlearn: 0.0389196\ttotal: 1m 36s\tremaining: 1m 34s\n",
            "507:\tlearn: 0.0389196\ttotal: 1m 36s\tremaining: 1m 33s\n",
            "508:\tlearn: 0.0389012\ttotal: 1m 37s\tremaining: 1m 33s\n",
            "509:\tlearn: 0.0388898\ttotal: 1m 37s\tremaining: 1m 33s\n",
            "510:\tlearn: 0.0388725\ttotal: 1m 37s\tremaining: 1m 33s\n",
            "511:\tlearn: 0.0388725\ttotal: 1m 37s\tremaining: 1m 32s\n",
            "512:\tlearn: 0.0388685\ttotal: 1m 37s\tremaining: 1m 32s\n",
            "513:\tlearn: 0.0388532\ttotal: 1m 37s\tremaining: 1m 32s\n",
            "514:\tlearn: 0.0388381\ttotal: 1m 37s\tremaining: 1m 32s\n",
            "515:\tlearn: 0.0388381\ttotal: 1m 37s\tremaining: 1m 31s\n",
            "516:\tlearn: 0.0388230\ttotal: 1m 38s\tremaining: 1m 31s\n",
            "517:\tlearn: 0.0388125\ttotal: 1m 38s\tremaining: 1m 31s\n",
            "518:\tlearn: 0.0388003\ttotal: 1m 38s\tremaining: 1m 31s\n",
            "519:\tlearn: 0.0387848\ttotal: 1m 38s\tremaining: 1m 30s\n",
            "520:\tlearn: 0.0387742\ttotal: 1m 38s\tremaining: 1m 30s\n",
            "521:\tlearn: 0.0387670\ttotal: 1m 38s\tremaining: 1m 30s\n",
            "522:\tlearn: 0.0387504\ttotal: 1m 38s\tremaining: 1m 30s\n",
            "523:\tlearn: 0.0387356\ttotal: 1m 38s\tremaining: 1m 29s\n",
            "524:\tlearn: 0.0387185\ttotal: 1m 39s\tremaining: 1m 29s\n",
            "525:\tlearn: 0.0387019\ttotal: 1m 39s\tremaining: 1m 29s\n",
            "526:\tlearn: 0.0386839\ttotal: 1m 39s\tremaining: 1m 29s\n",
            "527:\tlearn: 0.0386767\ttotal: 1m 39s\tremaining: 1m 28s\n",
            "528:\tlearn: 0.0386679\ttotal: 1m 39s\tremaining: 1m 28s\n",
            "529:\tlearn: 0.0386677\ttotal: 1m 39s\tremaining: 1m 28s\n",
            "530:\tlearn: 0.0386522\ttotal: 1m 39s\tremaining: 1m 28s\n",
            "531:\tlearn: 0.0386308\ttotal: 1m 39s\tremaining: 1m 27s\n",
            "532:\tlearn: 0.0386039\ttotal: 1m 40s\tremaining: 1m 27s\n",
            "533:\tlearn: 0.0385871\ttotal: 1m 40s\tremaining: 1m 27s\n",
            "534:\tlearn: 0.0385799\ttotal: 1m 40s\tremaining: 1m 27s\n",
            "535:\tlearn: 0.0385650\ttotal: 1m 40s\tremaining: 1m 26s\n",
            "536:\tlearn: 0.0385522\ttotal: 1m 40s\tremaining: 1m 26s\n",
            "537:\tlearn: 0.0385423\ttotal: 1m 40s\tremaining: 1m 26s\n",
            "538:\tlearn: 0.0385321\ttotal: 1m 40s\tremaining: 1m 26s\n",
            "539:\tlearn: 0.0385321\ttotal: 1m 40s\tremaining: 1m 26s\n",
            "540:\tlearn: 0.0385231\ttotal: 1m 41s\tremaining: 1m 25s\n",
            "541:\tlearn: 0.0385097\ttotal: 1m 41s\tremaining: 1m 25s\n",
            "542:\tlearn: 0.0384972\ttotal: 1m 41s\tremaining: 1m 25s\n",
            "543:\tlearn: 0.0384972\ttotal: 1m 42s\tremaining: 1m 25s\n",
            "544:\tlearn: 0.0384789\ttotal: 1m 42s\tremaining: 1m 25s\n",
            "545:\tlearn: 0.0384639\ttotal: 1m 42s\tremaining: 1m 25s\n",
            "546:\tlearn: 0.0384555\ttotal: 1m 42s\tremaining: 1m 25s\n",
            "547:\tlearn: 0.0384383\ttotal: 1m 42s\tremaining: 1m 24s\n",
            "548:\tlearn: 0.0384221\ttotal: 1m 42s\tremaining: 1m 24s\n",
            "549:\tlearn: 0.0384221\ttotal: 1m 43s\tremaining: 1m 24s\n",
            "550:\tlearn: 0.0384145\ttotal: 1m 43s\tremaining: 1m 24s\n",
            "551:\tlearn: 0.0384037\ttotal: 1m 43s\tremaining: 1m 23s\n",
            "552:\tlearn: 0.0383962\ttotal: 1m 43s\tremaining: 1m 23s\n",
            "553:\tlearn: 0.0383791\ttotal: 1m 43s\tremaining: 1m 23s\n",
            "554:\tlearn: 0.0383791\ttotal: 1m 43s\tremaining: 1m 23s\n",
            "555:\tlearn: 0.0383791\ttotal: 1m 43s\tremaining: 1m 22s\n",
            "556:\tlearn: 0.0383791\ttotal: 1m 43s\tremaining: 1m 22s\n",
            "557:\tlearn: 0.0383791\ttotal: 1m 44s\tremaining: 1m 22s\n",
            "558:\tlearn: 0.0383679\ttotal: 1m 44s\tremaining: 1m 22s\n",
            "559:\tlearn: 0.0383679\ttotal: 1m 44s\tremaining: 1m 21s\n",
            "560:\tlearn: 0.0383679\ttotal: 1m 44s\tremaining: 1m 21s\n",
            "561:\tlearn: 0.0383679\ttotal: 1m 44s\tremaining: 1m 21s\n",
            "562:\tlearn: 0.0383678\ttotal: 1m 44s\tremaining: 1m 21s\n",
            "563:\tlearn: 0.0383678\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "564:\tlearn: 0.0383678\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "565:\tlearn: 0.0383677\ttotal: 1m 44s\tremaining: 1m 20s\n",
            "566:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 20s\n",
            "567:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 20s\n",
            "568:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "569:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "570:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "571:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 19s\n",
            "572:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 18s\n",
            "573:\tlearn: 0.0383677\ttotal: 1m 45s\tremaining: 1m 18s\n",
            "574:\tlearn: 0.0383677\ttotal: 1m 46s\tremaining: 1m 18s\n",
            "575:\tlearn: 0.0383677\ttotal: 1m 46s\tremaining: 1m 18s\n",
            "576:\tlearn: 0.0383677\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "577:\tlearn: 0.0383574\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "578:\tlearn: 0.0383452\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "579:\tlearn: 0.0383291\ttotal: 1m 46s\tremaining: 1m 17s\n",
            "580:\tlearn: 0.0383291\ttotal: 1m 46s\tremaining: 1m 16s\n",
            "581:\tlearn: 0.0383290\ttotal: 1m 46s\tremaining: 1m 16s\n",
            "582:\tlearn: 0.0383290\ttotal: 1m 46s\tremaining: 1m 16s\n",
            "583:\tlearn: 0.0383290\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "584:\tlearn: 0.0383128\ttotal: 1m 47s\tremaining: 1m 16s\n",
            "585:\tlearn: 0.0383014\ttotal: 1m 47s\tremaining: 1m 15s\n",
            "586:\tlearn: 0.0383014\ttotal: 1m 47s\tremaining: 1m 15s\n",
            "587:\tlearn: 0.0383013\ttotal: 1m 47s\tremaining: 1m 15s\n",
            "588:\tlearn: 0.0382843\ttotal: 1m 47s\tremaining: 1m 15s\n",
            "589:\tlearn: 0.0382701\ttotal: 1m 47s\tremaining: 1m 14s\n",
            "590:\tlearn: 0.0382602\ttotal: 1m 47s\tremaining: 1m 14s\n",
            "591:\tlearn: 0.0382414\ttotal: 1m 48s\tremaining: 1m 14s\n",
            "592:\tlearn: 0.0382382\ttotal: 1m 48s\tremaining: 1m 14s\n",
            "593:\tlearn: 0.0382187\ttotal: 1m 48s\tremaining: 1m 14s\n",
            "594:\tlearn: 0.0382017\ttotal: 1m 48s\tremaining: 1m 13s\n",
            "595:\tlearn: 0.0381913\ttotal: 1m 48s\tremaining: 1m 13s\n",
            "596:\tlearn: 0.0381866\ttotal: 1m 48s\tremaining: 1m 13s\n",
            "597:\tlearn: 0.0381749\ttotal: 1m 48s\tremaining: 1m 13s\n",
            "598:\tlearn: 0.0381541\ttotal: 1m 48s\tremaining: 1m 12s\n",
            "599:\tlearn: 0.0381459\ttotal: 1m 49s\tremaining: 1m 12s\n",
            "600:\tlearn: 0.0381299\ttotal: 1m 49s\tremaining: 1m 12s\n",
            "601:\tlearn: 0.0381224\ttotal: 1m 49s\tremaining: 1m 12s\n",
            "602:\tlearn: 0.0381053\ttotal: 1m 49s\tremaining: 1m 12s\n",
            "603:\tlearn: 0.0381053\ttotal: 1m 49s\tremaining: 1m 11s\n",
            "604:\tlearn: 0.0380948\ttotal: 1m 49s\tremaining: 1m 11s\n",
            "605:\tlearn: 0.0380948\ttotal: 1m 49s\tremaining: 1m 11s\n",
            "606:\tlearn: 0.0380948\ttotal: 1m 49s\tremaining: 1m 11s\n",
            "607:\tlearn: 0.0380807\ttotal: 1m 50s\tremaining: 1m 10s\n",
            "608:\tlearn: 0.0380588\ttotal: 1m 50s\tremaining: 1m 10s\n",
            "609:\tlearn: 0.0380436\ttotal: 1m 50s\tremaining: 1m 10s\n",
            "610:\tlearn: 0.0380325\ttotal: 1m 50s\tremaining: 1m 10s\n",
            "611:\tlearn: 0.0380324\ttotal: 1m 50s\tremaining: 1m 10s\n",
            "612:\tlearn: 0.0380323\ttotal: 1m 50s\tremaining: 1m 9s\n",
            "613:\tlearn: 0.0380323\ttotal: 1m 50s\tremaining: 1m 9s\n",
            "614:\tlearn: 0.0380321\ttotal: 1m 50s\tremaining: 1m 9s\n",
            "615:\tlearn: 0.0380321\ttotal: 1m 50s\tremaining: 1m 9s\n",
            "616:\tlearn: 0.0380320\ttotal: 1m 51s\tremaining: 1m 8s\n",
            "617:\tlearn: 0.0380320\ttotal: 1m 51s\tremaining: 1m 8s\n",
            "618:\tlearn: 0.0380320\ttotal: 1m 51s\tremaining: 1m 8s\n",
            "619:\tlearn: 0.0380319\ttotal: 1m 51s\tremaining: 1m 8s\n",
            "620:\tlearn: 0.0380319\ttotal: 1m 51s\tremaining: 1m 8s\n",
            "621:\tlearn: 0.0380204\ttotal: 1m 51s\tremaining: 1m 7s\n",
            "622:\tlearn: 0.0380203\ttotal: 1m 51s\tremaining: 1m 7s\n",
            "623:\tlearn: 0.0380203\ttotal: 1m 51s\tremaining: 1m 7s\n",
            "624:\tlearn: 0.0380203\ttotal: 1m 51s\tremaining: 1m 7s\n",
            "625:\tlearn: 0.0380203\ttotal: 1m 52s\tremaining: 1m 6s\n",
            "626:\tlearn: 0.0380202\ttotal: 1m 52s\tremaining: 1m 6s\n",
            "627:\tlearn: 0.0380202\ttotal: 1m 52s\tremaining: 1m 6s\n",
            "628:\tlearn: 0.0380200\ttotal: 1m 52s\tremaining: 1m 6s\n",
            "629:\tlearn: 0.0380200\ttotal: 1m 52s\tremaining: 1m 6s\n",
            "630:\tlearn: 0.0380200\ttotal: 1m 52s\tremaining: 1m 5s\n",
            "631:\tlearn: 0.0380200\ttotal: 1m 52s\tremaining: 1m 5s\n",
            "632:\tlearn: 0.0380200\ttotal: 1m 52s\tremaining: 1m 5s\n",
            "633:\tlearn: 0.0380036\ttotal: 1m 52s\tremaining: 1m 5s\n",
            "634:\tlearn: 0.0380035\ttotal: 1m 52s\tremaining: 1m 4s\n",
            "635:\tlearn: 0.0380035\ttotal: 1m 53s\tremaining: 1m 4s\n",
            "636:\tlearn: 0.0380035\ttotal: 1m 53s\tremaining: 1m 4s\n",
            "637:\tlearn: 0.0380035\ttotal: 1m 53s\tremaining: 1m 4s\n",
            "638:\tlearn: 0.0379910\ttotal: 1m 53s\tremaining: 1m 4s\n",
            "639:\tlearn: 0.0379758\ttotal: 1m 53s\tremaining: 1m 3s\n",
            "640:\tlearn: 0.0379600\ttotal: 1m 53s\tremaining: 1m 3s\n",
            "641:\tlearn: 0.0379454\ttotal: 1m 53s\tremaining: 1m 3s\n",
            "642:\tlearn: 0.0379262\ttotal: 1m 53s\tremaining: 1m 3s\n",
            "643:\tlearn: 0.0379201\ttotal: 1m 54s\tremaining: 1m 3s\n",
            "644:\tlearn: 0.0379123\ttotal: 1m 54s\tremaining: 1m 2s\n",
            "645:\tlearn: 0.0378986\ttotal: 1m 54s\tremaining: 1m 2s\n",
            "646:\tlearn: 0.0378874\ttotal: 1m 54s\tremaining: 1m 2s\n",
            "647:\tlearn: 0.0378874\ttotal: 1m 54s\tremaining: 1m 2s\n",
            "648:\tlearn: 0.0378728\ttotal: 1m 54s\tremaining: 1m 1s\n",
            "649:\tlearn: 0.0378565\ttotal: 1m 54s\tremaining: 1m 1s\n",
            "650:\tlearn: 0.0378431\ttotal: 1m 54s\tremaining: 1m 1s\n",
            "651:\tlearn: 0.0378261\ttotal: 1m 55s\tremaining: 1m 1s\n",
            "652:\tlearn: 0.0378255\ttotal: 1m 55s\tremaining: 1m 1s\n",
            "653:\tlearn: 0.0378180\ttotal: 1m 55s\tremaining: 1m\n",
            "654:\tlearn: 0.0377922\ttotal: 1m 55s\tremaining: 1m\n",
            "655:\tlearn: 0.0377798\ttotal: 1m 55s\tremaining: 1m\n",
            "656:\tlearn: 0.0377610\ttotal: 1m 55s\tremaining: 1m\n",
            "657:\tlearn: 0.0377446\ttotal: 1m 55s\tremaining: 1m\n",
            "658:\tlearn: 0.0377446\ttotal: 1m 55s\tremaining: 59.9s\n",
            "659:\tlearn: 0.0377336\ttotal: 1m 55s\tremaining: 59.8s\n",
            "660:\tlearn: 0.0377201\ttotal: 1m 56s\tremaining: 59.5s\n",
            "661:\tlearn: 0.0377161\ttotal: 1m 56s\tremaining: 59.3s\n",
            "662:\tlearn: 0.0377068\ttotal: 1m 56s\tremaining: 59.1s\n",
            "663:\tlearn: 0.0376937\ttotal: 1m 56s\tremaining: 58.9s\n",
            "664:\tlearn: 0.0376780\ttotal: 1m 56s\tremaining: 58.7s\n",
            "665:\tlearn: 0.0376674\ttotal: 1m 56s\tremaining: 58.5s\n",
            "666:\tlearn: 0.0376673\ttotal: 1m 56s\tremaining: 58.3s\n",
            "667:\tlearn: 0.0376536\ttotal: 1m 56s\tremaining: 58.1s\n",
            "668:\tlearn: 0.0376525\ttotal: 1m 57s\tremaining: 57.9s\n",
            "669:\tlearn: 0.0376524\ttotal: 1m 57s\tremaining: 57.7s\n",
            "670:\tlearn: 0.0376524\ttotal: 1m 57s\tremaining: 57.5s\n",
            "671:\tlearn: 0.0376524\ttotal: 1m 57s\tremaining: 57.3s\n",
            "672:\tlearn: 0.0376523\ttotal: 1m 57s\tremaining: 57.1s\n",
            "673:\tlearn: 0.0376523\ttotal: 1m 57s\tremaining: 56.8s\n",
            "674:\tlearn: 0.0376522\ttotal: 1m 57s\tremaining: 56.6s\n",
            "675:\tlearn: 0.0376521\ttotal: 1m 57s\tremaining: 56.4s\n",
            "676:\tlearn: 0.0376521\ttotal: 1m 57s\tremaining: 56.2s\n",
            "677:\tlearn: 0.0376521\ttotal: 1m 57s\tremaining: 56s\n",
            "678:\tlearn: 0.0376520\ttotal: 1m 58s\tremaining: 55.8s\n",
            "679:\tlearn: 0.0376491\ttotal: 1m 58s\tremaining: 55.6s\n",
            "680:\tlearn: 0.0376333\ttotal: 1m 58s\tremaining: 55.4s\n",
            "681:\tlearn: 0.0376333\ttotal: 1m 58s\tremaining: 55.2s\n",
            "682:\tlearn: 0.0376153\ttotal: 1m 58s\tremaining: 55s\n",
            "683:\tlearn: 0.0376046\ttotal: 1m 58s\tremaining: 54.8s\n",
            "684:\tlearn: 0.0375814\ttotal: 1m 58s\tremaining: 54.6s\n",
            "685:\tlearn: 0.0375813\ttotal: 1m 58s\tremaining: 54.4s\n",
            "686:\tlearn: 0.0375813\ttotal: 1m 58s\tremaining: 54.2s\n",
            "687:\tlearn: 0.0375813\ttotal: 1m 59s\tremaining: 54s\n",
            "688:\tlearn: 0.0375813\ttotal: 1m 59s\tremaining: 53.8s\n",
            "689:\tlearn: 0.0375813\ttotal: 1m 59s\tremaining: 53.6s\n",
            "690:\tlearn: 0.0375813\ttotal: 1m 59s\tremaining: 53.4s\n",
            "691:\tlearn: 0.0375812\ttotal: 1m 59s\tremaining: 53.2s\n",
            "692:\tlearn: 0.0375812\ttotal: 1m 59s\tremaining: 53s\n",
            "693:\tlearn: 0.0375811\ttotal: 1m 59s\tremaining: 52.8s\n",
            "694:\tlearn: 0.0375803\ttotal: 1m 59s\tremaining: 52.6s\n",
            "695:\tlearn: 0.0375803\ttotal: 1m 59s\tremaining: 52.4s\n",
            "696:\tlearn: 0.0375646\ttotal: 2m\tremaining: 52.2s\n",
            "697:\tlearn: 0.0375545\ttotal: 2m\tremaining: 52s\n",
            "698:\tlearn: 0.0375545\ttotal: 2m\tremaining: 51.8s\n",
            "699:\tlearn: 0.0375545\ttotal: 2m\tremaining: 51.6s\n",
            "700:\tlearn: 0.0375439\ttotal: 2m\tremaining: 51.4s\n",
            "701:\tlearn: 0.0375348\ttotal: 2m\tremaining: 51.2s\n",
            "702:\tlearn: 0.0375348\ttotal: 2m\tremaining: 51s\n",
            "703:\tlearn: 0.0375348\ttotal: 2m\tremaining: 50.8s\n",
            "704:\tlearn: 0.0375347\ttotal: 2m 1s\tremaining: 50.6s\n",
            "705:\tlearn: 0.0375347\ttotal: 2m 1s\tremaining: 50.4s\n",
            "706:\tlearn: 0.0375346\ttotal: 2m 1s\tremaining: 50.2s\n",
            "707:\tlearn: 0.0375346\ttotal: 2m 1s\tremaining: 50s\n",
            "708:\tlearn: 0.0375346\ttotal: 2m 1s\tremaining: 49.8s\n",
            "709:\tlearn: 0.0375345\ttotal: 2m 1s\tremaining: 49.6s\n",
            "710:\tlearn: 0.0375345\ttotal: 2m 1s\tremaining: 49.4s\n",
            "711:\tlearn: 0.0375345\ttotal: 2m 1s\tremaining: 49.2s\n",
            "712:\tlearn: 0.0375345\ttotal: 2m 1s\tremaining: 49s\n",
            "713:\tlearn: 0.0375345\ttotal: 2m 1s\tremaining: 48.9s\n",
            "714:\tlearn: 0.0375240\ttotal: 2m 2s\tremaining: 48.7s\n",
            "715:\tlearn: 0.0375240\ttotal: 2m 2s\tremaining: 48.5s\n",
            "716:\tlearn: 0.0375240\ttotal: 2m 2s\tremaining: 48.3s\n",
            "717:\tlearn: 0.0375240\ttotal: 2m 2s\tremaining: 48.1s\n",
            "718:\tlearn: 0.0375240\ttotal: 2m 2s\tremaining: 47.9s\n",
            "719:\tlearn: 0.0375240\ttotal: 2m 2s\tremaining: 47.7s\n",
            "720:\tlearn: 0.0375238\ttotal: 2m 2s\tremaining: 47.5s\n",
            "721:\tlearn: 0.0375238\ttotal: 2m 2s\tremaining: 47.3s\n",
            "722:\tlearn: 0.0375237\ttotal: 2m 2s\tremaining: 47.1s\n",
            "723:\tlearn: 0.0375236\ttotal: 2m 3s\tremaining: 46.9s\n",
            "724:\tlearn: 0.0375236\ttotal: 2m 3s\tremaining: 46.7s\n",
            "725:\tlearn: 0.0375236\ttotal: 2m 3s\tremaining: 46.5s\n",
            "726:\tlearn: 0.0375236\ttotal: 2m 3s\tremaining: 46.3s\n",
            "727:\tlearn: 0.0375235\ttotal: 2m 3s\tremaining: 46.1s\n",
            "728:\tlearn: 0.0375235\ttotal: 2m 3s\tremaining: 45.9s\n",
            "729:\tlearn: 0.0375235\ttotal: 2m 3s\tremaining: 45.7s\n",
            "730:\tlearn: 0.0375235\ttotal: 2m 3s\tremaining: 45.5s\n",
            "731:\tlearn: 0.0375234\ttotal: 2m 3s\tremaining: 45.4s\n",
            "732:\tlearn: 0.0375234\ttotal: 2m 3s\tremaining: 45.2s\n",
            "733:\tlearn: 0.0375232\ttotal: 2m 4s\tremaining: 45s\n",
            "734:\tlearn: 0.0375231\ttotal: 2m 4s\tremaining: 44.8s\n",
            "735:\tlearn: 0.0375230\ttotal: 2m 4s\tremaining: 44.6s\n",
            "736:\tlearn: 0.0375230\ttotal: 2m 4s\tremaining: 44.4s\n",
            "737:\tlearn: 0.0375230\ttotal: 2m 4s\tremaining: 44.2s\n",
            "738:\tlearn: 0.0375229\ttotal: 2m 4s\tremaining: 44s\n",
            "739:\tlearn: 0.0375228\ttotal: 2m 4s\tremaining: 43.8s\n",
            "740:\tlearn: 0.0375228\ttotal: 2m 4s\tremaining: 43.6s\n",
            "741:\tlearn: 0.0375228\ttotal: 2m 4s\tremaining: 43.4s\n",
            "742:\tlearn: 0.0375227\ttotal: 2m 5s\tremaining: 43.2s\n",
            "743:\tlearn: 0.0375227\ttotal: 2m 5s\tremaining: 43.1s\n",
            "744:\tlearn: 0.0375227\ttotal: 2m 5s\tremaining: 42.9s\n",
            "745:\tlearn: 0.0375227\ttotal: 2m 5s\tremaining: 42.7s\n",
            "746:\tlearn: 0.0375227\ttotal: 2m 5s\tremaining: 42.5s\n",
            "747:\tlearn: 0.0375195\ttotal: 2m 5s\tremaining: 42.3s\n",
            "748:\tlearn: 0.0375195\ttotal: 2m 5s\tremaining: 42.1s\n",
            "749:\tlearn: 0.0375195\ttotal: 2m 5s\tremaining: 41.9s\n",
            "750:\tlearn: 0.0375195\ttotal: 2m 5s\tremaining: 41.7s\n",
            "751:\tlearn: 0.0375195\ttotal: 2m 5s\tremaining: 41.5s\n",
            "752:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 41.4s\n",
            "753:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 41.2s\n",
            "754:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 41s\n",
            "755:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 40.8s\n",
            "756:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 40.6s\n",
            "757:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 40.4s\n",
            "758:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 40.2s\n",
            "759:\tlearn: 0.0375195\ttotal: 2m 6s\tremaining: 40s\n",
            "760:\tlearn: 0.0375120\ttotal: 2m 6s\tremaining: 39.9s\n",
            "761:\tlearn: 0.0374962\ttotal: 2m 7s\tremaining: 39.7s\n",
            "762:\tlearn: 0.0374962\ttotal: 2m 7s\tremaining: 39.5s\n",
            "763:\tlearn: 0.0374956\ttotal: 2m 7s\tremaining: 39.3s\n",
            "764:\tlearn: 0.0374932\ttotal: 2m 7s\tremaining: 39.1s\n",
            "765:\tlearn: 0.0374932\ttotal: 2m 7s\tremaining: 38.9s\n",
            "766:\tlearn: 0.0374930\ttotal: 2m 7s\tremaining: 38.8s\n",
            "767:\tlearn: 0.0374829\ttotal: 2m 7s\tremaining: 38.6s\n",
            "768:\tlearn: 0.0374676\ttotal: 2m 7s\tremaining: 38.4s\n",
            "769:\tlearn: 0.0374676\ttotal: 2m 7s\tremaining: 38.2s\n",
            "770:\tlearn: 0.0374676\ttotal: 2m 8s\tremaining: 38s\n",
            "771:\tlearn: 0.0374676\ttotal: 2m 8s\tremaining: 37.8s\n",
            "772:\tlearn: 0.0374675\ttotal: 2m 8s\tremaining: 37.7s\n",
            "773:\tlearn: 0.0374600\ttotal: 2m 8s\tremaining: 37.5s\n",
            "774:\tlearn: 0.0374600\ttotal: 2m 8s\tremaining: 37.3s\n",
            "775:\tlearn: 0.0374600\ttotal: 2m 8s\tremaining: 37.1s\n",
            "776:\tlearn: 0.0374600\ttotal: 2m 8s\tremaining: 36.9s\n",
            "777:\tlearn: 0.0374525\ttotal: 2m 8s\tremaining: 36.8s\n",
            "778:\tlearn: 0.0374525\ttotal: 2m 8s\tremaining: 36.6s\n",
            "779:\tlearn: 0.0374524\ttotal: 2m 9s\tremaining: 36.4s\n",
            "780:\tlearn: 0.0374524\ttotal: 2m 9s\tremaining: 36.2s\n",
            "781:\tlearn: 0.0374523\ttotal: 2m 9s\tremaining: 36s\n",
            "782:\tlearn: 0.0374523\ttotal: 2m 9s\tremaining: 35.8s\n",
            "783:\tlearn: 0.0374523\ttotal: 2m 9s\tremaining: 35.7s\n",
            "784:\tlearn: 0.0374523\ttotal: 2m 9s\tremaining: 35.5s\n",
            "785:\tlearn: 0.0374522\ttotal: 2m 9s\tremaining: 35.3s\n",
            "786:\tlearn: 0.0374522\ttotal: 2m 9s\tremaining: 35.1s\n",
            "787:\tlearn: 0.0374522\ttotal: 2m 9s\tremaining: 34.9s\n",
            "788:\tlearn: 0.0374522\ttotal: 2m 9s\tremaining: 34.7s\n",
            "789:\tlearn: 0.0374522\ttotal: 2m 10s\tremaining: 34.6s\n",
            "790:\tlearn: 0.0374522\ttotal: 2m 10s\tremaining: 34.4s\n",
            "791:\tlearn: 0.0374458\ttotal: 2m 10s\tremaining: 34.2s\n",
            "792:\tlearn: 0.0374350\ttotal: 2m 10s\tremaining: 34s\n",
            "793:\tlearn: 0.0374202\ttotal: 2m 10s\tremaining: 33.9s\n",
            "794:\tlearn: 0.0374117\ttotal: 2m 10s\tremaining: 33.7s\n",
            "795:\tlearn: 0.0373874\ttotal: 2m 10s\tremaining: 33.5s\n",
            "796:\tlearn: 0.0373797\ttotal: 2m 10s\tremaining: 33.3s\n",
            "797:\tlearn: 0.0373662\ttotal: 2m 10s\tremaining: 33.2s\n",
            "798:\tlearn: 0.0373486\ttotal: 2m 11s\tremaining: 33s\n",
            "799:\tlearn: 0.0373328\ttotal: 2m 11s\tremaining: 32.8s\n",
            "800:\tlearn: 0.0373192\ttotal: 2m 11s\tremaining: 32.6s\n",
            "801:\tlearn: 0.0373061\ttotal: 2m 11s\tremaining: 32.5s\n",
            "802:\tlearn: 0.0372846\ttotal: 2m 11s\tremaining: 32.3s\n",
            "803:\tlearn: 0.0372706\ttotal: 2m 11s\tremaining: 32.1s\n",
            "804:\tlearn: 0.0372641\ttotal: 2m 11s\tremaining: 31.9s\n",
            "805:\tlearn: 0.0372477\ttotal: 2m 12s\tremaining: 31.8s\n",
            "806:\tlearn: 0.0372370\ttotal: 2m 12s\tremaining: 31.6s\n",
            "807:\tlearn: 0.0372369\ttotal: 2m 12s\tremaining: 31.4s\n",
            "808:\tlearn: 0.0372368\ttotal: 2m 12s\tremaining: 31.2s\n",
            "809:\tlearn: 0.0372363\ttotal: 2m 12s\tremaining: 31.1s\n",
            "810:\tlearn: 0.0372296\ttotal: 2m 12s\tremaining: 30.9s\n",
            "811:\tlearn: 0.0372113\ttotal: 2m 12s\tremaining: 30.7s\n",
            "812:\tlearn: 0.0372112\ttotal: 2m 12s\tremaining: 30.5s\n",
            "813:\tlearn: 0.0371944\ttotal: 2m 12s\tremaining: 30.4s\n",
            "814:\tlearn: 0.0371802\ttotal: 2m 13s\tremaining: 30.2s\n",
            "815:\tlearn: 0.0371802\ttotal: 2m 13s\tremaining: 30s\n",
            "816:\tlearn: 0.0371802\ttotal: 2m 13s\tremaining: 29.9s\n",
            "817:\tlearn: 0.0371726\ttotal: 2m 13s\tremaining: 29.7s\n",
            "818:\tlearn: 0.0371511\ttotal: 2m 13s\tremaining: 29.5s\n",
            "819:\tlearn: 0.0371383\ttotal: 2m 13s\tremaining: 29.3s\n",
            "820:\tlearn: 0.0371383\ttotal: 2m 13s\tremaining: 29.2s\n",
            "821:\tlearn: 0.0371382\ttotal: 2m 13s\tremaining: 29s\n",
            "822:\tlearn: 0.0371381\ttotal: 2m 14s\tremaining: 28.8s\n",
            "823:\tlearn: 0.0371381\ttotal: 2m 14s\tremaining: 28.7s\n",
            "824:\tlearn: 0.0371374\ttotal: 2m 14s\tremaining: 28.5s\n",
            "825:\tlearn: 0.0371266\ttotal: 2m 14s\tremaining: 28.3s\n",
            "826:\tlearn: 0.0371265\ttotal: 2m 14s\tremaining: 28.1s\n",
            "827:\tlearn: 0.0371265\ttotal: 2m 14s\tremaining: 28s\n",
            "828:\tlearn: 0.0371265\ttotal: 2m 14s\tremaining: 27.8s\n",
            "829:\tlearn: 0.0371264\ttotal: 2m 14s\tremaining: 27.6s\n",
            "830:\tlearn: 0.0371264\ttotal: 2m 14s\tremaining: 27.5s\n",
            "831:\tlearn: 0.0371263\ttotal: 2m 15s\tremaining: 27.3s\n",
            "832:\tlearn: 0.0371262\ttotal: 2m 15s\tremaining: 27.1s\n",
            "833:\tlearn: 0.0371262\ttotal: 2m 15s\tremaining: 26.9s\n",
            "834:\tlearn: 0.0371262\ttotal: 2m 15s\tremaining: 26.8s\n",
            "835:\tlearn: 0.0371261\ttotal: 2m 15s\tremaining: 26.6s\n",
            "836:\tlearn: 0.0371260\ttotal: 2m 15s\tremaining: 26.4s\n",
            "837:\tlearn: 0.0371260\ttotal: 2m 15s\tremaining: 26.3s\n",
            "838:\tlearn: 0.0371195\ttotal: 2m 15s\tremaining: 26.1s\n",
            "839:\tlearn: 0.0371074\ttotal: 2m 16s\tremaining: 25.9s\n",
            "840:\tlearn: 0.0370953\ttotal: 2m 16s\tremaining: 25.7s\n",
            "841:\tlearn: 0.0370952\ttotal: 2m 16s\tremaining: 25.6s\n",
            "842:\tlearn: 0.0370908\ttotal: 2m 16s\tremaining: 25.4s\n",
            "843:\tlearn: 0.0370796\ttotal: 2m 16s\tremaining: 25.2s\n",
            "844:\tlearn: 0.0370733\ttotal: 2m 16s\tremaining: 25.1s\n",
            "845:\tlearn: 0.0370733\ttotal: 2m 16s\tremaining: 24.9s\n",
            "846:\tlearn: 0.0370483\ttotal: 2m 17s\tremaining: 24.8s\n",
            "847:\tlearn: 0.0370384\ttotal: 2m 17s\tremaining: 24.7s\n",
            "848:\tlearn: 0.0370383\ttotal: 2m 17s\tremaining: 24.5s\n",
            "849:\tlearn: 0.0370245\ttotal: 2m 17s\tremaining: 24.3s\n",
            "850:\tlearn: 0.0370113\ttotal: 2m 18s\tremaining: 24.2s\n",
            "851:\tlearn: 0.0369925\ttotal: 2m 18s\tremaining: 24s\n",
            "852:\tlearn: 0.0369779\ttotal: 2m 18s\tremaining: 23.8s\n",
            "853:\tlearn: 0.0369697\ttotal: 2m 18s\tremaining: 23.7s\n",
            "854:\tlearn: 0.0369546\ttotal: 2m 18s\tremaining: 23.5s\n",
            "855:\tlearn: 0.0369546\ttotal: 2m 18s\tremaining: 23.3s\n",
            "856:\tlearn: 0.0369499\ttotal: 2m 18s\tremaining: 23.2s\n",
            "857:\tlearn: 0.0369322\ttotal: 2m 18s\tremaining: 23s\n",
            "858:\tlearn: 0.0369197\ttotal: 2m 19s\tremaining: 22.8s\n",
            "859:\tlearn: 0.0369059\ttotal: 2m 19s\tremaining: 22.7s\n",
            "860:\tlearn: 0.0368947\ttotal: 2m 19s\tremaining: 22.5s\n",
            "861:\tlearn: 0.0368774\ttotal: 2m 19s\tremaining: 22.3s\n",
            "862:\tlearn: 0.0368773\ttotal: 2m 19s\tremaining: 22.2s\n",
            "863:\tlearn: 0.0368773\ttotal: 2m 19s\tremaining: 22s\n",
            "864:\tlearn: 0.0368771\ttotal: 2m 19s\tremaining: 21.8s\n",
            "865:\tlearn: 0.0368686\ttotal: 2m 19s\tremaining: 21.6s\n",
            "866:\tlearn: 0.0368580\ttotal: 2m 20s\tremaining: 21.5s\n",
            "867:\tlearn: 0.0368473\ttotal: 2m 20s\tremaining: 21.3s\n",
            "868:\tlearn: 0.0368473\ttotal: 2m 20s\tremaining: 21.1s\n",
            "869:\tlearn: 0.0368411\ttotal: 2m 20s\tremaining: 21s\n",
            "870:\tlearn: 0.0368312\ttotal: 2m 20s\tremaining: 20.8s\n",
            "871:\tlearn: 0.0368216\ttotal: 2m 20s\tremaining: 20.6s\n",
            "872:\tlearn: 0.0368215\ttotal: 2m 20s\tremaining: 20.5s\n",
            "873:\tlearn: 0.0368214\ttotal: 2m 20s\tremaining: 20.3s\n",
            "874:\tlearn: 0.0368214\ttotal: 2m 20s\tremaining: 20.1s\n",
            "875:\tlearn: 0.0368213\ttotal: 2m 21s\tremaining: 20s\n",
            "876:\tlearn: 0.0368213\ttotal: 2m 21s\tremaining: 19.8s\n",
            "877:\tlearn: 0.0368213\ttotal: 2m 21s\tremaining: 19.6s\n",
            "878:\tlearn: 0.0368080\ttotal: 2m 21s\tremaining: 19.5s\n",
            "879:\tlearn: 0.0367936\ttotal: 2m 21s\tremaining: 19.3s\n",
            "880:\tlearn: 0.0367936\ttotal: 2m 21s\tremaining: 19.1s\n",
            "881:\tlearn: 0.0367936\ttotal: 2m 21s\tremaining: 19s\n",
            "882:\tlearn: 0.0367936\ttotal: 2m 21s\tremaining: 18.8s\n",
            "883:\tlearn: 0.0367936\ttotal: 2m 22s\tremaining: 18.6s\n",
            "884:\tlearn: 0.0367914\ttotal: 2m 22s\tremaining: 18.5s\n",
            "885:\tlearn: 0.0367914\ttotal: 2m 22s\tremaining: 18.3s\n",
            "886:\tlearn: 0.0367913\ttotal: 2m 22s\tremaining: 18.1s\n",
            "887:\tlearn: 0.0367913\ttotal: 2m 22s\tremaining: 18s\n",
            "888:\tlearn: 0.0367913\ttotal: 2m 22s\tremaining: 17.8s\n",
            "889:\tlearn: 0.0367911\ttotal: 2m 22s\tremaining: 17.6s\n",
            "890:\tlearn: 0.0367911\ttotal: 2m 22s\tremaining: 17.5s\n",
            "891:\tlearn: 0.0367910\ttotal: 2m 22s\tremaining: 17.3s\n",
            "892:\tlearn: 0.0367910\ttotal: 2m 23s\tremaining: 17.1s\n",
            "893:\tlearn: 0.0367910\ttotal: 2m 23s\tremaining: 17s\n",
            "894:\tlearn: 0.0367804\ttotal: 2m 23s\tremaining: 16.8s\n",
            "895:\tlearn: 0.0367804\ttotal: 2m 23s\tremaining: 16.6s\n",
            "896:\tlearn: 0.0367804\ttotal: 2m 23s\tremaining: 16.5s\n",
            "897:\tlearn: 0.0367803\ttotal: 2m 23s\tremaining: 16.3s\n",
            "898:\tlearn: 0.0367803\ttotal: 2m 23s\tremaining: 16.1s\n",
            "899:\tlearn: 0.0367803\ttotal: 2m 23s\tremaining: 16s\n",
            "900:\tlearn: 0.0367803\ttotal: 2m 23s\tremaining: 15.8s\n",
            "901:\tlearn: 0.0367725\ttotal: 2m 24s\tremaining: 15.7s\n",
            "902:\tlearn: 0.0367595\ttotal: 2m 24s\tremaining: 15.5s\n",
            "903:\tlearn: 0.0367453\ttotal: 2m 24s\tremaining: 15.3s\n",
            "904:\tlearn: 0.0367453\ttotal: 2m 24s\tremaining: 15.2s\n",
            "905:\tlearn: 0.0367453\ttotal: 2m 24s\tremaining: 15s\n",
            "906:\tlearn: 0.0367453\ttotal: 2m 24s\tremaining: 14.8s\n",
            "907:\tlearn: 0.0367364\ttotal: 2m 24s\tremaining: 14.7s\n",
            "908:\tlearn: 0.0367218\ttotal: 2m 24s\tremaining: 14.5s\n",
            "909:\tlearn: 0.0367218\ttotal: 2m 25s\tremaining: 14.3s\n",
            "910:\tlearn: 0.0367217\ttotal: 2m 25s\tremaining: 14.2s\n",
            "911:\tlearn: 0.0367097\ttotal: 2m 25s\tremaining: 14s\n",
            "912:\tlearn: 0.0367097\ttotal: 2m 25s\tremaining: 13.9s\n",
            "913:\tlearn: 0.0367097\ttotal: 2m 25s\tremaining: 13.7s\n",
            "914:\tlearn: 0.0367097\ttotal: 2m 25s\tremaining: 13.5s\n",
            "915:\tlearn: 0.0367097\ttotal: 2m 25s\tremaining: 13.4s\n",
            "916:\tlearn: 0.0367097\ttotal: 2m 25s\tremaining: 13.2s\n",
            "917:\tlearn: 0.0367096\ttotal: 2m 26s\tremaining: 13s\n",
            "918:\tlearn: 0.0367096\ttotal: 2m 26s\tremaining: 12.9s\n",
            "919:\tlearn: 0.0367096\ttotal: 2m 26s\tremaining: 12.7s\n",
            "920:\tlearn: 0.0367096\ttotal: 2m 26s\tremaining: 12.6s\n",
            "921:\tlearn: 0.0367096\ttotal: 2m 26s\tremaining: 12.4s\n",
            "922:\tlearn: 0.0367096\ttotal: 2m 26s\tremaining: 12.2s\n",
            "923:\tlearn: 0.0367095\ttotal: 2m 26s\tremaining: 12.1s\n",
            "924:\tlearn: 0.0367095\ttotal: 2m 26s\tremaining: 11.9s\n",
            "925:\tlearn: 0.0367095\ttotal: 2m 26s\tremaining: 11.7s\n",
            "926:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 11.6s\n",
            "927:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 11.4s\n",
            "928:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 11.3s\n",
            "929:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 11.1s\n",
            "930:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 10.9s\n",
            "931:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 10.8s\n",
            "932:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 10.6s\n",
            "933:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 10.4s\n",
            "934:\tlearn: 0.0367095\ttotal: 2m 27s\tremaining: 10.3s\n",
            "935:\tlearn: 0.0367095\ttotal: 2m 28s\tremaining: 10.1s\n",
            "936:\tlearn: 0.0367095\ttotal: 2m 28s\tremaining: 9.96s\n",
            "937:\tlearn: 0.0367094\ttotal: 2m 28s\tremaining: 9.8s\n",
            "938:\tlearn: 0.0367021\ttotal: 2m 28s\tremaining: 9.64s\n",
            "939:\tlearn: 0.0367021\ttotal: 2m 28s\tremaining: 9.48s\n",
            "940:\tlearn: 0.0366940\ttotal: 2m 28s\tremaining: 9.32s\n",
            "941:\tlearn: 0.0366776\ttotal: 2m 28s\tremaining: 9.16s\n",
            "942:\tlearn: 0.0366629\ttotal: 2m 28s\tremaining: 9s\n",
            "943:\tlearn: 0.0366629\ttotal: 2m 29s\tremaining: 8.84s\n",
            "944:\tlearn: 0.0366627\ttotal: 2m 29s\tremaining: 8.68s\n",
            "945:\tlearn: 0.0366545\ttotal: 2m 29s\tremaining: 8.52s\n",
            "946:\tlearn: 0.0366428\ttotal: 2m 29s\tremaining: 8.36s\n",
            "947:\tlearn: 0.0366340\ttotal: 2m 29s\tremaining: 8.2s\n",
            "948:\tlearn: 0.0366340\ttotal: 2m 29s\tremaining: 8.04s\n",
            "949:\tlearn: 0.0366329\ttotal: 2m 29s\tremaining: 7.88s\n",
            "950:\tlearn: 0.0366329\ttotal: 2m 29s\tremaining: 7.72s\n",
            "951:\tlearn: 0.0366329\ttotal: 2m 29s\tremaining: 7.56s\n",
            "952:\tlearn: 0.0366329\ttotal: 2m 30s\tremaining: 7.4s\n",
            "953:\tlearn: 0.0366114\ttotal: 2m 30s\tremaining: 7.24s\n",
            "954:\tlearn: 0.0366113\ttotal: 2m 30s\tremaining: 7.08s\n",
            "955:\tlearn: 0.0366113\ttotal: 2m 30s\tremaining: 6.92s\n",
            "956:\tlearn: 0.0365986\ttotal: 2m 30s\tremaining: 6.76s\n",
            "957:\tlearn: 0.0365881\ttotal: 2m 30s\tremaining: 6.61s\n",
            "958:\tlearn: 0.0365881\ttotal: 2m 30s\tremaining: 6.45s\n",
            "959:\tlearn: 0.0365881\ttotal: 2m 30s\tremaining: 6.29s\n",
            "960:\tlearn: 0.0365817\ttotal: 2m 31s\tremaining: 6.13s\n",
            "961:\tlearn: 0.0365816\ttotal: 2m 31s\tremaining: 5.97s\n",
            "962:\tlearn: 0.0365816\ttotal: 2m 31s\tremaining: 5.81s\n",
            "963:\tlearn: 0.0365814\ttotal: 2m 31s\tremaining: 5.65s\n",
            "964:\tlearn: 0.0365814\ttotal: 2m 31s\tremaining: 5.49s\n",
            "965:\tlearn: 0.0365814\ttotal: 2m 31s\tremaining: 5.33s\n",
            "966:\tlearn: 0.0365731\ttotal: 2m 31s\tremaining: 5.17s\n",
            "967:\tlearn: 0.0365624\ttotal: 2m 31s\tremaining: 5.02s\n",
            "968:\tlearn: 0.0365485\ttotal: 2m 31s\tremaining: 4.86s\n",
            "969:\tlearn: 0.0365288\ttotal: 2m 32s\tremaining: 4.7s\n",
            "970:\tlearn: 0.0365170\ttotal: 2m 32s\tremaining: 4.54s\n",
            "971:\tlearn: 0.0365170\ttotal: 2m 32s\tremaining: 4.39s\n",
            "972:\tlearn: 0.0365170\ttotal: 2m 32s\tremaining: 4.23s\n",
            "973:\tlearn: 0.0365082\ttotal: 2m 32s\tremaining: 4.07s\n",
            "974:\tlearn: 0.0364915\ttotal: 2m 32s\tremaining: 3.91s\n",
            "975:\tlearn: 0.0364861\ttotal: 2m 32s\tremaining: 3.76s\n",
            "976:\tlearn: 0.0364860\ttotal: 2m 32s\tremaining: 3.6s\n",
            "977:\tlearn: 0.0364859\ttotal: 2m 32s\tremaining: 3.44s\n",
            "978:\tlearn: 0.0364858\ttotal: 2m 33s\tremaining: 3.28s\n",
            "979:\tlearn: 0.0364858\ttotal: 2m 33s\tremaining: 3.13s\n",
            "980:\tlearn: 0.0364858\ttotal: 2m 33s\tremaining: 2.97s\n",
            "981:\tlearn: 0.0364857\ttotal: 2m 33s\tremaining: 2.81s\n",
            "982:\tlearn: 0.0364856\ttotal: 2m 33s\tremaining: 2.65s\n",
            "983:\tlearn: 0.0364856\ttotal: 2m 33s\tremaining: 2.5s\n",
            "984:\tlearn: 0.0364856\ttotal: 2m 33s\tremaining: 2.34s\n",
            "985:\tlearn: 0.0364855\ttotal: 2m 33s\tremaining: 2.18s\n",
            "986:\tlearn: 0.0364855\ttotal: 2m 33s\tremaining: 2.03s\n",
            "987:\tlearn: 0.0364855\ttotal: 2m 34s\tremaining: 1.87s\n",
            "988:\tlearn: 0.0364759\ttotal: 2m 34s\tremaining: 1.71s\n",
            "989:\tlearn: 0.0364759\ttotal: 2m 34s\tremaining: 1.56s\n",
            "990:\tlearn: 0.0364654\ttotal: 2m 34s\tremaining: 1.4s\n",
            "991:\tlearn: 0.0364653\ttotal: 2m 34s\tremaining: 1.25s\n",
            "992:\tlearn: 0.0364479\ttotal: 2m 34s\tremaining: 1.09s\n",
            "993:\tlearn: 0.0364347\ttotal: 2m 34s\tremaining: 934ms\n",
            "994:\tlearn: 0.0364347\ttotal: 2m 34s\tremaining: 778ms\n",
            "995:\tlearn: 0.0364346\ttotal: 2m 34s\tremaining: 622ms\n",
            "996:\tlearn: 0.0364346\ttotal: 2m 35s\tremaining: 466ms\n",
            "997:\tlearn: 0.0364248\ttotal: 2m 35s\tremaining: 311ms\n",
            "998:\tlearn: 0.0364248\ttotal: 2m 35s\tremaining: 155ms\n",
            "999:\tlearn: 0.0364192\ttotal: 2m 35s\tremaining: 0us\n"
          ]
        }
      ],
      "id": "3xLB0QlT4ENS"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy_score of CatBoost : %f'  %(accuracy_score(y_test_, y_pred)))\n",
        "\n",
        "print(roc_auc_score(y_test_, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWZywTYM8usI",
        "outputId": "c53a754f-9c65-4f95-cbc1-7bced0d4fbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy_score of CatBoost : 0.984899\n",
            "0.9849907799747227\n"
          ]
        }
      ],
      "id": "ZWZywTYM8usI"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)\n",
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzodpgsM4ETp",
        "outputId": "59877a28-97ed-4faf-a7d9-ff196ba7c9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.159933\n",
            "0:\tlearn: 0.3949393\ttotal: 163ms\tremaining: 2m 42s\n",
            "1:\tlearn: 0.2426274\ttotal: 330ms\tremaining: 2m 44s\n",
            "2:\tlearn: 0.1737005\ttotal: 476ms\tremaining: 2m 38s\n",
            "3:\tlearn: 0.1254081\ttotal: 634ms\tremaining: 2m 37s\n",
            "4:\tlearn: 0.1030054\ttotal: 783ms\tremaining: 2m 35s\n",
            "5:\tlearn: 0.0868551\ttotal: 931ms\tremaining: 2m 34s\n",
            "6:\tlearn: 0.0760032\ttotal: 1.07s\tremaining: 2m 31s\n",
            "7:\tlearn: 0.0710337\ttotal: 1.23s\tremaining: 2m 32s\n",
            "8:\tlearn: 0.0676089\ttotal: 1.39s\tremaining: 2m 32s\n",
            "9:\tlearn: 0.0646215\ttotal: 1.54s\tremaining: 2m 32s\n",
            "10:\tlearn: 0.0624555\ttotal: 1.7s\tremaining: 2m 33s\n",
            "11:\tlearn: 0.0597703\ttotal: 1.85s\tremaining: 2m 32s\n",
            "12:\tlearn: 0.0583929\ttotal: 2.02s\tremaining: 2m 33s\n",
            "13:\tlearn: 0.0575956\ttotal: 2.17s\tremaining: 2m 33s\n",
            "14:\tlearn: 0.0568261\ttotal: 2.32s\tremaining: 2m 32s\n",
            "15:\tlearn: 0.0559468\ttotal: 2.49s\tremaining: 2m 33s\n",
            "16:\tlearn: 0.0551458\ttotal: 2.65s\tremaining: 2m 33s\n",
            "17:\tlearn: 0.0547562\ttotal: 2.78s\tremaining: 2m 31s\n",
            "18:\tlearn: 0.0542723\ttotal: 2.94s\tremaining: 2m 31s\n",
            "19:\tlearn: 0.0539962\ttotal: 3.1s\tremaining: 2m 31s\n",
            "20:\tlearn: 0.0535729\ttotal: 3.26s\tremaining: 2m 31s\n",
            "21:\tlearn: 0.0531674\ttotal: 3.41s\tremaining: 2m 31s\n",
            "22:\tlearn: 0.0528060\ttotal: 3.56s\tremaining: 2m 31s\n",
            "23:\tlearn: 0.0524908\ttotal: 3.71s\tremaining: 2m 31s\n",
            "24:\tlearn: 0.0522339\ttotal: 3.87s\tremaining: 2m 30s\n",
            "25:\tlearn: 0.0520152\ttotal: 4.03s\tremaining: 2m 30s\n",
            "26:\tlearn: 0.0515531\ttotal: 4.17s\tremaining: 2m 30s\n",
            "27:\tlearn: 0.0512797\ttotal: 4.32s\tremaining: 2m 29s\n",
            "28:\tlearn: 0.0509707\ttotal: 4.48s\tremaining: 2m 30s\n",
            "29:\tlearn: 0.0508626\ttotal: 4.64s\tremaining: 2m 30s\n",
            "30:\tlearn: 0.0506836\ttotal: 4.79s\tremaining: 2m 29s\n",
            "31:\tlearn: 0.0504926\ttotal: 4.94s\tremaining: 2m 29s\n",
            "32:\tlearn: 0.0502911\ttotal: 5.1s\tremaining: 2m 29s\n",
            "33:\tlearn: 0.0501622\ttotal: 5.25s\tremaining: 2m 29s\n",
            "34:\tlearn: 0.0499282\ttotal: 5.41s\tremaining: 2m 29s\n",
            "35:\tlearn: 0.0497353\ttotal: 5.56s\tremaining: 2m 28s\n",
            "36:\tlearn: 0.0496373\ttotal: 5.7s\tremaining: 2m 28s\n",
            "37:\tlearn: 0.0494231\ttotal: 5.85s\tremaining: 2m 28s\n",
            "38:\tlearn: 0.0492846\ttotal: 6.02s\tremaining: 2m 28s\n",
            "39:\tlearn: 0.0489973\ttotal: 6.16s\tremaining: 2m 27s\n",
            "40:\tlearn: 0.0488633\ttotal: 6.31s\tremaining: 2m 27s\n",
            "41:\tlearn: 0.0486905\ttotal: 6.48s\tremaining: 2m 27s\n",
            "42:\tlearn: 0.0485731\ttotal: 6.63s\tremaining: 2m 27s\n",
            "43:\tlearn: 0.0485017\ttotal: 6.77s\tremaining: 2m 27s\n",
            "44:\tlearn: 0.0483949\ttotal: 6.92s\tremaining: 2m 26s\n",
            "45:\tlearn: 0.0483082\ttotal: 7.05s\tremaining: 2m 26s\n",
            "46:\tlearn: 0.0482426\ttotal: 7.19s\tremaining: 2m 25s\n",
            "47:\tlearn: 0.0481235\ttotal: 7.33s\tremaining: 2m 25s\n",
            "48:\tlearn: 0.0480560\ttotal: 7.5s\tremaining: 2m 25s\n",
            "49:\tlearn: 0.0479927\ttotal: 7.66s\tremaining: 2m 25s\n",
            "50:\tlearn: 0.0478773\ttotal: 7.81s\tremaining: 2m 25s\n",
            "51:\tlearn: 0.0477985\ttotal: 7.98s\tremaining: 2m 25s\n",
            "52:\tlearn: 0.0476693\ttotal: 8.14s\tremaining: 2m 25s\n",
            "53:\tlearn: 0.0475646\ttotal: 8.28s\tremaining: 2m 25s\n",
            "54:\tlearn: 0.0475124\ttotal: 8.43s\tremaining: 2m 24s\n",
            "55:\tlearn: 0.0472872\ttotal: 8.59s\tremaining: 2m 24s\n",
            "56:\tlearn: 0.0472195\ttotal: 8.75s\tremaining: 2m 24s\n",
            "57:\tlearn: 0.0471389\ttotal: 8.9s\tremaining: 2m 24s\n",
            "58:\tlearn: 0.0470752\ttotal: 9.06s\tremaining: 2m 24s\n",
            "59:\tlearn: 0.0469738\ttotal: 9.21s\tremaining: 2m 24s\n",
            "60:\tlearn: 0.0469141\ttotal: 9.36s\tremaining: 2m 24s\n",
            "61:\tlearn: 0.0468447\ttotal: 9.52s\tremaining: 2m 24s\n",
            "62:\tlearn: 0.0467746\ttotal: 9.68s\tremaining: 2m 23s\n",
            "63:\tlearn: 0.0467306\ttotal: 9.82s\tremaining: 2m 23s\n",
            "64:\tlearn: 0.0466763\ttotal: 9.97s\tremaining: 2m 23s\n",
            "65:\tlearn: 0.0466125\ttotal: 10.1s\tremaining: 2m 23s\n",
            "66:\tlearn: 0.0465136\ttotal: 10.3s\tremaining: 2m 23s\n",
            "67:\tlearn: 0.0464594\ttotal: 10.4s\tremaining: 2m 22s\n",
            "68:\tlearn: 0.0463787\ttotal: 10.6s\tremaining: 2m 22s\n",
            "69:\tlearn: 0.0463285\ttotal: 10.7s\tremaining: 2m 22s\n",
            "70:\tlearn: 0.0462833\ttotal: 10.9s\tremaining: 2m 22s\n",
            "71:\tlearn: 0.0462239\ttotal: 11s\tremaining: 2m 22s\n",
            "72:\tlearn: 0.0461548\ttotal: 11.2s\tremaining: 2m 22s\n",
            "73:\tlearn: 0.0461109\ttotal: 11.3s\tremaining: 2m 21s\n",
            "74:\tlearn: 0.0460655\ttotal: 11.5s\tremaining: 2m 21s\n",
            "75:\tlearn: 0.0460107\ttotal: 11.6s\tremaining: 2m 21s\n",
            "76:\tlearn: 0.0459420\ttotal: 11.8s\tremaining: 2m 21s\n",
            "77:\tlearn: 0.0458787\ttotal: 12s\tremaining: 2m 21s\n",
            "78:\tlearn: 0.0457875\ttotal: 12.1s\tremaining: 2m 21s\n",
            "79:\tlearn: 0.0457347\ttotal: 12.3s\tremaining: 2m 21s\n",
            "80:\tlearn: 0.0456986\ttotal: 12.4s\tremaining: 2m 21s\n",
            "81:\tlearn: 0.0456576\ttotal: 12.6s\tremaining: 2m 20s\n",
            "82:\tlearn: 0.0456158\ttotal: 12.7s\tremaining: 2m 20s\n",
            "83:\tlearn: 0.0455688\ttotal: 12.9s\tremaining: 2m 20s\n",
            "84:\tlearn: 0.0454757\ttotal: 13s\tremaining: 2m 20s\n",
            "85:\tlearn: 0.0454225\ttotal: 13.2s\tremaining: 2m 19s\n",
            "86:\tlearn: 0.0453881\ttotal: 13.3s\tremaining: 2m 19s\n",
            "87:\tlearn: 0.0453365\ttotal: 13.5s\tremaining: 2m 19s\n",
            "88:\tlearn: 0.0453058\ttotal: 13.6s\tremaining: 2m 19s\n",
            "89:\tlearn: 0.0451709\ttotal: 13.8s\tremaining: 2m 19s\n",
            "90:\tlearn: 0.0451391\ttotal: 13.9s\tremaining: 2m 19s\n",
            "91:\tlearn: 0.0451036\ttotal: 14.1s\tremaining: 2m 18s\n",
            "92:\tlearn: 0.0450276\ttotal: 14.2s\tremaining: 2m 18s\n",
            "93:\tlearn: 0.0449686\ttotal: 14.4s\tremaining: 2m 18s\n",
            "94:\tlearn: 0.0449272\ttotal: 14.5s\tremaining: 2m 18s\n",
            "95:\tlearn: 0.0448850\ttotal: 14.7s\tremaining: 2m 18s\n",
            "96:\tlearn: 0.0448319\ttotal: 14.8s\tremaining: 2m 18s\n",
            "97:\tlearn: 0.0447980\ttotal: 15s\tremaining: 2m 17s\n",
            "98:\tlearn: 0.0447553\ttotal: 15.1s\tremaining: 2m 17s\n",
            "99:\tlearn: 0.0447172\ttotal: 15.3s\tremaining: 2m 17s\n",
            "100:\tlearn: 0.0446867\ttotal: 15.4s\tremaining: 2m 17s\n",
            "101:\tlearn: 0.0446470\ttotal: 15.6s\tremaining: 2m 17s\n",
            "102:\tlearn: 0.0445853\ttotal: 15.8s\tremaining: 2m 17s\n",
            "103:\tlearn: 0.0445496\ttotal: 15.9s\tremaining: 2m 17s\n",
            "104:\tlearn: 0.0444989\ttotal: 16.1s\tremaining: 2m 16s\n",
            "105:\tlearn: 0.0444686\ttotal: 16.2s\tremaining: 2m 16s\n",
            "106:\tlearn: 0.0444368\ttotal: 16.3s\tremaining: 2m 16s\n",
            "107:\tlearn: 0.0444021\ttotal: 16.5s\tremaining: 2m 16s\n",
            "108:\tlearn: 0.0443705\ttotal: 16.6s\tremaining: 2m 16s\n",
            "109:\tlearn: 0.0443420\ttotal: 16.8s\tremaining: 2m 16s\n",
            "110:\tlearn: 0.0443231\ttotal: 17s\tremaining: 2m 15s\n",
            "111:\tlearn: 0.0442796\ttotal: 17.1s\tremaining: 2m 15s\n",
            "112:\tlearn: 0.0442462\ttotal: 17.3s\tremaining: 2m 15s\n",
            "113:\tlearn: 0.0442142\ttotal: 17.4s\tremaining: 2m 15s\n",
            "114:\tlearn: 0.0441546\ttotal: 17.6s\tremaining: 2m 15s\n",
            "115:\tlearn: 0.0441216\ttotal: 17.7s\tremaining: 2m 14s\n",
            "116:\tlearn: 0.0440886\ttotal: 17.9s\tremaining: 2m 14s\n",
            "117:\tlearn: 0.0440529\ttotal: 18s\tremaining: 2m 14s\n",
            "118:\tlearn: 0.0440182\ttotal: 18.2s\tremaining: 2m 14s\n",
            "119:\tlearn: 0.0439830\ttotal: 18.3s\tremaining: 2m 14s\n",
            "120:\tlearn: 0.0439562\ttotal: 18.5s\tremaining: 2m 14s\n",
            "121:\tlearn: 0.0439287\ttotal: 18.6s\tremaining: 2m 14s\n",
            "122:\tlearn: 0.0438964\ttotal: 18.8s\tremaining: 2m 13s\n",
            "123:\tlearn: 0.0438696\ttotal: 18.9s\tremaining: 2m 13s\n",
            "124:\tlearn: 0.0438527\ttotal: 19.1s\tremaining: 2m 13s\n",
            "125:\tlearn: 0.0438178\ttotal: 19.4s\tremaining: 2m 14s\n",
            "126:\tlearn: 0.0437818\ttotal: 20s\tremaining: 2m 17s\n",
            "127:\tlearn: 0.0437519\ttotal: 20.4s\tremaining: 2m 18s\n",
            "128:\tlearn: 0.0437150\ttotal: 20.5s\tremaining: 2m 18s\n",
            "129:\tlearn: 0.0436828\ttotal: 20.7s\tremaining: 2m 18s\n",
            "130:\tlearn: 0.0436683\ttotal: 21.1s\tremaining: 2m 19s\n",
            "131:\tlearn: 0.0436502\ttotal: 21.5s\tremaining: 2m 21s\n",
            "132:\tlearn: 0.0436192\ttotal: 22s\tremaining: 2m 23s\n",
            "133:\tlearn: 0.0435956\ttotal: 22.2s\tremaining: 2m 23s\n",
            "134:\tlearn: 0.0435644\ttotal: 22.3s\tremaining: 2m 23s\n",
            "135:\tlearn: 0.0435290\ttotal: 22.5s\tremaining: 2m 22s\n",
            "136:\tlearn: 0.0435060\ttotal: 22.6s\tremaining: 2m 22s\n",
            "137:\tlearn: 0.0434842\ttotal: 22.8s\tremaining: 2m 22s\n",
            "138:\tlearn: 0.0434477\ttotal: 22.9s\tremaining: 2m 22s\n",
            "139:\tlearn: 0.0433989\ttotal: 23.1s\tremaining: 2m 21s\n",
            "140:\tlearn: 0.0433598\ttotal: 23.3s\tremaining: 2m 21s\n",
            "141:\tlearn: 0.0433373\ttotal: 23.4s\tremaining: 2m 21s\n",
            "142:\tlearn: 0.0433008\ttotal: 23.6s\tremaining: 2m 21s\n",
            "143:\tlearn: 0.0432872\ttotal: 23.7s\tremaining: 2m 21s\n",
            "144:\tlearn: 0.0432667\ttotal: 23.9s\tremaining: 2m 20s\n",
            "145:\tlearn: 0.0432322\ttotal: 24s\tremaining: 2m 20s\n",
            "146:\tlearn: 0.0431996\ttotal: 24.2s\tremaining: 2m 20s\n",
            "147:\tlearn: 0.0431548\ttotal: 24.3s\tremaining: 2m 20s\n",
            "148:\tlearn: 0.0431343\ttotal: 24.5s\tremaining: 2m 19s\n",
            "149:\tlearn: 0.0431166\ttotal: 24.6s\tremaining: 2m 19s\n",
            "150:\tlearn: 0.0431009\ttotal: 24.8s\tremaining: 2m 19s\n",
            "151:\tlearn: 0.0430608\ttotal: 24.9s\tremaining: 2m 19s\n",
            "152:\tlearn: 0.0430322\ttotal: 25.1s\tremaining: 2m 18s\n",
            "153:\tlearn: 0.0430094\ttotal: 25.2s\tremaining: 2m 18s\n",
            "154:\tlearn: 0.0429821\ttotal: 25.4s\tremaining: 2m 18s\n",
            "155:\tlearn: 0.0429571\ttotal: 25.5s\tremaining: 2m 18s\n",
            "156:\tlearn: 0.0429443\ttotal: 25.7s\tremaining: 2m 17s\n",
            "157:\tlearn: 0.0429149\ttotal: 25.8s\tremaining: 2m 17s\n",
            "158:\tlearn: 0.0428797\ttotal: 26s\tremaining: 2m 17s\n",
            "159:\tlearn: 0.0428491\ttotal: 26.1s\tremaining: 2m 17s\n",
            "160:\tlearn: 0.0428245\ttotal: 26.3s\tremaining: 2m 17s\n",
            "161:\tlearn: 0.0427851\ttotal: 26.5s\tremaining: 2m 17s\n",
            "162:\tlearn: 0.0427719\ttotal: 26.6s\tremaining: 2m 16s\n",
            "163:\tlearn: 0.0427469\ttotal: 26.8s\tremaining: 2m 16s\n",
            "164:\tlearn: 0.0427203\ttotal: 27s\tremaining: 2m 16s\n",
            "165:\tlearn: 0.0426923\ttotal: 27.1s\tremaining: 2m 16s\n",
            "166:\tlearn: 0.0426647\ttotal: 27.3s\tremaining: 2m 16s\n",
            "167:\tlearn: 0.0426341\ttotal: 27.4s\tremaining: 2m 15s\n",
            "168:\tlearn: 0.0426137\ttotal: 27.6s\tremaining: 2m 15s\n",
            "169:\tlearn: 0.0425866\ttotal: 27.8s\tremaining: 2m 15s\n",
            "170:\tlearn: 0.0425621\ttotal: 27.9s\tremaining: 2m 15s\n",
            "171:\tlearn: 0.0425174\ttotal: 28.1s\tremaining: 2m 15s\n",
            "172:\tlearn: 0.0424991\ttotal: 28.2s\tremaining: 2m 14s\n",
            "173:\tlearn: 0.0424991\ttotal: 28.3s\tremaining: 2m 14s\n",
            "174:\tlearn: 0.0424776\ttotal: 28.5s\tremaining: 2m 14s\n",
            "175:\tlearn: 0.0424497\ttotal: 28.6s\tremaining: 2m 14s\n",
            "176:\tlearn: 0.0424342\ttotal: 28.8s\tremaining: 2m 13s\n",
            "177:\tlearn: 0.0424251\ttotal: 28.9s\tremaining: 2m 13s\n",
            "178:\tlearn: 0.0424251\ttotal: 29s\tremaining: 2m 13s\n",
            "179:\tlearn: 0.0424251\ttotal: 29.1s\tremaining: 2m 12s\n",
            "180:\tlearn: 0.0424251\ttotal: 29.3s\tremaining: 2m 12s\n",
            "181:\tlearn: 0.0424251\ttotal: 29.4s\tremaining: 2m 12s\n",
            "182:\tlearn: 0.0424250\ttotal: 29.5s\tremaining: 2m 11s\n",
            "183:\tlearn: 0.0424158\ttotal: 29.7s\tremaining: 2m 11s\n",
            "184:\tlearn: 0.0424158\ttotal: 29.8s\tremaining: 2m 11s\n",
            "185:\tlearn: 0.0424157\ttotal: 29.9s\tremaining: 2m 10s\n",
            "186:\tlearn: 0.0424157\ttotal: 30s\tremaining: 2m 10s\n",
            "187:\tlearn: 0.0424158\ttotal: 30.1s\tremaining: 2m 10s\n",
            "188:\tlearn: 0.0424087\ttotal: 30.3s\tremaining: 2m 9s\n",
            "189:\tlearn: 0.0424087\ttotal: 30.4s\tremaining: 2m 9s\n",
            "190:\tlearn: 0.0424087\ttotal: 30.5s\tremaining: 2m 9s\n",
            "191:\tlearn: 0.0424087\ttotal: 30.6s\tremaining: 2m 8s\n",
            "192:\tlearn: 0.0424087\ttotal: 30.7s\tremaining: 2m 8s\n",
            "193:\tlearn: 0.0423787\ttotal: 30.9s\tremaining: 2m 8s\n",
            "194:\tlearn: 0.0423560\ttotal: 31.1s\tremaining: 2m 8s\n",
            "195:\tlearn: 0.0423560\ttotal: 31.2s\tremaining: 2m 7s\n",
            "196:\tlearn: 0.0423339\ttotal: 31.3s\tremaining: 2m 7s\n",
            "197:\tlearn: 0.0423174\ttotal: 31.5s\tremaining: 2m 7s\n",
            "198:\tlearn: 0.0422962\ttotal: 31.6s\tremaining: 2m 7s\n",
            "199:\tlearn: 0.0422962\ttotal: 31.7s\tremaining: 2m 6s\n",
            "200:\tlearn: 0.0422751\ttotal: 31.9s\tremaining: 2m 6s\n",
            "201:\tlearn: 0.0422545\ttotal: 32s\tremaining: 2m 6s\n",
            "202:\tlearn: 0.0422299\ttotal: 32.2s\tremaining: 2m 6s\n",
            "203:\tlearn: 0.0422050\ttotal: 32.3s\tremaining: 2m 6s\n",
            "204:\tlearn: 0.0421959\ttotal: 32.5s\tremaining: 2m 5s\n",
            "205:\tlearn: 0.0421641\ttotal: 32.6s\tremaining: 2m 5s\n",
            "206:\tlearn: 0.0421256\ttotal: 32.8s\tremaining: 2m 5s\n",
            "207:\tlearn: 0.0421037\ttotal: 32.9s\tremaining: 2m 5s\n",
            "208:\tlearn: 0.0421029\ttotal: 33.1s\tremaining: 2m 5s\n",
            "209:\tlearn: 0.0420810\ttotal: 33.2s\tremaining: 2m 5s\n",
            "210:\tlearn: 0.0420603\ttotal: 33.4s\tremaining: 2m 4s\n",
            "211:\tlearn: 0.0420397\ttotal: 33.5s\tremaining: 2m 4s\n",
            "212:\tlearn: 0.0420397\ttotal: 33.7s\tremaining: 2m 4s\n",
            "213:\tlearn: 0.0420133\ttotal: 33.8s\tremaining: 2m 4s\n",
            "214:\tlearn: 0.0419896\ttotal: 34s\tremaining: 2m 3s\n",
            "215:\tlearn: 0.0419865\ttotal: 34.1s\tremaining: 2m 3s\n",
            "216:\tlearn: 0.0419676\ttotal: 34.2s\tremaining: 2m 3s\n",
            "217:\tlearn: 0.0419519\ttotal: 34.4s\tremaining: 2m 3s\n",
            "218:\tlearn: 0.0419519\ttotal: 34.5s\tremaining: 2m 3s\n",
            "219:\tlearn: 0.0419518\ttotal: 34.6s\tremaining: 2m 2s\n",
            "220:\tlearn: 0.0419518\ttotal: 34.7s\tremaining: 2m 2s\n",
            "221:\tlearn: 0.0419518\ttotal: 34.8s\tremaining: 2m 2s\n",
            "222:\tlearn: 0.0419357\ttotal: 35s\tremaining: 2m 1s\n",
            "223:\tlearn: 0.0419357\ttotal: 35.1s\tremaining: 2m 1s\n",
            "224:\tlearn: 0.0419357\ttotal: 35.2s\tremaining: 2m 1s\n",
            "225:\tlearn: 0.0419211\ttotal: 35.4s\tremaining: 2m 1s\n",
            "226:\tlearn: 0.0418927\ttotal: 35.5s\tremaining: 2m\n",
            "227:\tlearn: 0.0418927\ttotal: 35.6s\tremaining: 2m\n",
            "228:\tlearn: 0.0418879\ttotal: 35.8s\tremaining: 2m\n",
            "229:\tlearn: 0.0418683\ttotal: 35.9s\tremaining: 2m\n",
            "230:\tlearn: 0.0418525\ttotal: 36.1s\tremaining: 2m\n",
            "231:\tlearn: 0.0418303\ttotal: 36.3s\tremaining: 2m\n",
            "232:\tlearn: 0.0418116\ttotal: 36.4s\tremaining: 1m 59s\n",
            "233:\tlearn: 0.0417917\ttotal: 36.6s\tremaining: 1m 59s\n",
            "234:\tlearn: 0.0417917\ttotal: 36.7s\tremaining: 1m 59s\n",
            "235:\tlearn: 0.0417917\ttotal: 36.8s\tremaining: 1m 59s\n",
            "236:\tlearn: 0.0417917\ttotal: 36.9s\tremaining: 1m 58s\n",
            "237:\tlearn: 0.0417917\ttotal: 37s\tremaining: 1m 58s\n",
            "238:\tlearn: 0.0417917\ttotal: 37.2s\tremaining: 1m 58s\n",
            "239:\tlearn: 0.0417917\ttotal: 37.3s\tremaining: 1m 58s\n",
            "240:\tlearn: 0.0417917\ttotal: 37.4s\tremaining: 1m 57s\n",
            "241:\tlearn: 0.0417893\ttotal: 37.5s\tremaining: 1m 57s\n",
            "242:\tlearn: 0.0417893\ttotal: 37.6s\tremaining: 1m 57s\n",
            "243:\tlearn: 0.0417893\ttotal: 37.8s\tremaining: 1m 57s\n",
            "244:\tlearn: 0.0417893\ttotal: 37.9s\tremaining: 1m 56s\n",
            "245:\tlearn: 0.0417893\ttotal: 38s\tremaining: 1m 56s\n",
            "246:\tlearn: 0.0417825\ttotal: 38.2s\tremaining: 1m 56s\n",
            "247:\tlearn: 0.0417825\ttotal: 38.3s\tremaining: 1m 56s\n",
            "248:\tlearn: 0.0417556\ttotal: 38.8s\tremaining: 1m 56s\n",
            "249:\tlearn: 0.0417556\ttotal: 39.1s\tremaining: 1m 57s\n",
            "250:\tlearn: 0.0417556\ttotal: 39.4s\tremaining: 1m 57s\n",
            "251:\tlearn: 0.0417555\ttotal: 39.5s\tremaining: 1m 57s\n",
            "252:\tlearn: 0.0417555\ttotal: 39.6s\tremaining: 1m 57s\n",
            "253:\tlearn: 0.0417555\ttotal: 39.7s\tremaining: 1m 56s\n",
            "254:\tlearn: 0.0417555\ttotal: 40.1s\tremaining: 1m 57s\n",
            "255:\tlearn: 0.0417554\ttotal: 40.5s\tremaining: 1m 57s\n",
            "256:\tlearn: 0.0417554\ttotal: 40.8s\tremaining: 1m 57s\n",
            "257:\tlearn: 0.0417389\ttotal: 40.9s\tremaining: 1m 57s\n",
            "258:\tlearn: 0.0417222\ttotal: 41.1s\tremaining: 1m 57s\n",
            "259:\tlearn: 0.0417079\ttotal: 41.2s\tremaining: 1m 57s\n",
            "260:\tlearn: 0.0416856\ttotal: 41.4s\tremaining: 1m 57s\n",
            "261:\tlearn: 0.0416839\ttotal: 41.5s\tremaining: 1m 56s\n",
            "262:\tlearn: 0.0416660\ttotal: 41.7s\tremaining: 1m 56s\n",
            "263:\tlearn: 0.0416660\ttotal: 41.8s\tremaining: 1m 56s\n",
            "264:\tlearn: 0.0416659\ttotal: 41.9s\tremaining: 1m 56s\n",
            "265:\tlearn: 0.0416497\ttotal: 42.1s\tremaining: 1m 56s\n",
            "266:\tlearn: 0.0416400\ttotal: 42.2s\tremaining: 1m 55s\n",
            "267:\tlearn: 0.0416244\ttotal: 42.4s\tremaining: 1m 55s\n",
            "268:\tlearn: 0.0416084\ttotal: 42.5s\tremaining: 1m 55s\n",
            "269:\tlearn: 0.0415979\ttotal: 42.7s\tremaining: 1m 55s\n",
            "270:\tlearn: 0.0415861\ttotal: 42.8s\tremaining: 1m 55s\n",
            "271:\tlearn: 0.0415718\ttotal: 43s\tremaining: 1m 55s\n",
            "272:\tlearn: 0.0415506\ttotal: 43.1s\tremaining: 1m 54s\n",
            "273:\tlearn: 0.0415263\ttotal: 43.3s\tremaining: 1m 54s\n",
            "274:\tlearn: 0.0415104\ttotal: 43.5s\tremaining: 1m 54s\n",
            "275:\tlearn: 0.0414982\ttotal: 43.6s\tremaining: 1m 54s\n",
            "276:\tlearn: 0.0414982\ttotal: 43.7s\tremaining: 1m 54s\n",
            "277:\tlearn: 0.0414887\ttotal: 43.9s\tremaining: 1m 53s\n",
            "278:\tlearn: 0.0414709\ttotal: 44s\tremaining: 1m 53s\n",
            "279:\tlearn: 0.0414581\ttotal: 44.1s\tremaining: 1m 53s\n",
            "280:\tlearn: 0.0414314\ttotal: 44.3s\tremaining: 1m 53s\n",
            "281:\tlearn: 0.0414099\ttotal: 44.5s\tremaining: 1m 53s\n",
            "282:\tlearn: 0.0413981\ttotal: 44.6s\tremaining: 1m 53s\n",
            "283:\tlearn: 0.0413821\ttotal: 44.8s\tremaining: 1m 52s\n",
            "284:\tlearn: 0.0413649\ttotal: 44.9s\tremaining: 1m 52s\n",
            "285:\tlearn: 0.0413524\ttotal: 45.1s\tremaining: 1m 52s\n",
            "286:\tlearn: 0.0413309\ttotal: 45.2s\tremaining: 1m 52s\n",
            "287:\tlearn: 0.0413128\ttotal: 45.4s\tremaining: 1m 52s\n",
            "288:\tlearn: 0.0413127\ttotal: 45.5s\tremaining: 1m 51s\n",
            "289:\tlearn: 0.0413038\ttotal: 45.6s\tremaining: 1m 51s\n",
            "290:\tlearn: 0.0412862\ttotal: 45.8s\tremaining: 1m 51s\n",
            "291:\tlearn: 0.0412650\ttotal: 45.9s\tremaining: 1m 51s\n",
            "292:\tlearn: 0.0412650\ttotal: 46s\tremaining: 1m 51s\n",
            "293:\tlearn: 0.0412511\ttotal: 46.2s\tremaining: 1m 50s\n",
            "294:\tlearn: 0.0412273\ttotal: 46.4s\tremaining: 1m 50s\n",
            "295:\tlearn: 0.0412118\ttotal: 46.5s\tremaining: 1m 50s\n",
            "296:\tlearn: 0.0411867\ttotal: 46.7s\tremaining: 1m 50s\n",
            "297:\tlearn: 0.0411536\ttotal: 46.8s\tremaining: 1m 50s\n",
            "298:\tlearn: 0.0411385\ttotal: 47s\tremaining: 1m 50s\n",
            "299:\tlearn: 0.0411267\ttotal: 47.1s\tremaining: 1m 50s\n",
            "300:\tlearn: 0.0411267\ttotal: 47.3s\tremaining: 1m 49s\n",
            "301:\tlearn: 0.0411002\ttotal: 47.4s\tremaining: 1m 49s\n",
            "302:\tlearn: 0.0410692\ttotal: 47.6s\tremaining: 1m 49s\n",
            "303:\tlearn: 0.0410529\ttotal: 47.7s\tremaining: 1m 49s\n",
            "304:\tlearn: 0.0410383\ttotal: 47.9s\tremaining: 1m 49s\n",
            "305:\tlearn: 0.0410245\ttotal: 48s\tremaining: 1m 48s\n",
            "306:\tlearn: 0.0410008\ttotal: 48.2s\tremaining: 1m 48s\n",
            "307:\tlearn: 0.0409807\ttotal: 48.3s\tremaining: 1m 48s\n",
            "308:\tlearn: 0.0409670\ttotal: 48.5s\tremaining: 1m 48s\n",
            "309:\tlearn: 0.0409670\ttotal: 48.6s\tremaining: 1m 48s\n",
            "310:\tlearn: 0.0409670\ttotal: 48.7s\tremaining: 1m 47s\n",
            "311:\tlearn: 0.0409512\ttotal: 48.9s\tremaining: 1m 47s\n",
            "312:\tlearn: 0.0409350\ttotal: 49s\tremaining: 1m 47s\n",
            "313:\tlearn: 0.0409253\ttotal: 49.2s\tremaining: 1m 47s\n",
            "314:\tlearn: 0.0409237\ttotal: 49.3s\tremaining: 1m 47s\n",
            "315:\tlearn: 0.0409030\ttotal: 49.5s\tremaining: 1m 47s\n",
            "316:\tlearn: 0.0408781\ttotal: 49.6s\tremaining: 1m 46s\n",
            "317:\tlearn: 0.0408551\ttotal: 49.8s\tremaining: 1m 46s\n",
            "318:\tlearn: 0.0408426\ttotal: 49.9s\tremaining: 1m 46s\n",
            "319:\tlearn: 0.0408218\ttotal: 50.1s\tremaining: 1m 46s\n",
            "320:\tlearn: 0.0408110\ttotal: 50.2s\tremaining: 1m 46s\n",
            "321:\tlearn: 0.0408015\ttotal: 50.4s\tremaining: 1m 46s\n",
            "322:\tlearn: 0.0408015\ttotal: 50.5s\tremaining: 1m 45s\n",
            "323:\tlearn: 0.0407925\ttotal: 50.7s\tremaining: 1m 45s\n",
            "324:\tlearn: 0.0407924\ttotal: 50.8s\tremaining: 1m 45s\n",
            "325:\tlearn: 0.0407729\ttotal: 50.9s\tremaining: 1m 45s\n",
            "326:\tlearn: 0.0407555\ttotal: 51.1s\tremaining: 1m 45s\n",
            "327:\tlearn: 0.0407406\ttotal: 51.2s\tremaining: 1m 44s\n",
            "328:\tlearn: 0.0407202\ttotal: 51.4s\tremaining: 1m 44s\n",
            "329:\tlearn: 0.0407201\ttotal: 51.5s\tremaining: 1m 44s\n",
            "330:\tlearn: 0.0407064\ttotal: 51.7s\tremaining: 1m 44s\n",
            "331:\tlearn: 0.0406920\ttotal: 51.8s\tremaining: 1m 44s\n",
            "332:\tlearn: 0.0406731\ttotal: 52s\tremaining: 1m 44s\n",
            "333:\tlearn: 0.0406640\ttotal: 52.1s\tremaining: 1m 43s\n",
            "334:\tlearn: 0.0406457\ttotal: 52.3s\tremaining: 1m 43s\n",
            "335:\tlearn: 0.0406457\ttotal: 52.4s\tremaining: 1m 43s\n",
            "336:\tlearn: 0.0406456\ttotal: 52.6s\tremaining: 1m 43s\n",
            "337:\tlearn: 0.0406368\ttotal: 52.7s\tremaining: 1m 43s\n",
            "338:\tlearn: 0.0406214\ttotal: 52.9s\tremaining: 1m 43s\n",
            "339:\tlearn: 0.0406215\ttotal: 53s\tremaining: 1m 42s\n",
            "340:\tlearn: 0.0406215\ttotal: 53.1s\tremaining: 1m 42s\n",
            "341:\tlearn: 0.0406068\ttotal: 53.3s\tremaining: 1m 42s\n",
            "342:\tlearn: 0.0405864\ttotal: 53.4s\tremaining: 1m 42s\n",
            "343:\tlearn: 0.0405773\ttotal: 53.6s\tremaining: 1m 42s\n",
            "344:\tlearn: 0.0405616\ttotal: 53.7s\tremaining: 1m 42s\n",
            "345:\tlearn: 0.0405455\ttotal: 53.9s\tremaining: 1m 41s\n",
            "346:\tlearn: 0.0405274\ttotal: 54.1s\tremaining: 1m 41s\n",
            "347:\tlearn: 0.0405274\ttotal: 54.2s\tremaining: 1m 41s\n",
            "348:\tlearn: 0.0405274\ttotal: 54.3s\tremaining: 1m 41s\n",
            "349:\tlearn: 0.0405109\ttotal: 54.4s\tremaining: 1m 41s\n",
            "350:\tlearn: 0.0404959\ttotal: 54.6s\tremaining: 1m 40s\n",
            "351:\tlearn: 0.0404822\ttotal: 54.7s\tremaining: 1m 40s\n",
            "352:\tlearn: 0.0404762\ttotal: 54.9s\tremaining: 1m 40s\n",
            "353:\tlearn: 0.0404762\ttotal: 55s\tremaining: 1m 40s\n",
            "354:\tlearn: 0.0404699\ttotal: 55.2s\tremaining: 1m 40s\n",
            "355:\tlearn: 0.0404534\ttotal: 55.3s\tremaining: 1m 40s\n",
            "356:\tlearn: 0.0404421\ttotal: 55.5s\tremaining: 1m 39s\n",
            "357:\tlearn: 0.0404114\ttotal: 55.6s\tremaining: 1m 39s\n",
            "358:\tlearn: 0.0404114\ttotal: 55.8s\tremaining: 1m 39s\n",
            "359:\tlearn: 0.0404022\ttotal: 55.9s\tremaining: 1m 39s\n",
            "360:\tlearn: 0.0403918\ttotal: 56s\tremaining: 1m 39s\n",
            "361:\tlearn: 0.0403918\ttotal: 56.2s\tremaining: 1m 38s\n",
            "362:\tlearn: 0.0403918\ttotal: 56.3s\tremaining: 1m 38s\n",
            "363:\tlearn: 0.0403807\ttotal: 56.4s\tremaining: 1m 38s\n",
            "364:\tlearn: 0.0403632\ttotal: 56.6s\tremaining: 1m 38s\n",
            "365:\tlearn: 0.0403632\ttotal: 56.7s\tremaining: 1m 38s\n",
            "366:\tlearn: 0.0403632\ttotal: 56.8s\tremaining: 1m 37s\n",
            "367:\tlearn: 0.0403632\ttotal: 56.9s\tremaining: 1m 37s\n",
            "368:\tlearn: 0.0403631\ttotal: 57s\tremaining: 1m 37s\n",
            "369:\tlearn: 0.0403496\ttotal: 57.2s\tremaining: 1m 37s\n",
            "370:\tlearn: 0.0403496\ttotal: 57.3s\tremaining: 1m 37s\n",
            "371:\tlearn: 0.0403496\ttotal: 57.4s\tremaining: 1m 36s\n",
            "372:\tlearn: 0.0403496\ttotal: 57.5s\tremaining: 1m 36s\n",
            "373:\tlearn: 0.0403496\ttotal: 57.6s\tremaining: 1m 36s\n",
            "374:\tlearn: 0.0403333\ttotal: 57.8s\tremaining: 1m 36s\n",
            "375:\tlearn: 0.0403333\ttotal: 57.9s\tremaining: 1m 36s\n",
            "376:\tlearn: 0.0403333\ttotal: 58s\tremaining: 1m 35s\n",
            "377:\tlearn: 0.0403333\ttotal: 58.1s\tremaining: 1m 35s\n",
            "378:\tlearn: 0.0403333\ttotal: 58.2s\tremaining: 1m 35s\n",
            "379:\tlearn: 0.0403333\ttotal: 58.4s\tremaining: 1m 35s\n",
            "380:\tlearn: 0.0403247\ttotal: 58.5s\tremaining: 1m 35s\n",
            "381:\tlearn: 0.0403247\ttotal: 58.6s\tremaining: 1m 34s\n",
            "382:\tlearn: 0.0403246\ttotal: 58.7s\tremaining: 1m 34s\n",
            "383:\tlearn: 0.0403246\ttotal: 58.9s\tremaining: 1m 34s\n",
            "384:\tlearn: 0.0403246\ttotal: 59s\tremaining: 1m 34s\n",
            "385:\tlearn: 0.0403246\ttotal: 59.1s\tremaining: 1m 33s\n",
            "386:\tlearn: 0.0403246\ttotal: 59.2s\tremaining: 1m 33s\n",
            "387:\tlearn: 0.0403246\ttotal: 59.3s\tremaining: 1m 33s\n",
            "388:\tlearn: 0.0403246\ttotal: 59.4s\tremaining: 1m 33s\n",
            "389:\tlearn: 0.0403246\ttotal: 59.5s\tremaining: 1m 33s\n",
            "390:\tlearn: 0.0403246\ttotal: 59.7s\tremaining: 1m 32s\n",
            "391:\tlearn: 0.0403246\ttotal: 59.8s\tremaining: 1m 32s\n",
            "392:\tlearn: 0.0403246\ttotal: 59.9s\tremaining: 1m 32s\n",
            "393:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 32s\n",
            "394:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 32s\n",
            "395:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 31s\n",
            "396:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 31s\n",
            "397:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 31s\n",
            "398:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 31s\n",
            "399:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 31s\n",
            "400:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 30s\n",
            "401:\tlearn: 0.0403246\ttotal: 1m\tremaining: 1m 30s\n",
            "402:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 30s\n",
            "403:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 30s\n",
            "404:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 30s\n",
            "405:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 29s\n",
            "406:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 29s\n",
            "407:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 29s\n",
            "408:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 29s\n",
            "409:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 28s\n",
            "410:\tlearn: 0.0403246\ttotal: 1m 1s\tremaining: 1m 28s\n",
            "411:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 28s\n",
            "412:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 28s\n",
            "413:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 28s\n",
            "414:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 27s\n",
            "415:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 27s\n",
            "416:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 27s\n",
            "417:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 27s\n",
            "418:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 27s\n",
            "419:\tlearn: 0.0403246\ttotal: 1m 2s\tremaining: 1m 26s\n",
            "420:\tlearn: 0.0403246\ttotal: 1m 3s\tremaining: 1m 26s\n",
            "421:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 26s\n",
            "422:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 26s\n",
            "423:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 26s\n",
            "424:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 26s\n",
            "425:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 25s\n",
            "426:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 25s\n",
            "427:\tlearn: 0.0403083\ttotal: 1m 3s\tremaining: 1m 25s\n",
            "428:\tlearn: 0.0403083\ttotal: 1m 4s\tremaining: 1m 25s\n",
            "429:\tlearn: 0.0403083\ttotal: 1m 4s\tremaining: 1m 25s\n",
            "430:\tlearn: 0.0403083\ttotal: 1m 4s\tremaining: 1m 24s\n",
            "431:\tlearn: 0.0403083\ttotal: 1m 4s\tremaining: 1m 24s\n",
            "432:\tlearn: 0.0403083\ttotal: 1m 4s\tremaining: 1m 24s\n",
            "433:\tlearn: 0.0403083\ttotal: 1m 4s\tremaining: 1m 24s\n",
            "434:\tlearn: 0.0403082\ttotal: 1m 4s\tremaining: 1m 24s\n",
            "435:\tlearn: 0.0403082\ttotal: 1m 4s\tremaining: 1m 23s\n",
            "436:\tlearn: 0.0403082\ttotal: 1m 4s\tremaining: 1m 23s\n",
            "437:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 23s\n",
            "438:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 23s\n",
            "439:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 23s\n",
            "440:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 22s\n",
            "441:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 22s\n",
            "442:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 22s\n",
            "443:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 22s\n",
            "444:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 22s\n",
            "445:\tlearn: 0.0403082\ttotal: 1m 5s\tremaining: 1m 21s\n",
            "446:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 21s\n",
            "447:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 21s\n",
            "448:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 21s\n",
            "449:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 21s\n",
            "450:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 20s\n",
            "451:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 20s\n",
            "452:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 20s\n",
            "453:\tlearn: 0.0403082\ttotal: 1m 6s\tremaining: 1m 20s\n",
            "454:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 20s\n",
            "455:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 20s\n",
            "456:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 19s\n",
            "457:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 19s\n",
            "458:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 19s\n",
            "459:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 19s\n",
            "460:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 19s\n",
            "461:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 18s\n",
            "462:\tlearn: 0.0403082\ttotal: 1m 7s\tremaining: 1m 18s\n",
            "463:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 18s\n",
            "464:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 18s\n",
            "465:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 18s\n",
            "466:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 18s\n",
            "467:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 17s\n",
            "468:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 17s\n",
            "469:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 17s\n",
            "470:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 17s\n",
            "471:\tlearn: 0.0403082\ttotal: 1m 8s\tremaining: 1m 17s\n",
            "472:\tlearn: 0.0403082\ttotal: 1m 9s\tremaining: 1m 16s\n",
            "473:\tlearn: 0.0403081\ttotal: 1m 9s\tremaining: 1m 16s\n",
            "474:\tlearn: 0.0403081\ttotal: 1m 9s\tremaining: 1m 16s\n",
            "475:\tlearn: 0.0403082\ttotal: 1m 9s\tremaining: 1m 16s\n",
            "476:\tlearn: 0.0403082\ttotal: 1m 9s\tremaining: 1m 16s\n",
            "477:\tlearn: 0.0403081\ttotal: 1m 9s\tremaining: 1m 16s\n",
            "478:\tlearn: 0.0403081\ttotal: 1m 9s\tremaining: 1m 15s\n",
            "479:\tlearn: 0.0403081\ttotal: 1m 9s\tremaining: 1m 15s\n",
            "480:\tlearn: 0.0403081\ttotal: 1m 9s\tremaining: 1m 15s\n",
            "481:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 15s\n",
            "482:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 15s\n",
            "483:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 14s\n",
            "484:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 14s\n",
            "485:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 14s\n",
            "486:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 14s\n",
            "487:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 14s\n",
            "488:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 14s\n",
            "489:\tlearn: 0.0403081\ttotal: 1m 10s\tremaining: 1m 13s\n",
            "490:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 13s\n",
            "491:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 13s\n",
            "492:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 13s\n",
            "493:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 13s\n",
            "494:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 12s\n",
            "495:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 12s\n",
            "496:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 12s\n",
            "497:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 12s\n",
            "498:\tlearn: 0.0403081\ttotal: 1m 11s\tremaining: 1m 12s\n",
            "499:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 12s\n",
            "500:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 11s\n",
            "501:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 11s\n",
            "502:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 11s\n",
            "503:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 11s\n",
            "504:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 11s\n",
            "505:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 11s\n",
            "506:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 10s\n",
            "507:\tlearn: 0.0403081\ttotal: 1m 12s\tremaining: 1m 10s\n",
            "508:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 10s\n",
            "509:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 10s\n",
            "510:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 10s\n",
            "511:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 9s\n",
            "512:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 9s\n",
            "513:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 9s\n",
            "514:\tlearn: 0.0403081\ttotal: 1m 13s\tremaining: 1m 9s\n",
            "515:\tlearn: 0.0403080\ttotal: 1m 13s\tremaining: 1m 9s\n",
            "516:\tlearn: 0.0403080\ttotal: 1m 13s\tremaining: 1m 9s\n",
            "517:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 8s\n",
            "518:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 8s\n",
            "519:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 8s\n",
            "520:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 8s\n",
            "521:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 8s\n",
            "522:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 8s\n",
            "523:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 7s\n",
            "524:\tlearn: 0.0403080\ttotal: 1m 14s\tremaining: 1m 7s\n",
            "525:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 7s\n",
            "526:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 7s\n",
            "527:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 7s\n",
            "528:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 7s\n",
            "529:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 6s\n",
            "530:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 6s\n",
            "531:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 6s\n",
            "532:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 6s\n",
            "533:\tlearn: 0.0403080\ttotal: 1m 15s\tremaining: 1m 6s\n",
            "534:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 6s\n",
            "535:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 5s\n",
            "536:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 5s\n",
            "537:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 5s\n",
            "538:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 5s\n",
            "539:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 5s\n",
            "540:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 5s\n",
            "541:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 4s\n",
            "542:\tlearn: 0.0403080\ttotal: 1m 16s\tremaining: 1m 4s\n",
            "543:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 4s\n",
            "544:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 4s\n",
            "545:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 4s\n",
            "546:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 4s\n",
            "547:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 3s\n",
            "548:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 3s\n",
            "549:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 3s\n",
            "550:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 3s\n",
            "551:\tlearn: 0.0403080\ttotal: 1m 17s\tremaining: 1m 3s\n",
            "552:\tlearn: 0.0403080\ttotal: 1m 18s\tremaining: 1m 3s\n",
            "553:\tlearn: 0.0403080\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "554:\tlearn: 0.0403080\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "555:\tlearn: 0.0403080\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "556:\tlearn: 0.0403079\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "557:\tlearn: 0.0403026\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "558:\tlearn: 0.0403026\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "559:\tlearn: 0.0403026\ttotal: 1m 18s\tremaining: 1m 2s\n",
            "560:\tlearn: 0.0402948\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "561:\tlearn: 0.0402948\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "562:\tlearn: 0.0402948\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "563:\tlearn: 0.0402948\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "564:\tlearn: 0.0402948\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "565:\tlearn: 0.0402819\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "566:\tlearn: 0.0402675\ttotal: 1m 19s\tremaining: 1m 1s\n",
            "567:\tlearn: 0.0402612\ttotal: 1m 20s\tremaining: 1m\n",
            "568:\tlearn: 0.0402612\ttotal: 1m 20s\tremaining: 1m\n",
            "569:\tlearn: 0.0402612\ttotal: 1m 20s\tremaining: 1m\n",
            "570:\tlearn: 0.0402612\ttotal: 1m 20s\tremaining: 1m\n",
            "571:\tlearn: 0.0402426\ttotal: 1m 20s\tremaining: 1m\n",
            "572:\tlearn: 0.0402426\ttotal: 1m 20s\tremaining: 1m\n",
            "573:\tlearn: 0.0402426\ttotal: 1m 20s\tremaining: 60s\n",
            "574:\tlearn: 0.0402426\ttotal: 1m 20s\tremaining: 59.8s\n",
            "575:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 59.7s\n",
            "576:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 59.5s\n",
            "577:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 59.4s\n",
            "578:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 59.2s\n",
            "579:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 59s\n",
            "580:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 58.9s\n",
            "581:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 58.7s\n",
            "582:\tlearn: 0.0402426\ttotal: 1m 21s\tremaining: 58.5s\n",
            "583:\tlearn: 0.0402359\ttotal: 1m 21s\tremaining: 58.4s\n",
            "584:\tlearn: 0.0402359\ttotal: 1m 22s\tremaining: 58.2s\n",
            "585:\tlearn: 0.0402359\ttotal: 1m 22s\tremaining: 58.1s\n",
            "586:\tlearn: 0.0402359\ttotal: 1m 22s\tremaining: 57.9s\n",
            "587:\tlearn: 0.0402359\ttotal: 1m 22s\tremaining: 57.8s\n",
            "588:\tlearn: 0.0402359\ttotal: 1m 22s\tremaining: 57.6s\n",
            "589:\tlearn: 0.0402359\ttotal: 1m 22s\tremaining: 57.5s\n",
            "590:\tlearn: 0.0402128\ttotal: 1m 22s\tremaining: 57.3s\n",
            "591:\tlearn: 0.0402128\ttotal: 1m 22s\tremaining: 57.2s\n",
            "592:\tlearn: 0.0402128\ttotal: 1m 23s\tremaining: 57s\n",
            "593:\tlearn: 0.0402128\ttotal: 1m 23s\tremaining: 56.9s\n",
            "594:\tlearn: 0.0402128\ttotal: 1m 23s\tremaining: 56.7s\n",
            "595:\tlearn: 0.0401990\ttotal: 1m 23s\tremaining: 56.6s\n",
            "596:\tlearn: 0.0401990\ttotal: 1m 23s\tremaining: 56.4s\n",
            "597:\tlearn: 0.0401990\ttotal: 1m 23s\tremaining: 56.3s\n",
            "598:\tlearn: 0.0401990\ttotal: 1m 23s\tremaining: 56.1s\n",
            "599:\tlearn: 0.0401990\ttotal: 1m 23s\tremaining: 56s\n",
            "600:\tlearn: 0.0401990\ttotal: 1m 24s\tremaining: 55.8s\n",
            "601:\tlearn: 0.0401990\ttotal: 1m 24s\tremaining: 55.6s\n",
            "602:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 55.5s\n",
            "603:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 55.3s\n",
            "604:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 55.2s\n",
            "605:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 55s\n",
            "606:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 54.9s\n",
            "607:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 54.7s\n",
            "608:\tlearn: 0.0401888\ttotal: 1m 24s\tremaining: 54.6s\n",
            "609:\tlearn: 0.0401888\ttotal: 1m 25s\tremaining: 54.4s\n",
            "610:\tlearn: 0.0401888\ttotal: 1m 25s\tremaining: 54.3s\n",
            "611:\tlearn: 0.0401888\ttotal: 1m 25s\tremaining: 54.1s\n",
            "612:\tlearn: 0.0401888\ttotal: 1m 25s\tremaining: 54s\n",
            "613:\tlearn: 0.0401717\ttotal: 1m 25s\tremaining: 53.8s\n",
            "614:\tlearn: 0.0401717\ttotal: 1m 25s\tremaining: 53.7s\n",
            "615:\tlearn: 0.0401717\ttotal: 1m 25s\tremaining: 53.5s\n",
            "616:\tlearn: 0.0401717\ttotal: 1m 25s\tremaining: 53.3s\n",
            "617:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 53.2s\n",
            "618:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 53s\n",
            "619:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 52.9s\n",
            "620:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 52.7s\n",
            "621:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 52.6s\n",
            "622:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 52.4s\n",
            "623:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 52.3s\n",
            "624:\tlearn: 0.0401717\ttotal: 1m 26s\tremaining: 52.1s\n",
            "625:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 52s\n",
            "626:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 51.8s\n",
            "627:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 51.7s\n",
            "628:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 51.5s\n",
            "629:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 51.4s\n",
            "630:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 51.2s\n",
            "631:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 51.1s\n",
            "632:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 50.9s\n",
            "633:\tlearn: 0.0401717\ttotal: 1m 27s\tremaining: 50.8s\n",
            "634:\tlearn: 0.0401717\ttotal: 1m 28s\tremaining: 50.6s\n",
            "635:\tlearn: 0.0401717\ttotal: 1m 28s\tremaining: 50.5s\n",
            "636:\tlearn: 0.0401717\ttotal: 1m 28s\tremaining: 50.3s\n",
            "637:\tlearn: 0.0401717\ttotal: 1m 28s\tremaining: 50.2s\n",
            "638:\tlearn: 0.0401716\ttotal: 1m 28s\tremaining: 50s\n",
            "639:\tlearn: 0.0401716\ttotal: 1m 28s\tremaining: 49.9s\n",
            "640:\tlearn: 0.0401716\ttotal: 1m 28s\tremaining: 49.7s\n",
            "641:\tlearn: 0.0401716\ttotal: 1m 28s\tremaining: 49.6s\n",
            "642:\tlearn: 0.0401716\ttotal: 1m 29s\tremaining: 49.4s\n",
            "643:\tlearn: 0.0401716\ttotal: 1m 29s\tremaining: 49.3s\n",
            "644:\tlearn: 0.0401716\ttotal: 1m 29s\tremaining: 49.1s\n",
            "645:\tlearn: 0.0401549\ttotal: 1m 29s\tremaining: 49s\n",
            "646:\tlearn: 0.0401413\ttotal: 1m 29s\tremaining: 48.9s\n",
            "647:\tlearn: 0.0401413\ttotal: 1m 29s\tremaining: 48.7s\n",
            "648:\tlearn: 0.0401413\ttotal: 1m 29s\tremaining: 48.6s\n",
            "649:\tlearn: 0.0401413\ttotal: 1m 29s\tremaining: 48.4s\n",
            "650:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 48.3s\n",
            "651:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 48.1s\n",
            "652:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 48s\n",
            "653:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 47.8s\n",
            "654:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 47.7s\n",
            "655:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 47.5s\n",
            "656:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 47.4s\n",
            "657:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 47.2s\n",
            "658:\tlearn: 0.0401413\ttotal: 1m 30s\tremaining: 47.1s\n",
            "659:\tlearn: 0.0401413\ttotal: 1m 31s\tremaining: 46.9s\n",
            "660:\tlearn: 0.0401413\ttotal: 1m 31s\tremaining: 46.8s\n",
            "661:\tlearn: 0.0401413\ttotal: 1m 31s\tremaining: 46.6s\n",
            "662:\tlearn: 0.0401412\ttotal: 1m 31s\tremaining: 46.5s\n",
            "663:\tlearn: 0.0401412\ttotal: 1m 31s\tremaining: 46.3s\n",
            "664:\tlearn: 0.0401412\ttotal: 1m 31s\tremaining: 46.2s\n",
            "665:\tlearn: 0.0401412\ttotal: 1m 31s\tremaining: 46s\n",
            "666:\tlearn: 0.0401305\ttotal: 1m 31s\tremaining: 45.9s\n",
            "667:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 45.7s\n",
            "668:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 45.6s\n",
            "669:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 45.4s\n",
            "670:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 45.3s\n",
            "671:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 45.2s\n",
            "672:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 45s\n",
            "673:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 44.9s\n",
            "674:\tlearn: 0.0401305\ttotal: 1m 32s\tremaining: 44.7s\n",
            "675:\tlearn: 0.0401129\ttotal: 1m 33s\tremaining: 44.6s\n",
            "676:\tlearn: 0.0401063\ttotal: 1m 33s\tremaining: 44.4s\n",
            "677:\tlearn: 0.0400974\ttotal: 1m 33s\tremaining: 44.3s\n",
            "678:\tlearn: 0.0400974\ttotal: 1m 33s\tremaining: 44.2s\n",
            "679:\tlearn: 0.0400974\ttotal: 1m 33s\tremaining: 44s\n",
            "680:\tlearn: 0.0400817\ttotal: 1m 33s\tremaining: 43.9s\n",
            "681:\tlearn: 0.0400634\ttotal: 1m 33s\tremaining: 43.8s\n",
            "682:\tlearn: 0.0400475\ttotal: 1m 34s\tremaining: 43.6s\n",
            "683:\tlearn: 0.0400475\ttotal: 1m 34s\tremaining: 43.5s\n",
            "684:\tlearn: 0.0400475\ttotal: 1m 34s\tremaining: 43.4s\n",
            "685:\tlearn: 0.0400358\ttotal: 1m 34s\tremaining: 43.2s\n",
            "686:\tlearn: 0.0400262\ttotal: 1m 34s\tremaining: 43.1s\n",
            "687:\tlearn: 0.0400261\ttotal: 1m 34s\tremaining: 42.9s\n",
            "688:\tlearn: 0.0400261\ttotal: 1m 34s\tremaining: 42.8s\n",
            "689:\tlearn: 0.0400261\ttotal: 1m 34s\tremaining: 42.7s\n",
            "690:\tlearn: 0.0400225\ttotal: 1m 35s\tremaining: 42.5s\n",
            "691:\tlearn: 0.0400118\ttotal: 1m 35s\tremaining: 42.4s\n",
            "692:\tlearn: 0.0400117\ttotal: 1m 35s\tremaining: 42.2s\n",
            "693:\tlearn: 0.0400118\ttotal: 1m 35s\tremaining: 42.1s\n",
            "694:\tlearn: 0.0399956\ttotal: 1m 35s\tremaining: 42s\n",
            "695:\tlearn: 0.0399956\ttotal: 1m 35s\tremaining: 41.8s\n",
            "696:\tlearn: 0.0399863\ttotal: 1m 35s\tremaining: 41.7s\n",
            "697:\tlearn: 0.0399861\ttotal: 1m 36s\tremaining: 41.6s\n",
            "698:\tlearn: 0.0399768\ttotal: 1m 36s\tremaining: 41.4s\n",
            "699:\tlearn: 0.0399676\ttotal: 1m 36s\tremaining: 41.3s\n",
            "700:\tlearn: 0.0399556\ttotal: 1m 36s\tremaining: 41.2s\n",
            "701:\tlearn: 0.0399543\ttotal: 1m 36s\tremaining: 41s\n",
            "702:\tlearn: 0.0399426\ttotal: 1m 36s\tremaining: 40.9s\n",
            "703:\tlearn: 0.0399426\ttotal: 1m 36s\tremaining: 40.8s\n",
            "704:\tlearn: 0.0399426\ttotal: 1m 37s\tremaining: 40.6s\n",
            "705:\tlearn: 0.0399375\ttotal: 1m 37s\tremaining: 40.5s\n",
            "706:\tlearn: 0.0399277\ttotal: 1m 37s\tremaining: 40.3s\n",
            "707:\tlearn: 0.0399121\ttotal: 1m 37s\tremaining: 40.2s\n",
            "708:\tlearn: 0.0398992\ttotal: 1m 37s\tremaining: 40.1s\n",
            "709:\tlearn: 0.0398992\ttotal: 1m 37s\tremaining: 40s\n",
            "710:\tlearn: 0.0398992\ttotal: 1m 37s\tremaining: 39.8s\n",
            "711:\tlearn: 0.0398992\ttotal: 1m 38s\tremaining: 39.7s\n",
            "712:\tlearn: 0.0398992\ttotal: 1m 38s\tremaining: 39.5s\n",
            "713:\tlearn: 0.0398992\ttotal: 1m 38s\tremaining: 39.4s\n",
            "714:\tlearn: 0.0398820\ttotal: 1m 38s\tremaining: 39.2s\n",
            "715:\tlearn: 0.0398686\ttotal: 1m 38s\tremaining: 39.1s\n",
            "716:\tlearn: 0.0398551\ttotal: 1m 38s\tremaining: 39s\n",
            "717:\tlearn: 0.0398551\ttotal: 1m 38s\tremaining: 38.8s\n",
            "718:\tlearn: 0.0398277\ttotal: 1m 39s\tremaining: 38.7s\n",
            "719:\tlearn: 0.0398155\ttotal: 1m 39s\tremaining: 38.6s\n",
            "720:\tlearn: 0.0398155\ttotal: 1m 39s\tremaining: 38.4s\n",
            "721:\tlearn: 0.0398154\ttotal: 1m 39s\tremaining: 38.3s\n",
            "722:\tlearn: 0.0398154\ttotal: 1m 39s\tremaining: 38.1s\n",
            "723:\tlearn: 0.0398154\ttotal: 1m 39s\tremaining: 38s\n",
            "724:\tlearn: 0.0398154\ttotal: 1m 39s\tremaining: 37.9s\n",
            "725:\tlearn: 0.0398154\ttotal: 1m 39s\tremaining: 37.7s\n",
            "726:\tlearn: 0.0398154\ttotal: 1m 40s\tremaining: 37.6s\n",
            "727:\tlearn: 0.0398154\ttotal: 1m 40s\tremaining: 37.4s\n",
            "728:\tlearn: 0.0398154\ttotal: 1m 40s\tremaining: 37.3s\n",
            "729:\tlearn: 0.0398154\ttotal: 1m 40s\tremaining: 37.1s\n",
            "730:\tlearn: 0.0398075\ttotal: 1m 40s\tremaining: 37s\n",
            "731:\tlearn: 0.0398075\ttotal: 1m 40s\tremaining: 36.9s\n",
            "732:\tlearn: 0.0398075\ttotal: 1m 40s\tremaining: 36.7s\n",
            "733:\tlearn: 0.0398075\ttotal: 1m 40s\tremaining: 36.6s\n",
            "734:\tlearn: 0.0398075\ttotal: 1m 41s\tremaining: 36.4s\n",
            "735:\tlearn: 0.0398075\ttotal: 1m 41s\tremaining: 36.3s\n",
            "736:\tlearn: 0.0398075\ttotal: 1m 41s\tremaining: 36.1s\n",
            "737:\tlearn: 0.0397932\ttotal: 1m 41s\tremaining: 36s\n",
            "738:\tlearn: 0.0397932\ttotal: 1m 41s\tremaining: 35.9s\n",
            "739:\tlearn: 0.0397784\ttotal: 1m 41s\tremaining: 35.7s\n",
            "740:\tlearn: 0.0397784\ttotal: 1m 41s\tremaining: 35.6s\n",
            "741:\tlearn: 0.0397784\ttotal: 1m 41s\tremaining: 35.4s\n",
            "742:\tlearn: 0.0397784\ttotal: 1m 42s\tremaining: 35.3s\n",
            "743:\tlearn: 0.0397784\ttotal: 1m 42s\tremaining: 35.2s\n",
            "744:\tlearn: 0.0397784\ttotal: 1m 42s\tremaining: 35s\n",
            "745:\tlearn: 0.0397591\ttotal: 1m 42s\tremaining: 34.9s\n",
            "746:\tlearn: 0.0397491\ttotal: 1m 42s\tremaining: 34.8s\n",
            "747:\tlearn: 0.0397491\ttotal: 1m 42s\tremaining: 34.6s\n",
            "748:\tlearn: 0.0397491\ttotal: 1m 42s\tremaining: 34.5s\n",
            "749:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 34.3s\n",
            "750:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 34.2s\n",
            "751:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 34s\n",
            "752:\tlearn: 0.0397490\ttotal: 1m 43s\tremaining: 33.9s\n",
            "753:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 33.8s\n",
            "754:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 33.6s\n",
            "755:\tlearn: 0.0397490\ttotal: 1m 43s\tremaining: 33.5s\n",
            "756:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 33.3s\n",
            "757:\tlearn: 0.0397491\ttotal: 1m 43s\tremaining: 33.2s\n",
            "758:\tlearn: 0.0397491\ttotal: 1m 44s\tremaining: 33.1s\n",
            "759:\tlearn: 0.0397364\ttotal: 1m 44s\tremaining: 32.9s\n",
            "760:\tlearn: 0.0397181\ttotal: 1m 44s\tremaining: 32.8s\n",
            "761:\tlearn: 0.0397180\ttotal: 1m 44s\tremaining: 32.7s\n",
            "762:\tlearn: 0.0397180\ttotal: 1m 44s\tremaining: 32.5s\n",
            "763:\tlearn: 0.0397072\ttotal: 1m 44s\tremaining: 32.4s\n",
            "764:\tlearn: 0.0397072\ttotal: 1m 44s\tremaining: 32.2s\n",
            "765:\tlearn: 0.0397072\ttotal: 1m 45s\tremaining: 32.1s\n",
            "766:\tlearn: 0.0397072\ttotal: 1m 45s\tremaining: 31.9s\n",
            "767:\tlearn: 0.0397072\ttotal: 1m 45s\tremaining: 31.8s\n",
            "768:\tlearn: 0.0397071\ttotal: 1m 45s\tremaining: 31.7s\n",
            "769:\tlearn: 0.0397071\ttotal: 1m 45s\tremaining: 31.5s\n",
            "770:\tlearn: 0.0397071\ttotal: 1m 45s\tremaining: 31.4s\n",
            "771:\tlearn: 0.0397071\ttotal: 1m 45s\tremaining: 31.2s\n",
            "772:\tlearn: 0.0397072\ttotal: 1m 45s\tremaining: 31.1s\n",
            "773:\tlearn: 0.0397072\ttotal: 1m 45s\tremaining: 30.9s\n",
            "774:\tlearn: 0.0397072\ttotal: 1m 46s\tremaining: 30.8s\n",
            "775:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 30.7s\n",
            "776:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 30.5s\n",
            "777:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 30.4s\n",
            "778:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 30.2s\n",
            "779:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 30.1s\n",
            "780:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 30s\n",
            "781:\tlearn: 0.0397070\ttotal: 1m 46s\tremaining: 29.8s\n",
            "782:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 29.7s\n",
            "783:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 29.5s\n",
            "784:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 29.4s\n",
            "785:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 29.2s\n",
            "786:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 29.1s\n",
            "787:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 29s\n",
            "788:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 28.8s\n",
            "789:\tlearn: 0.0397070\ttotal: 1m 47s\tremaining: 28.7s\n",
            "790:\tlearn: 0.0396955\ttotal: 1m 48s\tremaining: 28.5s\n",
            "791:\tlearn: 0.0396955\ttotal: 1m 48s\tremaining: 28.4s\n",
            "792:\tlearn: 0.0396955\ttotal: 1m 48s\tremaining: 28.3s\n",
            "793:\tlearn: 0.0396874\ttotal: 1m 48s\tremaining: 28.1s\n",
            "794:\tlearn: 0.0396874\ttotal: 1m 48s\tremaining: 28s\n",
            "795:\tlearn: 0.0396874\ttotal: 1m 48s\tremaining: 27.8s\n",
            "796:\tlearn: 0.0396874\ttotal: 1m 48s\tremaining: 27.7s\n",
            "797:\tlearn: 0.0396768\ttotal: 1m 48s\tremaining: 27.6s\n",
            "798:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 27.4s\n",
            "799:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 27.3s\n",
            "800:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 27.1s\n",
            "801:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 27s\n",
            "802:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 26.9s\n",
            "803:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 26.7s\n",
            "804:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 26.6s\n",
            "805:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 26.4s\n",
            "806:\tlearn: 0.0396768\ttotal: 1m 49s\tremaining: 26.3s\n",
            "807:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 26.2s\n",
            "808:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 26s\n",
            "809:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 25.9s\n",
            "810:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 25.7s\n",
            "811:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 25.6s\n",
            "812:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 25.4s\n",
            "813:\tlearn: 0.0396768\ttotal: 1m 50s\tremaining: 25.3s\n",
            "814:\tlearn: 0.0396663\ttotal: 1m 50s\tremaining: 25.2s\n",
            "815:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 25s\n",
            "816:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.9s\n",
            "817:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.8s\n",
            "818:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.6s\n",
            "819:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.5s\n",
            "820:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.3s\n",
            "821:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.2s\n",
            "822:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 24.1s\n",
            "823:\tlearn: 0.0396663\ttotal: 1m 51s\tremaining: 23.9s\n",
            "824:\tlearn: 0.0396663\ttotal: 1m 52s\tremaining: 23.8s\n",
            "825:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 23.6s\n",
            "826:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 23.5s\n",
            "827:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 23.4s\n",
            "828:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 23.2s\n",
            "829:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 23.1s\n",
            "830:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 22.9s\n",
            "831:\tlearn: 0.0396662\ttotal: 1m 52s\tremaining: 22.8s\n",
            "832:\tlearn: 0.0396662\ttotal: 1m 53s\tremaining: 22.7s\n",
            "833:\tlearn: 0.0396662\ttotal: 1m 53s\tremaining: 22.5s\n",
            "834:\tlearn: 0.0396662\ttotal: 1m 53s\tremaining: 22.4s\n",
            "835:\tlearn: 0.0396663\ttotal: 1m 53s\tremaining: 22.2s\n",
            "836:\tlearn: 0.0396663\ttotal: 1m 53s\tremaining: 22.1s\n",
            "837:\tlearn: 0.0396662\ttotal: 1m 53s\tremaining: 22s\n",
            "838:\tlearn: 0.0396662\ttotal: 1m 53s\tremaining: 21.8s\n",
            "839:\tlearn: 0.0396661\ttotal: 1m 53s\tremaining: 21.7s\n",
            "840:\tlearn: 0.0396661\ttotal: 1m 53s\tremaining: 21.6s\n",
            "841:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 21.4s\n",
            "842:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 21.3s\n",
            "843:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 21.1s\n",
            "844:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 21s\n",
            "845:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 20.9s\n",
            "846:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 20.7s\n",
            "847:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 20.6s\n",
            "848:\tlearn: 0.0396661\ttotal: 1m 54s\tremaining: 20.4s\n",
            "849:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 20.3s\n",
            "850:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 20.2s\n",
            "851:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 20s\n",
            "852:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 19.9s\n",
            "853:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 19.8s\n",
            "854:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 19.6s\n",
            "855:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 19.5s\n",
            "856:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 19.3s\n",
            "857:\tlearn: 0.0396661\ttotal: 1m 55s\tremaining: 19.2s\n",
            "858:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 19.1s\n",
            "859:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.9s\n",
            "860:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.8s\n",
            "861:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.6s\n",
            "862:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.5s\n",
            "863:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.4s\n",
            "864:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.2s\n",
            "865:\tlearn: 0.0396661\ttotal: 1m 56s\tremaining: 18.1s\n",
            "866:\tlearn: 0.0396661\ttotal: 1m 57s\tremaining: 18s\n",
            "867:\tlearn: 0.0396661\ttotal: 1m 57s\tremaining: 17.8s\n",
            "868:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 17.7s\n",
            "869:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 17.5s\n",
            "870:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 17.4s\n",
            "871:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 17.3s\n",
            "872:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 17.1s\n",
            "873:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 17s\n",
            "874:\tlearn: 0.0396660\ttotal: 1m 57s\tremaining: 16.9s\n",
            "875:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 16.7s\n",
            "876:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 16.6s\n",
            "877:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 16.4s\n",
            "878:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 16.3s\n",
            "879:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 16.2s\n",
            "880:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 16s\n",
            "881:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 15.9s\n",
            "882:\tlearn: 0.0396660\ttotal: 1m 58s\tremaining: 15.8s\n",
            "883:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 15.6s\n",
            "884:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 15.5s\n",
            "885:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 15.3s\n",
            "886:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 15.2s\n",
            "887:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 15.1s\n",
            "888:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 14.9s\n",
            "889:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 14.8s\n",
            "890:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 14.7s\n",
            "891:\tlearn: 0.0396660\ttotal: 1m 59s\tremaining: 14.5s\n",
            "892:\tlearn: 0.0396660\ttotal: 2m\tremaining: 14.4s\n",
            "893:\tlearn: 0.0396660\ttotal: 2m\tremaining: 14.2s\n",
            "894:\tlearn: 0.0396660\ttotal: 2m\tremaining: 14.1s\n",
            "895:\tlearn: 0.0396660\ttotal: 2m\tremaining: 14s\n",
            "896:\tlearn: 0.0396660\ttotal: 2m\tremaining: 13.8s\n",
            "897:\tlearn: 0.0396660\ttotal: 2m\tremaining: 13.7s\n",
            "898:\tlearn: 0.0396660\ttotal: 2m\tremaining: 13.6s\n",
            "899:\tlearn: 0.0396660\ttotal: 2m\tremaining: 13.4s\n",
            "900:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 13.3s\n",
            "901:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 13.2s\n",
            "902:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 13s\n",
            "903:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 12.9s\n",
            "904:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 12.8s\n",
            "905:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 12.6s\n",
            "906:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 12.5s\n",
            "907:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 12.3s\n",
            "908:\tlearn: 0.0396660\ttotal: 2m 1s\tremaining: 12.2s\n",
            "909:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 12.1s\n",
            "910:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.9s\n",
            "911:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.8s\n",
            "912:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.7s\n",
            "913:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.5s\n",
            "914:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.4s\n",
            "915:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.3s\n",
            "916:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11.1s\n",
            "917:\tlearn: 0.0396660\ttotal: 2m 2s\tremaining: 11s\n",
            "918:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10.9s\n",
            "919:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10.7s\n",
            "920:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10.6s\n",
            "921:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10.4s\n",
            "922:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10.3s\n",
            "923:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10.2s\n",
            "924:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 10s\n",
            "925:\tlearn: 0.0396660\ttotal: 2m 3s\tremaining: 9.9s\n",
            "926:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 9.77s\n",
            "927:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 9.63s\n",
            "928:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 9.5s\n",
            "929:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 9.36s\n",
            "930:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 9.23s\n",
            "931:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 9.09s\n",
            "932:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 8.96s\n",
            "933:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 8.82s\n",
            "934:\tlearn: 0.0396660\ttotal: 2m 4s\tremaining: 8.69s\n",
            "935:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 8.55s\n",
            "936:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 8.42s\n",
            "937:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 8.28s\n",
            "938:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 8.15s\n",
            "939:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 8.02s\n",
            "940:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 7.88s\n",
            "941:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 7.75s\n",
            "942:\tlearn: 0.0396660\ttotal: 2m 5s\tremaining: 7.61s\n",
            "943:\tlearn: 0.0396660\ttotal: 2m 6s\tremaining: 7.48s\n",
            "944:\tlearn: 0.0396660\ttotal: 2m 6s\tremaining: 7.34s\n",
            "945:\tlearn: 0.0396660\ttotal: 2m 6s\tremaining: 7.21s\n",
            "946:\tlearn: 0.0396660\ttotal: 2m 6s\tremaining: 7.07s\n",
            "947:\tlearn: 0.0396660\ttotal: 2m 6s\tremaining: 6.94s\n",
            "948:\tlearn: 0.0396659\ttotal: 2m 6s\tremaining: 6.8s\n",
            "949:\tlearn: 0.0396659\ttotal: 2m 6s\tremaining: 6.67s\n",
            "950:\tlearn: 0.0396659\ttotal: 2m 6s\tremaining: 6.54s\n",
            "951:\tlearn: 0.0396659\ttotal: 2m 6s\tremaining: 6.4s\n",
            "952:\tlearn: 0.0396510\ttotal: 2m 7s\tremaining: 6.27s\n",
            "953:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 6.14s\n",
            "954:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 6s\n",
            "955:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 5.87s\n",
            "956:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 5.73s\n",
            "957:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 5.6s\n",
            "958:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 5.46s\n",
            "959:\tlearn: 0.0396429\ttotal: 2m 7s\tremaining: 5.33s\n",
            "960:\tlearn: 0.0396350\ttotal: 2m 8s\tremaining: 5.2s\n",
            "961:\tlearn: 0.0396112\ttotal: 2m 8s\tremaining: 5.07s\n",
            "962:\tlearn: 0.0396112\ttotal: 2m 8s\tremaining: 4.93s\n",
            "963:\tlearn: 0.0396111\ttotal: 2m 8s\tremaining: 4.8s\n",
            "964:\tlearn: 0.0396111\ttotal: 2m 8s\tremaining: 4.67s\n",
            "965:\tlearn: 0.0396111\ttotal: 2m 8s\tremaining: 4.53s\n",
            "966:\tlearn: 0.0396111\ttotal: 2m 8s\tremaining: 4.4s\n",
            "967:\tlearn: 0.0396111\ttotal: 2m 8s\tremaining: 4.26s\n",
            "968:\tlearn: 0.0396111\ttotal: 2m 9s\tremaining: 4.13s\n",
            "969:\tlearn: 0.0396111\ttotal: 2m 9s\tremaining: 4s\n",
            "970:\tlearn: 0.0396111\ttotal: 2m 9s\tremaining: 3.86s\n",
            "971:\tlearn: 0.0396111\ttotal: 2m 9s\tremaining: 3.73s\n",
            "972:\tlearn: 0.0396111\ttotal: 2m 9s\tremaining: 3.6s\n",
            "973:\tlearn: 0.0396111\ttotal: 2m 9s\tremaining: 3.46s\n",
            "974:\tlearn: 0.0396029\ttotal: 2m 9s\tremaining: 3.33s\n",
            "975:\tlearn: 0.0395948\ttotal: 2m 10s\tremaining: 3.2s\n",
            "976:\tlearn: 0.0395948\ttotal: 2m 10s\tremaining: 3.06s\n",
            "977:\tlearn: 0.0395846\ttotal: 2m 10s\tremaining: 2.93s\n",
            "978:\tlearn: 0.0395656\ttotal: 2m 10s\tremaining: 2.8s\n",
            "979:\tlearn: 0.0395656\ttotal: 2m 10s\tremaining: 2.66s\n",
            "980:\tlearn: 0.0395432\ttotal: 2m 10s\tremaining: 2.53s\n",
            "981:\tlearn: 0.0395298\ttotal: 2m 10s\tremaining: 2.4s\n",
            "982:\tlearn: 0.0395179\ttotal: 2m 11s\tremaining: 2.27s\n",
            "983:\tlearn: 0.0395179\ttotal: 2m 11s\tremaining: 2.13s\n",
            "984:\tlearn: 0.0395179\ttotal: 2m 11s\tremaining: 2s\n",
            "985:\tlearn: 0.0395067\ttotal: 2m 11s\tremaining: 1.86s\n",
            "986:\tlearn: 0.0395067\ttotal: 2m 11s\tremaining: 1.73s\n",
            "987:\tlearn: 0.0395067\ttotal: 2m 11s\tremaining: 1.6s\n",
            "988:\tlearn: 0.0395067\ttotal: 2m 11s\tremaining: 1.47s\n",
            "989:\tlearn: 0.0395067\ttotal: 2m 11s\tremaining: 1.33s\n",
            "990:\tlearn: 0.0395067\ttotal: 2m 12s\tremaining: 1.2s\n",
            "991:\tlearn: 0.0395067\ttotal: 2m 12s\tremaining: 1.06s\n",
            "992:\tlearn: 0.0395067\ttotal: 2m 12s\tremaining: 932ms\n",
            "993:\tlearn: 0.0395067\ttotal: 2m 12s\tremaining: 799ms\n",
            "994:\tlearn: 0.0395066\ttotal: 2m 12s\tremaining: 666ms\n",
            "995:\tlearn: 0.0395066\ttotal: 2m 12s\tremaining: 533ms\n",
            "996:\tlearn: 0.0395066\ttotal: 2m 12s\tremaining: 400ms\n",
            "997:\tlearn: 0.0395066\ttotal: 2m 12s\tremaining: 266ms\n",
            "998:\tlearn: 0.0395066\ttotal: 2m 12s\tremaining: 133ms\n",
            "999:\tlearn: 0.0395066\ttotal: 2m 13s\tremaining: 0us\n"
          ]
        }
      ],
      "id": "WzodpgsM4ETp"
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = pd.DataFrame(prediction, columns=[\"category\"])\n",
        "df_sub.to_csv('output_cat.csv', float_format='%.6f', index_label=\"ID\")\n",
        "\n",
        "print(\"done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgvf06jz5Fxq",
        "outputId": "c2c80e8b-9969-4e94-c86b-67c531a9e313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done.\n"
          ]
        }
      ],
      "id": "Lgvf06jz5Fxq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adaboost"
      ],
      "metadata": {
        "id": "TRcZRm0V0Q93"
      },
      "id": "TRcZRm0V0Q93"
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the required packages\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ],
      "metadata": {
        "id": "HlHojsqM0UTq"
      },
      "id": "HlHojsqM0UTq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOnCZWdZiKkC",
        "outputId": "24896d41-0acf-4629-ea82-af4b3300c643"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AdaBoostClassifier(learning_rate=0.1, n_estimators=100)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Using RandomizedSearchCV to get the best set of hyperparameter. \n",
        "ada = AdaBoostClassifier(random_state=0)\n",
        "learning_rate=[0.01, 0.1, 1.0]\n",
        "n_estimators=[10, 100, 500]\n",
        "parameters = {'learning_rate': [0.01, 0.1, 1.0],'n_estimators' : [10, 100, 500]}\n",
        "clf = RandomizedSearchCV(ada, parameters, scoring='f1_micro',cv=5, n_jobs=-1)\n",
        "clf.fit(X_train, Y_train)"
      ],
      "id": "kOnCZWdZiKkC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZCi__0hibiJ",
        "outputId": "296b2cbe-8dc9-4423-f328-51ea1faad8ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9634281627791663"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#evaluating the model on the best set of parameter found\n",
        "model = AdaBoostClassifier(learning_rate=0.1, n_estimators = 100)\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='f1_micro', cv=cv)\n",
        "\n",
        "# report performance\n",
        "print(mean(n_scores))"
      ],
      "id": "0ZCi__0hibiJ"
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the values on the test dataset\n",
        "output = model.predict(X_test)\n",
        "output = [int(i>0.5) for i in output]"
      ],
      "metadata": {
        "id": "RDEoWmOypg2m"
      },
      "id": "RDEoWmOypg2m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpV4tTotiku3",
        "outputId": "dcb0d4a5-5f26-4072-f40e-7b71b5be24ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        }
      ],
      "source": [
        "df_ada = pd.DataFrame(output, columns=[\"category\"])\n",
        "df_ada.to_csv('output.csv', float_format='%.6f', index_label=\"ID\")\n",
        "\n",
        "print(\"done.\")"
      ],
      "id": "PpV4tTotiku3"
    },
    {
      "cell_type": "markdown",
      "id": "b9013149",
      "metadata": {
        "id": "b9013149"
      },
      "source": [
        "##Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbe1bd1",
      "metadata": {
        "id": "5fbe1bd1",
        "outputId": "b34970cb-621a-487e-d15b-1866643062d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ],
      "source": [
        "#pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60c7fb46",
      "metadata": {
        "id": "60c7fb46",
        "outputId": "af3573d6-276f-469a-e181-0994a94149c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (13.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.1.2)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.14.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (0.24.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from Tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->Tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->Tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->Tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->Tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->Tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->Tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "#pip install Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d4881a",
      "metadata": {
        "id": "91d4881a"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Embedding, Dropout, Conv1D, Conv2D, MaxPooling1D, Dense, Merge, Flatten\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.merge import concatenate\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.regularizers import l2\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3986bc31",
      "metadata": {
        "id": "3986bc31"
      },
      "outputs": [],
      "source": [
        "#my_optimizer = 'adam'\n",
        "#N_VECTORIZATION = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d4123a",
      "metadata": {
        "id": "23d4123a"
      },
      "outputs": [],
      "source": [
        "#path_to_data = \"data/\"\n",
        "\n",
        "#training_set = pd.read_csv(path_to_data+\"improved_training_set.csv\")\n",
        "#testing_set = pd.read_csv(path_to_data+\"improved_testing_set.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e8c9deb",
      "metadata": {
        "id": "7e8c9deb"
      },
      "outputs": [],
      "source": [
        "#training_set = training_set.fillna(0)\n",
        "#training_set[selected_features_global] = preprocessing.scale(training_set[selected_features])\n",
        "\n",
        "#testing_set = testing_set.fillna(0)\n",
        "#testing_set[selected_features_global] = preprocessing.scale(testing_set[selected_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d29e53",
      "metadata": {
        "id": "18d29e53"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39394dc",
      "metadata": {
        "id": "e39394dc"
      },
      "outputs": [],
      "source": [
        "#model = Sequential()\n",
        "\n",
        "#model.add(Dense(1500, activation = \"relu\", input_dim=len(selected_features_global)))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(Dense(1500, activation = \"relu\"))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(Dense(1, activation = \"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2e55ad",
      "metadata": {
        "id": "4b2e55ad"
      },
      "outputs": [],
      "source": [
        "#model.compile(optimizer=my_optimizer,\n",
        " #             loss='binary_crossentropy',\n",
        "  #            metrics=[f1])\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7decc5d8",
      "metadata": {
        "id": "7decc5d8"
      },
      "outputs": [],
      "source": [
        "#checkpoint = ModelCheckpoint(\"modelsNN/weights_1500_1500.{epoch:02d}-{f1:.4f}-{val_f1:.4f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "#model.fit(X_tr,Y_tr,batch_size=128,epochs=50,verbose=1,validation_data=(X_val, Y_val,), callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cddf7061",
      "metadata": {
        "id": "cddf7061"
      },
      "outputs": [],
      "source": [
        "#predicted = model.predict(X_tst)\n",
        "#predicted = [int(i>0.5) for i in predicted]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d8f88f",
      "metadata": {
        "id": "e8d8f88f"
      },
      "outputs": [],
      "source": [
        "#df_sub = pd.DataFrame(predicted,columns=[\"category\"])\n",
        "\n",
        "#df_sub.to_csv('output_NN.csv', float_format='%.6f', index_label=\"ID\")\n",
        "#print(\"done\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Link Prediction(3).ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1aaf50191c4649d6ba62232d6ed4f238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df131eafaaf14d2ab2b14f7a0e1758b6",
              "IPY_MODEL_337e2ada51ea4d4582fe744f866eec3b",
              "IPY_MODEL_dbe8b1b1216847e19b727a01f5330035"
            ],
            "layout": "IPY_MODEL_1b3140e58dd543fd991301eec58b2643"
          }
        },
        "df131eafaaf14d2ab2b14f7a0e1758b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c33878e0bd0459fa65027320c6a12ff",
            "placeholder": "​",
            "style": "IPY_MODEL_7856211ed05f4e6a90b5e3ec96637ece",
            "value": ""
          }
        },
        "337e2ada51ea4d4582fe744f866eec3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a427bc407b14f8a9bcd18148d264086",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a1a882635f248d7a23e60ecde6997c8",
            "value": 0
          }
        },
        "dbe8b1b1216847e19b727a01f5330035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e05e9a81ea4d048449ee70ae751e56",
            "placeholder": "​",
            "style": "IPY_MODEL_98b56302a75a4f3e8b30d4636f2a5fb9",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "1b3140e58dd543fd991301eec58b2643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c33878e0bd0459fa65027320c6a12ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7856211ed05f4e6a90b5e3ec96637ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a427bc407b14f8a9bcd18148d264086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8a1a882635f248d7a23e60ecde6997c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0e05e9a81ea4d048449ee70ae751e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b56302a75a4f3e8b30d4636f2a5fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}